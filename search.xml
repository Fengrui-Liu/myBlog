<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F16%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%2F2019-09-16-%E5%9F%BA%E4%BA%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B%E7%9A%84RNN%E6%97%B6%E5%BA%8F%E9%A2%84%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[时间注意力模型下的时序预测.md]]></title>
    <url>%2F2019%2F09%2F12%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%2F2019-09-12-%E6%97%B6%E9%97%B4%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B%E4%B8%8B%E7%9A%84%E6%97%B6%E5%BA%8F%E9%A2%84%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[Multi-Horizon Time Series Forecasting with Temporal Attention Learning(KDD' 19) 文章阐述了历史信息中的时间模式对长时间序列的预测是至关重要的。传统方法中手动设置时间依赖从而探索相关的时序模式是很不靠谱的，本文用DNN的方法提出了端到端的多视界模型来进行预测，从时间的注意力上来更好地捕获历史数据的潜在模式，还提出了一种多模型的融合机制可以结合不同历史数据的特征来更好地预测。 multi-horizon代表的意思就是在未来时间内进行多步预测。这可以用来进行资源规划的预测以及决策。这对LSTM提出了挑战，因为当前的输入源于历史信息和未来动态输入的变量，我们的可以精确预测是因为，可以通过对潜在模型的适当表示以及历史数据时间模式的参照。 方法 基础编码-解码结构 采用的是seq2seq流水线结构来编码历史/未来的输入变量，然后解码用于未来的预测 如上图所示，编码过程是一个两层的LSTM架构，可以将历史信息匹配到隐藏层的上一层的\(h_{t-1}\)。其中\(x_t\)代表每一个时间戳中的输入，隐藏层就是\(h_t\)，内部的门(gate cell)就是\(i_t,f_t,o_t,c_t\) \[ \begin{array}{l}{i_{t}=\sigma\left(W_{i x} x_{t}+W_{i m} m_{t-1}\right)} \\ {f_{t}=\sigma\left(W_{f x} x_{t}+W_{f m} m_{t-1}\right)} \\ {o_{t}=\sigma\left(W_{o x} x_{t}+W_{o m} m_{t-1}\right)} \\ {c_{t}=f_{t} \cdot c_{t-1}+i_{t} \cdot \tanh \left(W_{c x} x_{t}+W_{c m} m_{t-1}\right)} \\ {h_{t}=o_{t} \cdot \tanh \left(c_{t}\right)}\end{array} \] 上述复杂的公式简写成\(h_t^e=LSTM^e(x_t;h_{t-1})\), 其中\(e\)就表示在隐含层中已经经过了编码。 解码器就是将编码器的输出当作输入的初始状态，未来的信息也作为输入生成未来序列，也就是输出。解码器设计成一个双向LSTM网络，可以正向和逆向传播未来的输入特征。这个结构可以使得前向和后向的输入都可以在每一个未来的时间步中观察得到。BiLSTM的隐含层传入一个全连接层或者一个时间域上的卷积层来进行最后的预测。我们强调说最后的预测应该是在BiLSTM信息传播后来进行的。通过将信息传播状态和信息预测状态进行分离，防止在一个长视界（long horizon）中错误的累加。这个结构中前向和后向的信息传播是分离的。定义如下： \[ \begin{aligned} h_{t}^{f} &amp;=L S T M^{f}\left(x_{t} ; h_{t-1}\right) \\ h_{t}^{b} &amp;=L S T M^{b}\left(x_{t} ; h_{t+1}\right) \\ h_{t} &amp;=\left[h_{t}^{f} ; h_{t}^{b}\right] \end{aligned} \] 上式可以综合写成\(h_t^d = BiLSTM^d(x_t;h_{t-1},h_{t+1})\)，为了从隐含层生成分位数的预测，我们加入了一个线性层，在编码解码层的K维分位数预测则为 \[ \begin{aligned} y_{t}^{e} &amp;=W_{e} h_{t}^{e}+b_{e} \\ y_{t}^{d} &amp;=W_{d} h_{t}^{d}+b_{d} \end{aligned} \] Embedding 通过Embedding技术可以将明确的变量映射为数个特征向量，采用one-hot编码代表\(|C|\)变量\(x_c=\{0...010...0\}\in R^{|C|}\)，学习的嵌入式矩阵\(W_c\in R^{D*|C|}\)，变化后的变量可以由\(x_c&#39;=W_cx_c\)计算得。 注意力模型 编码解码模型由于内存的更新很难捕获长期的记忆，所以这里使用注意力模型，如图所示 最下层的是历史编码模块，最上层是一个BiLSTM的未来解码模块，文章设计了一个多模型的注意力机制，他由每次未来时间步骤中的BiLSTM的隐藏层引导，并且融合不同的权重应用到不同的历史数据中 时间注意力 不能使用全体的历史数据，原因是真实世界的时序数据太长了，可能会模糊掉注意力模型，并且计算不够有效率。文章提出了一种分离性注意每个时期下的历史数据并将其结合到多形态融合的模式下，长度可以由人为设定。时间注意力的权重\(\gamma_{1:T_h}\)可以表述为 \[ \begin{array} {c}{\mathbf{g}=\mathbf{v}_{g}^{\top} \tanh \left(\mathbf{W}_{g} \mathbf{s}_{t}+\mathbf{V}_{g} \mathbf{h}+\mathbf{b}_{g}\right)} \\ {\gamma_{i}=\frac{\exp \left(g_{i}\right)}{\sum_{j=1}^{T_{h}} \exp \left(g_{j}\right)} \quad \text { for } i=1 \ldots T_{h}} \end{array} \] 然后加入的内容向量\(c_t\)和transformer\(d_t\)为： \[ \begin{aligned} \mathbf{c}_{t} &amp;=\sum_{i=1}^{T_{h}} \gamma_{i} \mathbf{h}_{i} \\ \mathbf{d}_{t} &amp;=\operatorname{ReLU}\left(\mathbf{W}_{d} \mathbf{c}_{t}+\mathbf{b}_{d}\right) \end{aligned} \] 多形态融合 图3 给出的是M=2的融合结果， \[ \begin{array}{l}{\mathbf{p}_{t}^{m}=\mathbf{v}_{p}^{\top} \tanh \left(\mathbf{W}_{p} \mathbf{s}_{t}+\mathbf{V}_{p}^{m} \mathbf{d}_{t}^{m}+\mathbf{b}_{p}\right)} \\ {\phi_{t}^{m}=\frac{\exp \left(p_{t}^{m}\right)}{\sum_{k=1}^{M} \exp \left(p_{t}^{k}\right)} \quad \text { for } m=1 \ldots M}\end{array} \] 融合后的知识库\(x_t\)可以由\(d_t^m\)的加和计算结果给出 \[ x_t=\sum_{m=1}^M\phi_t^md_t^m \]]]></content>
      <categories>
        <category>Anomaly detection</category>
      </categories>
      <tags>
        <tag>Anomaly detection</tag>
        <tag>time series</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多维时序无监督异常检测.md]]></title>
    <url>%2F2019%2F09%2F09%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%2F2019-09-09-DNN%E5%A4%9A%E7%BB%B4%E6%97%B6%E5%BA%8F%E6%97%A0%E7%9B%91%E7%9D%A3%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[A Deep Neural Network for Unsupervised Anomaly Detectionand Diagnosisin Multivariate Time Series Data 贡献 形式化异常检测到三个子问题上： 异常检测 根因定位 异常严重性解释 提出了系统签名矩阵（system signature matrix）的概念，用MSCRED通过一个卷积编码器来编码tensor间的联系，基于注意力模型的ConvLSTM网络可以处理时间的模型。该模型首次可以解决上述三个问题 性能超越baseline MSCRED 框架 Multi-Scale Convolutional Recurrent Encoder-Decoder 大体思路： 1. 生成多尺度的系统签名矩阵 2. 通过卷积编码器把空间信息编码到签名矩阵中 3. 把时间信息编码到ConvLSTM注意力模型中 4. 根据卷积解码器重构签名矩阵，利用平方误差来进行端到端的学习 使用签名矩阵描述状态 对于时间段\(t-w\) 到 \(t\) 这段时间内，两个时序\(x_i^w =(x_i^{t-w},x_i^{t-w-1},...,x_i^t)\) 与 \(x_j^w =(x_j^{t-w},x_j^{t-w-1},...,x_j^t)\)，联合计算 \[ m_{ij}^t = \frac{sum_{\delta=0}^\omega x_i^{t-\delta}x_j^{t-\delta}}{K} \] 其中\(K\)作为缩放因子。这个矩阵可以衡量相似性且有一定的鲁棒性，有\(m\)构成完全矩阵\(M\) 卷积下的编码器 首先将\(M^t\)用不同尺度连接成tensor \(\chi^{t,0}\in \mathbb{R}^{n*n*s}\) 然后再传入卷积层，前后两层的通过激活函数连接 \[ \chi^{t,l}=f(W^l*\chi^{t,l-1}+b^l) \] 激励函数用的是SELU 基于注意力的ConvLSTM 传统的ConvLSTM可能随着时序序列的增加，性能发生下降，为了解决这个问题，引入了注意力模型，可以根据时间戳动态采取相关隐含层（feature map）。隐含层的更新\(H^{t,l} = ConvLSTM(\chi^{t,l},H^{t-1,l})\)]]></content>
      <categories>
        <category>Anomaly detection</category>
      </categories>
      <tags>
        <tag>Anomaly detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异常检测（MSRA，KDD'19）]]></title>
    <url>%2F2019%2F08%2F14%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%2F2019-08-14-%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%EF%BC%88MSRA%20KDD'19%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Time-Series Anomaly Detection Service at Microsoft Spectral Residual(SR) 以及 Convolutional Neural Network(CRR) 方法来进行时序异常检测。 挑战： 1. 缺少标签：系统往往需要同时处理千百万的数据量，不能手动添加标签。时序数据分布也是不断变化的，需要识别从前没有过的异常模式，也就是说有监督的模型是不可以的。 2. 普适性：需要兼容多种数据模式。 3. 有效性：监控系统往往要实时处理很多的数据，尤其是分钟级的数据，异常检测系统需要在有限时间内进行处理。 CNN是一种带标签的有监督检测，SR则是一个无监督的模型，二者结合。 系统 Data Ingestion 连接及粒度。连接可以将用户存储系统和异常检测系统对接，粒度可以确定异常检测任务周期性接纳新的数据。（fluxDB和Kafka） ### Online Compute 在线计算可以让每个数据都在进入流水线后立即得到处理，这里需要一个滑动窗口来优化内存以及保证计算有效性。（Flink） ### Experimentation Platform 衡量性能，可以人工标记一些数据来评判检测的准确性 方法 异常检测可以使用SR的基础是，时序的异常表现在图形图像上来说往往是突出的。CNN可行的原因是有标签的数据效果较好，因此二者要结合 SR 步骤如下： 1. 快速傅里叶变化FTT得到对数振幅频谱 2. 计算频谱冗余 3. 逆傅里叶变化将序列反转到空间域名 特别的快速傅里叶FFT是通过滑动窗口处理队列的。更多的是关注延迟，发现当检测点是滑动窗口中间点时效果最好，因此要在已知输入的最后一个点后加上几个预测点来从而使该点放在滑动窗口的中心位置，对于\(x_n\)后的估计点\(x_{n+1}\)计算如下： \[ \bar{g}=\frac{1}{m}\sum_{i=1}^mg(x_n,x_{n-i})\\ x_{n+1} = x_{n-m+1}+\bar{g}\cdot m \] 其中\(g(x_i,x_j)\)可以作为i，j两点直线上的斜率，\(\bar{g}\)也就是平均梯度，m=5，\(x_{n+1}\)作为一个关键点这里复制K次加到序列末尾即可。 SR-CNN 原始的SR可以通过设置阈值实现异常检测，但是为了解决更复杂的问题要采用CNN，用在显著图（FTT变换后的）而非原始输入图。CNN由两个1-D的卷积层（卷积核大小与滑动窗口大小一样）以及两个全连接层构成，第一个卷积层的通道大小与滑动窗口一样，第二个卷积层大小翻倍，全连接层在Sigmoid输出前是堆叠的，交叉熵采用损失函数]]></content>
      <categories>
        <category>Anomaly detection</category>
      </categories>
      <tags>
        <tag>Anomaly detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实时异常检测（xStream，KDD'18）]]></title>
    <url>%2F2019%2F07%2F21%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%2F2019-08-13-%E5%AE%9E%E6%97%B6%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[xStream: Outlier Dete‘x’ion in Feature-Evolving Data Streams 首次对evolving数据流进行异常检测，特征：不仅仅由随着时间出现的新的数据点，已有数据点的特征可能会变化也可能会出现新的特征，也就是说数据矩阵的行列都是不确定规模的 提出算法xStream的特性 对于固定数据模型算法计算的内存空间和时间都是固定的； 使用子空间投影可以处理高维数据； 多种尺度来衡量异常点，区分离散的异常点和聚集的异常异常群 基于窗口的方法来处理非平稳数据 问题形式化：网络数据流\(D=\{e_t\}_{t=1,2,...}\)，每一个元素\(e_t\)都是一个三元组的形式\((id,f,\delta)_t\)。这里的\(id\)对于每一个数据点来说是唯一的，\(f\)是特征名，由一个字符串代替，\(\delta\)是一个连续或者离散的标量。每一个三元组都是对一个不可见特征空间里点的更新。 问题1: 给定一个数据流\(D=\{e_t\}_{t=1,2,...}\)以及三元组\((id,f,\delta)_t\)计算并持续对每个点打分，要求所有的异常点分数都高于非异常点 xStream 通过整合Half-Space Chains来有效估计密度，每个链通过大规模计算邻居从而估计某个点的密度 StreamHash：通过稀疏随机投影来子空间选择来实习降维。 Half-Space Chains：一种大规模有效密度估计方法。 扩展到对非静态数据以及进化特征的处理。 StreamHash 随机投影。经典的随机投影方法是通过一系列的高斯随机向量\(\{r_1,...,r_K\}\subset \mathbb{R}^d\)把每一个点\(x\in \mathbb{R}^d\)投影到一个低维嵌入空间\(y\in \mathbb{R}^K\),\(y = (x^Tr_1,...,x^Tr_K)\)其中K是随机投影的个数，从而保证嵌入向量的距离与原空间的向量距离相似。 对于高维数据，异常点经常是存在于低维的子空间中，由于不相干特征的存在导致很难检测出异常。这个问题可以通过在已选择的子空间数据中寻找异常来降低困难。改进高斯随机投影为database-friendly random projection，只有其中1/3的向量都是非零向量，在这种规则下，每个投影都忽略2/3的特征空间，始终保持每对点的距离。投影值遵循以下分布： \[ r_i[j] = \sqrt{\frac{3}{K}}\left\{\begin{matrix} -1 &amp; with\ probability \ \frac{1}{6}\\ 0 &amp; with\ probability \ \frac{2}{3}\\ +1 &amp; with\ probability \ \frac{1}{6} \end{matrix}\right. \] 在特征进化的数据流中，真正的维度d是不可观测的，并且数据进化是实时的。因此他不可能抽取一系列随机向量\(r_1,...,r_K\)作为先验维度。为了解决这个问题，StreamHash是一个基于哈希的离散随机投影，初始化时K个哈希函数\(h_1(\cdot),...h_K(\cdot)\),每个哈希函数都能将一个特征名称f映射成一个哈希值\(h_i:f\rightarrow \mathbb{R}\),给定一个固定特征空间\(\mathcal{F}\)的点x，随机投影结果如下： \[ y[i]=\sum_{f_j\in\mathcal{F}}h_i(f_j)x[j], i=1,...,K \] 上式是对所有特征一次性全部到达的结果 对于进化特征的数据点，更新的投影id可以通过如下计算： \[ y_{id}[i] = y_{id}[i]+h_i(f)\delta, i=1,...,K \] 如果更新项\(y_{id}\)不存在，那么他就将使用第一次的更新值作为初始值，在这个投影规则下，尽管数据是在不断接受的，我们仍可以计算并保持低维的投影。 对于哈希函数，我们使用哈希族\(g_1(\cdot),...,g_K(\cdot)\)将字符串哈希成32bit整数，令\(a_i(f)=g_i(f)/(2^{32}-1)\)是一个0~1之间的数字。\(h_i(f)\)被定义为K随机投影，这一部分其实就是用哈希的方式随机抽取一定的数据进行分布。 \[ h_i[f]=\sqrt{\frac{3}{K}} \left\{\begin{matrix} -1 &amp; if\ a_i(f)\in[0,1/6)\\ 0 &amp; if\ a_i(f)\in[1/6,5/6)\\ +1 &amp; if\ a_i(f)\in[5/6,1] \end{matrix}\right. \] Half-Space Chains 密度估计异常点，可以通过半径估计邻居数量。 两个问题： 1. 异常检测对于选择的尺度非常敏感 2. 在高维数据中，随着维数增高其邻居数量逐渐趋近于0 我们在K维空间上使用密度估计\(\mathcal{P}=\{1,...,K\}\),一种方法是通过利用等宽直方图估计，但是随着维数增加，bins也会指数上升，导致每个bins太分散以至于不能可靠地估计密度，我们提出了深度为D的Half-Space Chains方法。每个链都随机在不同level\(l=1,...,D\)选择一个分割维度\(p\in \mathcal{P}\),递归地将高维空间分割成离散的bins。除此之位，如果一个特征在子空间被重复采样，那么将会被离散成一个较小宽度的bin。维度的采样也是通过可替代随机进行采样的。令\(\Delta[p]\)作为初始bin宽度。初始化bin vector \(\bar{z}\in\mathbb{Z}^K\)为0，令\(p=p[1]\in \mathcal{P}\)作为在level=1时的特征采样。bin vector在level=1的bin宽度是\(\bar{z}[p]=\left \lfloor y[p]/\Delta[p] \right \rfloor\), 对于密度估计来说，bin 的边界设置是至关重要的。这里提出了对每个维度随机偏移\(s[p]，s[p]\in Uniform(0,\Delta[p])\)。这个偏移减少了确定性边界对聚类结果的影响，因为聚类节点有可能会落入到同一个bin当中。令\(o(p,l)\)做完特征p在链中采样的次数。详见论文中的例子，有很好解释。 \[ z[p] = \frac{y[p]+s[p]/2^{o(p,l)-1}}{\Delta[p]/2^{o(p,l)-1}}\\ \bar{z} = \left \lfloor z \right \rfloor \] 打分： \[ S(y)=\frac{1}{M}\sum_{c\in C}S_{C}(y)=\frac{1}{M}\sum_{c\in C}min_l 2^lH_l[\bar{z}] \] 对于给出的有异常的图\(S(x)\),输出序列如下： \[ O(x_i) = \left\{\begin{matrix} 1, if\ \frac{S(x_i)-\bar{S(x_i)}}{\bar{S(x_i)}} &gt; \tau \\ 0, otherwise \end{matrix}\right. \] 其中x是序列中任意一个点，\(S(x_i)\)是异常图中对应的点，\(\bar{S(x_i)}\)是当前平均点 通过上述计算可以得到任意level的\(\bar{z}\)，我们可以索引其到计数的数据结构中，以得到该level的一个bin-count。然而，独一无二的bin vectors可能会在无限的网络流场景中特别大，因此我们在不同的level上使用一个count-min-sketch，\(H_l\in H,l=1,...,D\),可以通过这个高精确度地估计bin-counts。 总的来说，每个链可以定义为\(C=\{p,\Delta,s,H\}\),这样链的集合可以构成一个\(C =\{C_1,...C_M\}\),从而组成了一个Half-Space Chains 接下来就是构建适当的bin-vecto，通过上面的公式我们可以在不同level \(l=1,...D\) 计算bin-vector，然而，如下的递归式可以增量地计算非离散化的bin vectors， 从\(l=1\)开始，向下层逐步计算算术操作。 \[ z[p] = (y[p]+s[p])/\Delta [p] \ \ if\ o(p,l)=1 \\ z[p] = 2z[p] - s[p]/\Delta[p] \ \ if\ o(p,l)&gt;1 \] 其中p是在level \(l\) 处的特征采样，\(o(p,l)\) 表示该特征曾经被采样过的次数 在Half-Space Chain 中更新bin-counts ，bin-vector可以索引到\(H_l\)中来进行bin-count计数\(H_l[\bar{z}]\),但存在情况要把链中的点删除，当某个点（特征）发生进化，就需要删除原投影，并加入更新后的投影，删除过程与加入过程类似，bin-count要使用递减的方式来代替。 多尺度的异常打分。在更高的level，由于维度关系，bin-counts可能会趋近于非常低的数，为了针对不同的level都有合理的分数，推断bin-count为\(2^lH_l[\bar{z}]\),这和当初始bin宽度\(\Delta[p]\)恰巧等于p范围的一半时，期望的每条链中的随机分布相等。 我们定义的多尺度异常评分 \[ S(y)=\frac{1}{M}\sum_{C\in C}S_C(y)=\frac{1}{M}\sum_{C\in C}min_l2^lH_k[\bar{z}] \] 更新bin-counts与计算异常点的评分时同步的。 处理非静态数据 问题的关键在于随着网络流的变化，数据分布也会变化，导致bin-counts的构成不再能代表现在数据的分布。 处理非静态数据 使用窗口，分为当前窗口和参考窗口，当点y开始在链中传播时，用参考窗口计算评分，当前窗口进行更新，当出现新的点，用当前窗口代替参考窗口，并把当前窗口初始化为0。窗口有分布的频率确定，高频适合小窗口，但是也不能太小，会导致变化过大。 特征进化的点 前面的公式介绍了计算方法，实际要保留固定cache的N个投影点，采用LRU算法保留特征]]></content>
      <categories>
        <category>Anomaly detection</category>
      </categories>
      <tags>
        <tag>Anomaly detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[孤立森林（Isolation Forest）]]></title>
    <url>%2F2019%2F07%2F21%2F%E5%AE%89%E5%85%A8%2F2019-07-22-xgboost%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Anomaly detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[指数加权移动平均法（EWMA）]]></title>
    <url>%2F2019%2F07%2F21%2F%E5%AE%89%E5%85%A8%2F2019-07-21-%E6%8C%87%E6%95%B0%E5%8A%A0%E6%9D%83%E7%A7%BB%E5%8A%A8%E5%B9%B3%E5%9D%87%E6%B3%95%EF%BC%88EWMA%EF%BC%89%2F</url>
    <content type="text"><![CDATA[主要思想 Exponentially Weighted Moving Average (EWMA)，对观察值给予不同的权重求得平均值，并以平均值为基础确定预测值的方法，往往近期观察值的权重高是因为其更能反映近期变化的趋势。各个指数加权系数是随时间指数递减的，越靠近当前时刻，加权系数就越大。 可以视作一种理想的最大似然估计，当前估计值由前一次估计值和当前的抽样值共同决定；也可以视作一个低通滤波器，剔除短期波动保留长期发展趋势的平滑形式。 优点 不需要保存过去的所有数值 计算量显著减小 计算 \[ v_t = \beta v_{t-1}+(1-\beta)\theta_t\] 其中\(\theta_t\)为时刻\(t\)的实际温度；\(\beta\)表示加权下降的速率，其值越小下降越快；\(v_t\)为\(t\)时刻的EWMA值。 变差修正 如果初始化\(v_0=0\),那么初期值都会偏小，虽然最后会慢慢减小这部分影响但是还是对公式做出适当修正： \[v_t = \frac{\beta v_{t-1}+(1-\beta)\theta_t}{1-\beta^t}\] 当t表较小（初期）分母可以很好放大当前数值，当t很大，分母趋为1，对数值机会没有影响。 代码 import numpy as npclass Ewma(object): """ In statistical quality control, the EWMA chart (or exponentially weighted moving average chart) is a type of control chart used to monitor either variables or attributes-type data using the monitored business or industrial process's entire history of output. While other control charts treat rational subgroups of samples individually, the EWMA chart tracks the exponentially-weighted moving average of all prior sample means. WIKIPEDIA: https://en.wikipedia.org/wiki/EWMA_chart """ def __init__(self, alpha=0.3, coefficient=3): """ :param alpha: Discount rate of ewma, usually in (0.2, 0.3). :param coefficient: Coefficient is the width of the control limits, usually in (2.7, 3.0). """ self.alpha = alpha self.coefficient = coefficient def predict(self, X): """ Predict if a particular sample is an outlier or not. :param X: the time series to detect of :param type X: pandas.Series :return: 1 denotes normal, 0 denotes abnormal """ s = [X[0]] for i in range(1, len(X)): temp = self.alpha * X[i] + (1 - self.alpha) * s[-1] s.append(temp) s_avg = np.mean(s) sigma = np.sqrt(np.var(X)) ucl = s_avg + self.coefficient * sigma * np.sqrt(self.alpha / (2 - self.alpha)) lcl = s_avg - self.coefficient * sigma * np.sqrt(self.alpha / (2 - self.alpha)) if s[-1] &gt; ucl or s[-1] &lt; lcl: return 0 return 1]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Anomaly detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多项式插值]]></title>
    <url>%2F2019%2F07%2F21%2F%E5%AE%89%E5%85%A8%2F2019-07-21-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%8F%92%E5%80%BC%2F</url>
    <content type="text"><![CDATA[Polynominal Interpolation 多项式插值，给定一组数据，寻找一个恰好通过这些数据点的多项式。 代码 import numpy as npfrom sklearn.linear_model import Ridgefrom sklearn.preprocessing import PolynomialFeaturesfrom sklearn.pipeline import make_pipelinefrom time_series_detector.common.tsd_common import *class PolynomialInterpolation(object): """ In statistics, polynomial regression is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial in x. WIKIPEDIA: https://en.wikipedia.org/wiki/Polynomial_regression """ def __init__(self, threshold=0.15, degree=4): """ :param threshold: The critical point of normal. :param degree: Depth of iteration. """ self.degree = degree self.threshold = threshold def predict(self, X, window=DEFAULT_WINDOW): """ Predict if a particular sample is an outlier or not. :param X: the time series to detect of :param type X: pandas.Series :param window: the length of window :param type window: int :return: 1 denotes normal, 0 denotes abnormal """ x_train = list(range(0, 2 * window + 1)) + list(range(0, 2 * window + 1)) + list(range(0, window + 1)) x_train = np.array(x_train) x_train = x_train[:, np.newaxis] avg_value = np.mean(X[-(window + 1):]) if avg_value &gt; 1: y_train = X / avg_value else: y_train = X model = make_pipeline(PolynomialFeatures(self.degree), Ridge()) model.fit(x_train, y_train) if abs(y_train[-1] - model.predict(np.array(x_train[-1]).reshape(1, -1))) &gt; self.threshold: return 0 return 1]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Anomaly detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用时序决策树进行DGA僵尸检测]]></title>
    <url>%2F2019%2F07%2F21%2F%E5%AE%89%E5%85%A8%2F2019-07-22-%E5%88%A9%E7%94%A8%E6%97%B6%E5%BA%8F%E5%86%B3%E7%AD%96%E6%A0%91%E8%BF%9B%E8%A1%8CDGA%E5%83%B5%E5%B0%B8%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[DGA Bot Detection with Time Series Decision Trees 主要思路 标签模块依赖分类技术，该模块可以对训练模型生成有标签的数据，并对每一个已经检测到的僵尸网络提供一系列的感染IP 训练模块使用对生成的标签数据进行有监督的学习，对每一个僵尸网络家族都构造一个检测模型。利用典型的IP时间轮廓评估。 检测模块在短时间内检测受到影响的IP。 标签模块 给有监督训练模型提供受感染IP的实例，该模块只处理在DNS服务器中不存在的域名，利用的原理是通过将相同DGA僵尸网络的子集请求进行聚类。 数据预处理 通过启发式方法减小数据量，减少良性的DNS流量，只保留可疑的NXDOMAIN来进行后续的聚类。（根据域名进行判断） 分级聚类 D作为一系列的域名，每一个域名d都由一组IP代表，这组IP可以至少区分一个不成功的DNS请求。聚类结果C可以代表D的一种划分，对于每一个类别c都是自底向上聚类的结果。两个类可以计算相似度，如果相似度在限制内可以进行合并；该限制也可以防止没有共享足够IP的两个类进行合并。 相似度计算公式： \[ \forall(c_i,c_j) \in C^2, sim(c_i.c_j) = |IP^{c_i}\cap IP^{c_j} | \] 相似度限制公式： \[ sim(c_1^*,c_2^*) &gt; \alpha \cdot min(|IP^{c_1^*}|,|IP^{c_2^*}|) \] 得到受感染的IP 往往丢弃与恶意行为不相干的类别，对已识别的DGA僵尸网络命名， 检测模块：时序决策树 输入：DNS时序，每个IP都有标签{Infected，NonInfected} 在CART决策树的基础上训练，根节点包含所有的训练实例。每个内部节点都包含一系列的训练实例\(\tau\)以及根据输入特征确定的分割条件s 所有的实例拥有相同的标签 \[\forall(T_0,T_1) \in \tau^2, label(T_0)=label(T_1)\] 所有的实例根据距离公式都是相等的 \[\forall(T_0,T_1) \in \tau^2, dist(T_0,T_1)=0\] 训练模块 分治算法进行决策树的处理，一条子树持续划分直到满足上述两个限制。 对于一个训练集，首先计算分裂的候选值，要求分裂结果使得子树最干净，干净可以用标签的定义来进行判断。最不干净的结果就是一半为{Infected}另一半为{NonInfected} 检测模块 当决策树构建结束后，就可以通过从根节点到叶子节点的一条路径上的划分来区分其属于哪一个类。 时序划分候选 标准划分：通过半径划分 聚类划分：根据到中心的的距离进行划分 时序距离 DTW距离（很好的分析时序距离的方法）]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Anomaly detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度提升决策树（GBDT）]]></title>
    <url>%2F2019%2F07%2F21%2F%E5%AE%89%E5%85%A8%2F2019-07-21-%E6%A2%AF%E5%BA%A6%E6%8F%90%E5%8D%87%E5%86%B3%E7%AD%96%E6%A0%91(GBDT)%2F</url>
    <content type="text"><![CDATA[GCDT：梯度提升决策树 Gradient Boosting Decision Tree，又叫做MART（Multiple Additive Regression Tree）迭代的决策树算法，由多颗决策树组成，具有较强的泛化能力。GBDT是一回归树用来做回归预测，调整后可以用于分类。 Regression Decision Tree：回归树 回归树的每一个节点都会有一个预测值（例如平均值），分支时穷举每一个feature的每个阈值找到最好的分割点，且用最小化平方误差进行衡量分类标准。也就是说分类错误越多平方误差越大，直到每个叶子节点上的预测值都能达到预设的终止条件。 Boosting Decision Tree：提升树算法 Boosting：将弱学习提升为强学习器的算法。主要思想：对于负责任务，将多个专家的判断进行适当综合得出对应的判断，比任何一个专家单独的判断要好。 提升树通过迭代多个回归树来进行共同决策。当采用平方误差损失函数，每一个回归树学习的是所有树的结论和残差，拟合得到当前的残差回归树。残差=真实值-预测值。提升树可以视作整个迭代过程生成的回归树的累加。 每一次迭代都增加被错误分类的样本的权重，使模型在之后的迭代中更加注意到难以分类的样本。 Xgboost 和 GBDT 的区别： GBDT： GBDT 它的非线性变换比较多，表达能力强，而且不需要做复杂的特征工程和特征变换。 GBDT 的缺点也很明显，Boost 是一个串行过程，不好并行化，而且计算复杂度高，同时不太适合高维稀疏特征； 传统 GBDT 在优化时只用到一阶导数信息。 Xgboost： 显示的把树模型复杂度作为正则项加到优化目标中。 公式推导中用到了二阶导数，用了二阶泰勒展开。（GBDT 用牛顿法貌似也是二阶信息） 实现了分裂点寻找近似算法。 利用了特征的稀疏性。 数据事先排序并且以 block 形式存储，有利于并行计算。 基于分布式通信框架 rabit，可以运行在 MPI 和 yarn 上。（最新已经不基于 rabit 了） 实现做了面向体系结构的优化，针对 cache 和内存做了性能优化]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Anomaly detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[孤立森林（Isolation Forest）]]></title>
    <url>%2F2019%2F07%2F21%2F%E5%AE%89%E5%85%A8%2F2019-07-22-%E5%AD%A4%E7%AB%8B%E6%A3%AE%E6%9E%97%EF%BC%88Isolation%20Froest%EF%BC%89%2F</url>
    <content type="text"><![CDATA[iForest 无参数无监督方法。 假设用一个随机超平面切割数据空间，切一次产生两个子空间，依次循环下去直到每个子空间只有一个数据点为止。直观的说那些密度很高的簇需要被切割很多次才会停止，但是那些密度较低的点很容易较早地停在一个子空间里 实现步骤 切割是随机的因此需要集成方法得到一个收敛值，即反复从头开始切然后平均每次的结果。 从训练数据集中选择样本点作为subsample,放入树的根节点。 随机指定一个维度，随机产生一个切割点p，位于当前数据的最大最小值之间。 以切割点生成超平面，然后将当前的节点数据空间划分为2个子空间，把小于p的放入节点的左孩子，大于等于p的放在右孩子 在孩子节点中不断递归步骤2和3，直到无法切割，或者达到限定高度。 获得t个iTree后，训练结束然后可以用生成的iForest来评估测试数据，对于每一个训练数据x遍历每一棵iTree，计算其落在第几层，得到x在每个树高度平均值。获得测试数据的高度平均值后可以设置一个阈值，低于阈值的测试数据为异常。异常在书中往往有较短的平均高度。论文对高度进行归一化结果是一个0到1的数值，越短高度越接近1（异常可能性越高） 可以看出d最有可能是异常 默认参数 subsample size：256 Tree height：8 Number of trees：100]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Anomaly detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络异常行为检测]]></title>
    <url>%2F2019%2F06%2F22%2F%E5%AE%89%E5%85%A8%2F2019-06-22-%E7%BD%91%E7%BB%9C%E5%BC%82%E5%B8%B8%E8%A1%8C%E4%B8%BA%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[基于统计学习的网络异常行为检测技术(启明) 基于人工特征提取的异常检测技术的技术路线是：分析人员首先以某种方式从原始数据中提取特征参数，然后基于特征进行建模和异常检测。 人工特征提取的优点是（应用较多）： * 特征提取建立在安全分析人员的认知基础之上，对异常行为有较强的针对性； * 对训练样本数量的依赖度低，较少的样本训练即可得到相对准确的模型； * 模型的可解释度高，容易确定异常检测结果的有效性。 人工特征提取的缺点： * 对安全分析人员的依赖度高，特征的选取方法会对异常检测结果的有效性产生直接影响。 深度学习优点： * 提出了一种让计算机自动学习产生特征的方法，并将特征学习融入建立模型的过程中，从而减少了人为设计特征引发的不完备。 深度学习方法局限性： * 需要有大量的训练样本进行训练，才能保证模型的准确度。 * 当训练样本数量不足时，深度学习算法将不能够对数据的规律进行无偏估计，模型的识别效果可能还不如传统基于人工特征提取的统计分析方法。 * 当前深度学习的成功应用大都集中在有大量训练样本的模式识别领域，如语音识别、图像识别、机器翻译等。 特征选择： * 命令与控制通道行为检测 * 反向连接特征（判断是不是一个流） * 心跳特征（检测数据传输的平稳度） * 获取行为检测 * 会话信息类指标。统计一台主机单位时间内不同协议类型的会话统计信息。如TCP连接次数、UDP连接次数、对应的流量、数据分组大小的均值和标准差等 * 应用分布类指标。统计一台主机单位时间内不同应用类型的访问统计信息。如访问不同应用的流量分布、次数、目标地址位置、国别分布等 * 指示位标识类指标。统计一台主机单位时间内收发的含特定协议标识位的数据分组数量及其比值。有TCP_SYN_send、TCP_SYN_ACK_receive、RST_send等标志位的会话数目；TCP_SYN_ACK_receive/TCP_SYN_send的比值；单位时间里的ICMP_T3、ICMP_Echo_Reply、ICMP_Echo_Request等报文数目 * 地址分布指标。统计一台主机单位时间内访问的IP地址网段分布、内外网分布等参数 特征值异常检测 基于主动学习的异常检测 运维人员会把自己的领域知识融入到异常检测中，针对初始的异常分数排名，给出排名靠前的样本的反馈之后，模型会根据这个反馈来重新调整参数，从而输出新的异常分数排名，目的是使运维人员感兴趣的异常排在靠前的位置，从而节约排查异常所需的时间。 损失函数： 异常样本被排在最前面，说明目前的模型是好的，损失函数的值需要减少,正常点排在前面，那么这个模型是有问题的，需要增大损失函数。 镜像下降学习算法 通过半监督学习为新KPI曲线快速部署异常检测 分析KPI曲线，尽管KPI曲线的数量众多，但是曲线的形状大体上只有少数的几类。这本质是由于，曲线的形状是由业务的类型（比如交易量，游戏在线人数，搜索）以及曲线的类型（CPU使用率，成功率）所决定的，而非集群的规模。除非是上线一个全新的业务，否则新的曲线的形状大概率会和旧曲线的形状相似。这启示作者，可以对曲线做聚类，属于同一类别的曲线，其特征空间也大致相似。属于同一类别的曲线形状相似，但是并不完全一致，在模型层面上需要有所区分。作者开始思考，是否可以用机器学习中的半监督算法来解决这个问题，既可以使用原有的label标注，提高准确率，又能够为每根新上线的曲线分配不同的模型。 ROCKA 分析曲线相似度 腾讯Metis 对于已知的故障：织云 Metis 能够综合故障数据和人工经验自动提取故障特征，以故障特征库的形式，自动匹配定位故障； 对于未知场景：织云 Metis 可根据故障特征推算出可能的原因，并在人工确认后加入故障特征库。 特征：提供三类时间序列的特征（统计特征、拟合特征、分类特征）用于对时序数据进行特征提取，在监督学习和训练中使用。支持增加自定义特征 算法： 提供常见的几种机器学习算法封装（统计判别算法、指数移动平均算法、多项式算法、GBDT和xgboost等）用于对序数据进行联合仲裁检测。 百度 阈值检测 突升突降类算法（检测均值漂移） 同比类算法（判断正态分布的均值与方差） 参数自动配置]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据存储系统]]></title>
    <url>%2F2019%2F06%2F04%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2019-06-04-%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[NFS POSIX文件系统 主要目的： * 从不同终端访问同一个目录 * 多用户共享数据 * 集中管理 * 不是处理大规模数据 设计目标1：服务器出现故障可以简单快速恢复。 Staeless(无状态)：NFS Server不保存任何状态，每个操作都是无状态的。 Idempoten(幂等性)：重复多次结果不变。（Read不改变数据；Write在相同位置写相同的数据） Server Crash Recovery：Server只用重启；Client不断重试。 设计目标2：远程文件操作性能高。 在Client cache中缓存读写的数据。 可能会造成访问冲突问题，Cache不能保证一致性。解决方法: 1. 在文件关闭时必须把缓存的已修改的文件数据写回NFS Server。 2. 每次使用缓存数据前必须检查是否已经过时（轮询操作影响性能）。 AFS Invalidation * Client 获得一个文件在server上登记 * Server 发现文件被修改向登记的Client发送一个callback * Client 收到callback删除缓存的文件 GFS/HDFS 应用层文件系统（Meta data和Data分离） Name Node（存元数据）：文件名，长度，分成多少数据块，每个数据块分布在哪些Data Node上 Data Node：存数据块 Read 打开文件时与Name node通信一次 之后的读操作直接与Data Node通信 支持并发read Write 写与Name node通信一次，返回应写的Data nodes（由Name Node决定） CLient 发送数据给Primary和secondary datanode，形成流水线，实现备份，此时写入cache中还没写进HDFS 收到写命令才把缓存写入文件系统 并发写的问题可能因为对于同一个数据块的两次操作，可能对之前的有覆盖（不支持此操作）；支持并行append。 NoSQL Dynamo 最简单的&lt;key,value&gt;模型，get/put操作 * 单节点上存储由外部存储系统实现 * 多节点间的数据分布 * Consistent hashing * Quorum (N, W, R) * Eventual consistency 一致性哈希 3副本备份 Put到Node j上的数据，要备份到Node j+1和Node j+2上，所以一个Node j上实际存储的数据是\((u_{j-3}, u_j]\)，增加或者删除节点时需要更改备份位置。 Quorum机制：实现读写的一致性 Quorum（N，W，R） * 由N个副本 * 写:保证&gt;=W个副本的写完成 * 读:读&gt;=R个副本，选出最新版本 * 如果R+W&gt;N，那么一定读到最新的数据 * R小，读效率高 * W小，写效率高 Put操作 * Client根据hash(key)得到所有N个副本所在的节点 * Client向所有N个副本所在的节点发出put * 等到至少W个节点完成的响应，就认为写成功 Get操作 * Client根据hash(key)得到所有N个副本所在的节点 * Client向所有N个副本所在的节点发出get * 等到至少R个节点的value，就必然包含最新一次写的值 Bigtable/HBase Key包括row key与column两个部分 所有row key是按顺序存储的 其中column又有column family前缀 Column family是需要事先声明的，种类有限（例如10或100） 而column key可以有很多 具体存储时，每个column family将分开存储（类似列式数据库） Get 给定row key, column family, column key 读取value Put 给定row key, column family, column key 创建或更新value Scan 给定一个范围，读取这个范围内所有row key的value Row key是排序存储的 Delete 删除一个指定的value Tablet是分布式Bigtable表的一部分 查找Tablet：三层的B+-Tree，每个叶子节点是一个Tablet，内部节点是特殊的MetaData Tablet，其包含Tablet的位置信息。 Put 写入MemTable，Append日志 MemTable满了就对其排序，生成新的SSTable，只创建一次不修改最后删除。 Get 对每个SSTable都建索引 Cassandra(Dynamo+Bigtable) 分布式协调（ZooKeeper） 多个ZooKeeper维护一组共同的数据状态，2f+1个ZooKeeper可以容忍f个节点故障。 ZooKeeper是一个简化的文件系统，树结构，可以用一条从根开始的路径确定。 Client Session：开始（Client主动连接），结束（CLient主动关闭，或者经过一个Timeout，Zookeeper没有收到通信） Watch机制：exists可以判断节点是否存在；ZooKeeper通知，通知后Watch被删除。 同步机制：请求后阻塞；异步机制：允许Client发多个请求，提供回调函数。 Zookeeper需要保证写操作串行化（由leader领导follower按照相同顺序完成，FIFO，无保证，要调用sync） ZAB（一致性协议） * Propose阶段 * Leader把一个新的txn写入本地log， 广播Propose这个txn * 每个Follower收到Propose后，写入本地log，向Leader发回Ack * Commit阶段 * Leader收到 f个Ack后，写Commit到log, 广播Commit，然后修改自己的ZooKeeper树 * Follower收到Commit消息，写Commit到log，然后修改ZooKeeper树、 * Recovery * 竞选leader（Txn ID最大的节点） * 新的leader包正确执行的Txn都正确执行，丢弃未执行的操作 ## JSON ### JSON vs Google Protocol Buffers * 相同点： * 都可以表达程序设计语言中的结构和数组 * 嵌套：JSON object, PB message/group * 数组：JSON array, PB repeated * 缺值的情况：JSON记录实际上没有规定一定要有什么域，PB optional * 不同点： * 数据类型：PB要求事先声明，JSON不需要 ### JSON vs XML * JSON；轻量，自定义格式，key-value * XML：重量，需要定义格式 Document Store Database &lt;-&gt; 数据库 Collection &lt;-&gt; Table概念 Document &lt;-&gt; 记录概念 MongoDB SQL insert create insert insert find select aggregate/group group by 不支持join join 支持index Write concern： 1. Unacknowledged: 写请求发送了，就认为完成 2. Acknowledged：MongoDB应答了收到写请求，就认为完成 3. Journaled：MongoDB把写请求记录在硬盘上的日志中，认为完成 图存储系统 Neo4j 顶点 &lt;-&gt; node 边 &lt;-&gt; relationship, 双向链表 顶点和边存储多个key-value值 &lt;-&gt; property，单向链表 对node relationship property由缓冲区]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据存储系统]]></title>
    <url>%2F2019%2F06%2F04%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2019-06-04-%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%BF%90%E7%AE%97%2F</url>
    <content type="text"><![CDATA[MapReduce 程序员写串行程序，系统并行分布式执行。 数据模型&lt;key,value&gt; * 数据由一条一条记录组成 * 记录之间无序 * 每一条记录有一个key，一个value * key可以不唯一 * key与value具体类型和内部结构由程序员决定 Map(ik,iv)-&gt;{&lt;mk,mv&gt;} Shuffle = group by mk, 对所有的map输出进行group by，相同mk的所有mv提供给Reduce Reduce(mk,{mv})-&gt;{&lt;ok,ov&gt;} JobTracker/Name Node控制协调作业的运行；TaskTracker/Data Node执行Map和Reduce的任务。 MR运行： 1. 提交作业：Map/Reduce函数，配置信息，输入输出路径。 2. Map Task读数据：Split对应一个Map Task数据块个数可能多余Mapper个数，每个Mapper可能处理多个Task，就近处理。 3. Map Task执行：对于产生的mk调用Partitioner计算对应的Reduce task id。同一个task存在同一个文件上，放在本地硬盘上，文件按照mk自小到大排序。在这一步可以使用Combiner：Combiner（mk，{mv}）-&gt; &lt;mk,mv'&gt;，减少后续传输。 4. Shuffle：Reducer从每个Map Task传输中间结果文件，进行归并实现group by 5. Reduce 图计算模型 1. 运算分成多个超步 2. 超步内并行 3. 超步间全局同步 4. 相邻超步之间存在依赖 基于顶点的编程模型 1. 每个顶点有一个value 2. 顶点为中心的运算Compute函数可以接收消息，计算，发送消息等 3. 顶点由活跃态（只对活跃态调用compute）和非活跃态（收到信息可以重新活跃） 4. 所有顶点都是非活跃态，结束图运算 Aggregator 全局统计量：每个超步内每个Worker分别进行本地的统计accumulate();超步间Master进行汇总；下一个超步Worker从Master得到上个超步的全局统计 GraphLab 单机系统 共享内存（可以立即看到完成的计算结果） 异步计算 数据模型 Data graph G=(V,E)。每个顶点和边都可以有数据。 全局数据表(SDT)，定义全局可见的数据。 顶点计算 \(Scope_v\)是顶点计算涉及的范围，运算直接访问内存，update直接修改顶点和边上的数据，修改立即可见。 共享内存 解决数据竞争的方法：一致性模型 * Full consistency：不允许其他函数访问该Scope。 * Edge consistency：update不写邻居顶点数据，但可能读，不允许其他函数会访问v及其邻边。 * Vertex consistency：只读本顶点和v邻边数据，不允许其他函数访问v本身。 PowerGraph 问题：图划分有大量的跨边 解决：把大度顶点分裂成多个，看起来有多个主节点的副本 数据流系统Storm 计算形成一个有向无环图DAG（Topology数据结构表示，每个job有一个Topology） Topology每一个顶点代表一个运算 边代表数据流动的关系 上游节点输出分发到下游： * 随机分发 * 根据tuple指定域取值进行分发 Hive(MapReduce + SQL) 数据存在HDFS Table是一个单独的hdfs目录 Table进一步划分为Partition Partition可以进一步划分为Bucket HDFS不支持修改：Insert是append操作；overwrite是删除然后新创建操作 内存处理 去除I/O开销，提高处理速度 挑战：内存墙（解决：减少cache miss；预取指令降低cache miss对性能的影响） MonetDB系统 内存键值系统 Memcached 单机内存键值对系统，hashtable形式 Redis 分布式内存键值对，hash，list，sets，sorted sets等 Spark 解决MapReduce中多个运算采用同一个数据时，代价太高的问题 思路：把数据放入多台机器的内存，避免HDFS开销 基础数据结构RDD Transformation（RDD-&gt;RDD） Action（RDD-&gt;计算结果） 读入内存一次可以多次处理 Spark SQL DataFrame：可以看作RDD定义Relational Schema Spark Streaming 输入的数据流转化成一个个minibatch，在mininbatch上运算]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关系数据库]]></title>
    <url>%2F2019%2F06%2F03%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2019-06-03-%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[大数据的概念(三个重要挑战) 1. 数据量巨大(Volumn) 2. 数据的产生 速度、更新速度快(Velocity) 3. 数据种类繁多(Variety) 大数据管理系统： 1. 关系型（Oracle，DB2，MS SQL） 2. 云平台（MapReduce，Apache Hadoop，MS Dryad） 3. 云平台+SQL（Apache Hive） 4. No-SQL（Apache Hbase，MongoDB，Neo4j） 5. 图数据处理（Google Pregel，Apache Giraph，Graphlab） 6. 内存数据处理（MMDB，Spark） ACID： 1. 原子性（Atomicity） 2. 一致性（Consistency） 3. 隔离性（Isolation） 4. 持久性（Durability） ----- 关系型数据库 Table/Relation(表) 列：一个属性，有明确的数据类型 行：一个记录 通常很瘦长 原子类型（无内部嵌套结构，不能用struct、class、array、list、set、map等） Scheme vs Instance Scheme：一个表的类型是由每个列的类型决定的 Instance：具体取值，由具体应用决定 Scheme定义一次对应多个instance Key Primary key主键确定本表中的一个记录(可以是多个键的组合)； Foreign key外键唯一决定另一个表的记录； SQL create table 表名 (列名 类型,列名 类型,列名 类型,…… ,primary key(ID) -&gt; 声明主键，可以包含多个属性foreign key(CourseId) references Course(ID),foreign key(StudentId) references Student(ID) -&gt; 声明外键，可以有多个);插入完整记录：insert into Studentvalues (131234, ‘张飞’, 1995/1/1, M, ‘计算机’, 2013, 85);插入记录特定的列，其它列为空：insert into Student(ID, Name)values (131234, ‘张飞’);删除记录delete from Studentwhere ID = 131234;更新update Studentset GPA = 86where ID = 131234选择（从一个表中提取一些行）select *from 表名where 条件（多个条件可以用and,or,()进行组合）投影（从一个表中提取一些列）select 列名，...列名from 表名选择+投影select Name,GPAfrom Studentwhere Major="计算机"连接(Join)select Student.Name, Course.Namefrom Student, Course, TakeCoursewhere TakeCourse.CourseId = Course.ID and TakeCourse.StudentID = Student.ID;分组统计(group by)select Major, count(*)from Studentwhere Year &gt;= 2013 and Year &lt;= 2014group by Major;过滤(Having,在group by基础上选择)select Major, count(*) as Cntfrom Studentwhere Year &gt;= 2013 and Year &lt;= 2014group by Majorhaving Cnt &gt;= 2;排序(Order by,desc减少，asc增加)select Major, count(*) as Cntfrom Studentwhere Year &gt;= 2013 and Year &lt;= 2014group by Majororder by Cnt desc; RDBMS(关系型数据库系统) 系统架构 * SQL Parse:SQL语句的程序（语法解析，表名，列名，类型检查） * Query Optimizer：SQL内部表达（产生可行的query plan选最佳） * Data storage and indexing（如何在硬盘上存储访问数据） * Buffer pool：在内存中缓存硬盘数据 * Execution Engine：（根据query plan完成相应的运算和操作） * Transaction management：事务管理（ACID，logging日志加锁，保证并行事务正确性） 数据库 vs 文件系统 文件系统 数据库 存储文件 存储数据表 通用的 专用的 文件无结构，由一串字节组成 由记录组成，每个记录有多个属性 操作系统实现 用户态程序实现 提供编程接口 提供SQL接口 相同点：数据存储在外存；数据分成定长数据块 RDBMS最小存储单位database page size Tuple可以存储变长的列,主要就是利用指针把边长空间放到后面 数据的顺序访问会造成性能问题，所以采用有选择的访问 索引 * Tree based index：有序，支持点查询和范围查询（每个叶子节点是一个page，内部节点索引用） * Hash based index：无序，只支持点查询（每个bucket是一个page，\(O(log_2^N)\)） * 主索引：记录存在index中，顺序为index顺序 * 二级索引：index存page ID和in-page tuple slot ID 数据访问有空间和时间局部性 buffer pool如果在替换时没有空闲frame，找到已缓存的page（LRU）被修改过需要写回硬盘 LRU的实现： 1. 时间戳最小的页\(O(n)\) 2. 循环链表，当一个页被访问放到链表最前端，然后替换最后一个页\(O(1)\)(修改队列代价大且多线程需要共享队头) 3. Clock算法：访问R=1；旋转R==1-&gt;R=0;R==0选中。（说明在旋转一圈时间里都没有被访问） Operator Tree 每个节点代表一个运算；输入来自孩子节点；输出送往父节点。 Selection:行过滤（比较操作、数学运算、逻辑运算） Projection:列提取（从记录中提取属性生成结果记录） Join Nested loop（双重循环，总共读\(M_R+BM_RM_S\)） Block Nested Loop Join(在外循环每次读入M页的R而不是一条R记录，减少了内循环总共读\(M_R+M_RM_S/M\)) Index Nested Loop Join(设置一个中间index用来检索S表，当很少有匹配时效率较高) Hashing（读R建立Hash table，读S访问hash table找到所有的匹配；当R大于内存可以分为小块，由于匹配的记录hash值相同因此必然存在与对应的块中，块id=hash(join key)%分块数量。总共读\(2M_R+2M_S\)个page，写\(M_R+M_S\)个） Sort Merge Join（先排序，后merge） Sorting 事务的正确性：存在一个顺序，按照这个顺序依次串行执行这些Transactions，得到的结果与并行执行相同。 数据冲突引起的问题： * 读脏数据（写读） * 不可重复读（读写） * 更新丢失（写写） 解决方案： * 悲观：假设数据竞争可能经常出现；防止竞争的出现（等待） * 乐观：假设数据竞争很少见；先执行然后提交前检查是否没有数据竞争 加锁： 对每个访问的数据都要加锁后才能访问，commite前集中解锁。 * 共享锁(S)：保护读操作 * 互斥锁(X)：保护写操作 * IS(a):将对a下面更细粒度的数据元素进行读 * IX(a):将对a下面更细粒度的数据进行写 下面这个图分四个2*2观察，只有左上角全绿，其余三个时一样的。 循环等待时的deadlock(死锁) 死锁避免：规定lock对象顺序，按照顺序请求lock，适用于lock少的情况。由于数据库lock多不适合该方法。 死锁检测：对长期等待的事务检查，如果有死锁则对环上任意一个事务丢弃处理。 乐观的并发控制：读；验证；写。（冲突多时可能要不断重试浪费资源） Snapshot Isolation：在起始点snapshot数据先临时保存commit检查冲突。 事务日志：记录一个写操作的全部信息 1. 写操作：产生一个事务日志记录 2. Commit：产生一个commit日志记录 3. Abort：产生一个abort日志记录 Write-Ahead logging：先logging后实际操作。先记录commit日志然后在commit。 WAL的持久性：出现掉电可以回溯日志，寻找commit日志。必须保证日志记录先于修改后的数据出现在硬盘上。 checkpoint：使崩溃恢复时间可控。 崩溃恢复： 1. 检查 2. 找到最后一个检查点 3. 找到日志崩溃点 4. 确定崩溃时的活跃事务和脏页 5. REDO阶段 6. 找到脏页最早的LSN 7. 从LSN正向读取日志 8. 如果日志涉及的页不在脏页中跳过，数据页LSN&gt;=日志的LSN跳过；否则修改数据页。 9. UNDO阶段 10. 对于所有在崩溃时活跃的事务找到最新LSN，通过反向链表读取其所有日志记录。 11. 如果数据页LSN&gt;=日志LSN，才进行undo 数据仓库 事务处理 少数数据分析操作 大量并发transactions 每个操作访问大量数据 访问很少数据 读 读写 OLAP(联机分析处理) 数据仓库的基础。基本数据模型：多维矩阵。称为数据立方。 常用操作： * rollup（上卷-&gt;在某维度从细粒度到粗粒度）， * drill down（下钻-&gt;从粗粒度到细粒度） * slice（切片-&gt;在某一维上选一个值） * dice（切块-&gt;在多维上选多个值） 行式数据存储：每个记录中所有的列都相邻存放。多个列通过一个I/O得到 列式数据存储：每个列产生一个文件，（因为大部分情况只涉及一个表的少数几列，数据更容易压缩，拼装代价大） 系统架构 划分：把数据分布在多台服务器上machine Id=hash(key) % MachineNumber。对与join操作，如果划分key等于join key可以直接进行；如果不是需要在join key进行一次划分然后再join。 2-phase commit 1. Coordinator 向每个participant 发送query to commit消息，participant根据本地情况回答yes/no。 2. 当所有回答为yes进行commit，participant发送acknowledgment 3. 至少一个回答no进行abort]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F05%2F30%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%2F~%2419-05-28-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(2)%2F</url>
    <content type="text"><![CDATA[liufr                                                 l i u f r   �数只在事件结束时离线更新, 那么所有的更新量等    ���    ��� r��P ��  �]]></content>
  </entry>
  <entry>
    <title><![CDATA[强化学习(3)]]></title>
    <url>%2F2019%2F05%2F29%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%2F2019-05-29-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(3)%2F</url>
    <content type="text"><![CDATA[在策略学习根据策略\(\pi\) 产生的样本来学习关于\(\pi\)的相关知识 离策略学习根据另一个策略\(\mu\)产生的样本来学习关于\(\pi\)的相关知识(智能体观察人；重复利用旧策略；探索性策略学习最优策略；单一策略去学习多个策略) \(\epsilon-贪心探索\):以\(1−\epsilon\)概率选择贪心动作 以\(\epsilon\)概率随机选择一个动作 \(\epsilon-贪心策略提升\)给定任意\(\epsilon\)-贪心策略\(\pi\), 根据 \(q_{\pi}\) 构造出新的 \(\epsilon\)-贪心策略 \(\pi′\) 具有 更好的性能, 即 \(v_{\pi′}(s) ≥v_{\pi}(s)\) 无限探索, 无穷时刻收敛为贪心策略（GLIE）的含义是:智能体能够无限次数地探索所有的状态-动作对;策略在无穷时刻收敛到贪心策略。 GLIE蒙特卡洛控制：能够收敛到最优动作 -价值函数, \(Q(s,a) \rightarrow q∗(s,a)\) 使用策略\(\pi\)采集第\(k\)次事件: \({S_1,A_1,R_2,...,S_T}∼ \pi\) 对事件中的每个状态 \(S_t\) 和动作 \(A_t\):\(N(S_t,A_t)\leftarrow N(S_t,A_t)+1;Q(S_t,A_t)\leftarrow Q(S_t,A_t)+\frac{1}{N(S_t,A_t)}(G_t-Q(S_t,A_t))\) 基于新得到的动作-价值函数对策略进行提升\(\epsilon \leftarrow \frac{1}{k};\pi \leftarrow\epsilon-greedy(Q)\) Sarsa(S,A,R,S',A') 基于样本的TD更新 \(Q(S,A) \leftarrow Q(S,A) + \alpha(R+ \gamma Q(S^′,A^′)−Q(S,A)\) 任意初始化 \(Q(s,a)\), 令 \(Q(S_{terminal},\cdot) = 0\) repeat {在每次事件中:} 初始化 S 根据从 Q 提取的策略 (例如 \(\epsilon\)-贪心策略) 对 S 选择动作 A repeat {对事件中的每一时刻} 执行动作 A, 观察 \(R,S′\) 根据从 Q 提取的策略 (例如 \(\epsilon\)-贪心策略) 对 S′ 选择动作 A′ \(Q(S,A) \leftarrow Q(S,A) + \alpha(R+ \gamma Q(S^′,A^′)−Q(S,A)\) \(S\leftarrow S^′, A\leftarrow A^′\) until S 是终止状态 until Sarsa vs MC * MC可能无法达到终止状态（例如学习到呆在原地不动） * Sarsa每一步都在学习，转向其他策略 一步 Sarsa vs Sarsa(\(\lambda\)) * 一步 Sarsa 只对最终导致高奖励的最后一步动作强化它的价值 * 资格迹方法能够对事件中的多个动作强化它们的价值,步数增加强化幅度减小；衰减率\(\gamma\lambda\) Q-学习 考虑基于动作-价值 Q(s,a) 的离策略学习 不再使用重要性采样 智能体下一时刻执行的动作是由行为策略产生\(A_{t+1} ∼ \mu(\cdot|S_t)\) 但是学习算法考虑的是由另一个目标策略产生的后继动作 \(A^′ ∼ \pi(\cdot|S_t)\) 更新 \(Q(S_t,A_t)\) 向另一个后继动作的价值逼近 \(Q(St,At) \leftarrow Q(S_t,A_t)+\alpha(R_{t+1} + \gamma Q(S_{t+1},A^′)−Q(S_t,A_t))\) 任意初始化 Q(s,a), 令 \(Q(Sterminal,\cdot) = 0\) repeat {在每次事件中:} 初始化 S repeat {对事件中的每一时刻} 根据从 Q 提取的策略 (例如 \(\epsilon\)-贪心策略) 对 S 选择动作 A 执行动作 A, 观察 R,S′ \(Q(St,At) \leftarrow Q(S_t,A_t)+\alpha(R_{t+1} + \gamma Q(S_{t+1},A^′)−Q(S_t,A_t))\) \(S\leftarrow S^′\) until S 是终止状态 until 对于悬崖问题： * Q-学习：最优路径；Sarsa安全路径（考虑到了随机探索） * 即使 Sarsa 学到的安全路径比 Q-学习的最优路径行走步数要长, 但是每次获得的奖励和却比 Q-学习的高 利用: 根据当前的信息做出最佳的决策； 探索: 采样更多的信息 想要做出长期的最佳决 对于Q学习来说，\(\epsilon=0\)学习结果容易陷入局部最优；\(\epsilon\)过大探索整个空间，降低回报。探索率随时间衰减 \(\epsilon\)贪心根据动作-价值决定动作被选中的概率]]></content>
      <categories>
        <category>RL</category>
      </categories>
      <tags>
        <tag>RL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强化学习(2)]]></title>
    <url>%2F2019%2F05%2F28%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%2F2019-05-28-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(2)%2F</url>
    <content type="text"><![CDATA[动态规划 通过把原问题分解为相对简单的子问题来求解复杂问题 马尔可夫决策过程满足如下两个属性 * 贝尔曼方程具有递归形式 * 价值函数可以保存和重复利用 贝尔曼最优方程如下,其难点是\(v_*\)同时存在于等式左右两边 \[ v_*(s)=max_a(R_s^a+\gamma \sum_{s&#39;\in S}P_{ss&#39;}^av_*(s&#39;)) \] 价值迭代的基本思路: 1. 对\(v_∗\)定义一个估计函数\(v\) 2. 将估计函数代入方程右边, 等式左边得到一个新函数\(v′\) 3. \(v′\) 是对 \(v_∗\) 更为准确的估计 4. 将 \(v′\) 代入右式继续上述过程 \[ v&#39;(s)=max_a(R_s^a+\gamma \sum_{s&#39;\in S}P_{ss&#39;}^av(s&#39;)) \] 价值迭代算子定义一个以函数作为输入的算子\(\tau\), 对给定的函数\(v_k\)计算新的函数 \(v_{k+1}(s)=[\tau(v_k)](s)\),贝尔曼最优方程写成 \[ v_*(s)=[\tau(v_*)](s)=max_a(R_s^a+\gamma\sum_{s&#39;\in S}P_{ss&#39;}^av_*(s&#39;)) \] \(\gamma &lt; 1\) 时, 价值迭代算子是一个收缩算子(\(||\tau(f-g)||_{\infty}&lt;||f-g||\)) 确定性策略：价值迭代找到最优策略；随机性策略：机器人在所有位置以相同的概率向左或向右。 策略迭代： 给定一个初始策略 π1, k = 1 loop 策略评估: 对当前策略 πk 计算它的价值函数 \(v_{πk}(s) = \mathbb E[R_{t+1} + \gamma R_{t+2} + ...|_St = s,A_t ∼ π_k(St)] =\sum_a π_k(a|s)(R^a_{ss&#39;} + \gamma P^a_{ss′}v_{πk}(s′))\) 策略提升: 根据 \(v_{πk}\) 提取出新的策略 \(π_{k+1}(s) = argmax_{a\in A}(R^a_s + \gamma \sum_{s′\in S} P^a_{ss′}v_{πk}(s′))\) k←k+ 1 end loop 价值迭代 vs 策略迭代 价值迭代 1. 只在收敛得到 \(v∗\) 后计算 \(π∗\), 中间过程不产生策略 2. 涉及赋值操作, 计算量小, \(O(|S|^2|A|)\) 3. 迭代次数多 策略迭代 1. 每次迭代开始时给定一个 \(π\), 结束时产生一个新 \(π′\) 2. 求解方程, 计算量大, 矩阵求逆 \(O(|S|^3)\), 策略提升 \(O(|S|^2|A|)\) 3. 迭代次数少 异步动态规划对每个状态单独更新价值函数值, 可以以任意一种顺序选择被更新的状态 只对被选中的状态更新价值, 未选中的保持不变 就地价值迭代只对整个状态集存储一个价值函数, 优化动态规划对拥有最大贝尔曼误差的状态更新价值。 实时动态规划 只考虑与智能体直接相关的状态 策略评估的不足：对模型的依赖\(R,P\)(MDP 问题的模型已知/智能体对环境建模) 蒙特卡洛方法MC MC 方法直接从经历过的事件中学习 无模型方法: 不需要 MDP 的转移/奖励函数 从完整的事件中学习: 没有自举 基于最简单的思想: 价值 = 平均回报 运行 MC 方法通常要求: 所有事件都到达终止状态或者事件的时序足够长 目标: 从策略 \(\pi\) 产生的事件中学习 \(v_{\pi}\) \(S_1,A_1,R_2,...,S_k ∼ \pi\) 回忆下回报的定义是所有折扣奖励和 \(G_t = R_{t+1} + \gamma R_{t+2} +···+ \gamma^{T−1}R_t\) 回忆下价值函数的定义是回报的期望 \(v_π(s) = \mathbb E \pi[G_t|S_t = s]\) 蒙特卡洛策略评估方法使用回报的经验均值作为回报的期望 每次经过的 MC 策略评估 * 为了评估状态 s * 对一次事件中每一次经过状态 s 的时刻 t * 计数加一 \(N(s) \leftarrow N(s) + 1\) * 全部回报相加 \(S(s) \leftarrow S(s) +G_t\) * 估计的价值等于回报均值 \(V(s) = S(s)/N(s)\) * 同样当 \(N(s) \rightarrow \infty\) 时, \(V(s) \rightarrow v_π(s)\) P75 怎么算？？？？ MC可以使用增量计算\(V(S_t)\leftarrow V(S_t)+\frac{1}{N(S_t)}(G_t-V(S_t))\) 时间差分学习TD TD 方法直接从智能体经历的事件中学习 无模型的: 不知道 MDP 问题的转移和奖励函数 可以从非完整的事件中学习, 借助自举法 根据一个猜测值更新另一个猜测值 TD学习算法： * 调整价值 \((S_t)\) 向估计的回报 \(R_{t+1} + \gamma V(S_{t+1})\) 逼近 \(V(S_t) \leftarrow V(S_t) + α(R_{t+1} + \gamma V(S_{t+1})−V(S_t))\) * \(R_{t+1} + \gamma V(S_{t+1})\) 称为TD 目标 * \(\delta_t = R_{t+1} + \gamma V(S_{t+1})−V(S_t)\) 称为TD 误差 MC 与 TD 对比 * TD 可以在智能体运行过程中的每一步在线学习； MC 需要完整的事件序列计算出回报后学习 * TD 可以从不完整的事件序列中学习， MC 要求事件达到终止状态或序列足够长 * TD 是 低方差, 有偏差；MC 是 高方差, 零偏差 * TD 能够利用马尔可夫性，因此在马尔可夫环境下更有效； MC 能利用马尔可夫性因此在非马尔可夫环境下更有效（只考虑reward） P90 AB问题：假如应用MC算法，由于需要完整的episode，因此，只有episode 1 能够用来计算A的状态值，所以显然，V(A) = 0；同时B状态的价值为6/8。而对于TD算法来说，由于状态A的后继有状态B（A-&gt;B是100%；B-&gt;1是75%），所以状态A的价值是通过状态B的价值来计算的。所以根据上面TD的计算公式，V(A)=V(B) = 6/8 自举法 : 更新时包含一个猜测量；采样法 : 使用采样的数据计算期望 * MC 不使用自举，使用采样 * DP 使用自举，不使用采样 * TD 使用自举，使用采样 \(\lambda -回报\)： 每项的权重\((1-\lambda)\lambda^{n-1}\)前向更新 \[ G_t^{\lambda}=(1-\lambda)\sum_{n=1}^{\infty}\lambda^{n-1}G_t^{(n)}\\ V(S_t)\leftarrow V(S_t)+\alpha(G_t^{\lambda}-V(S_t)) \] 资格迹：受频率启发；受近因启发（二者结合）更新量与 TD 误差 和资格迹 \(E_t(s)\) 呈正比 后向更新 \[ \delta_t = R_{t+1}+\gamma V(S_{t+1})-V(S_t)\\ V(s)\leftarrow V(s) + \alpha\delta_tE_t(s) \] TD(1) 大致等价于每次经过的 MC 方法,误差会随在线运行逐步累积,如果价值函数只在事件结束时离线更新, 那么所有的更新量等同于 MC 方法]]></content>
      <categories>
        <category>RL</category>
      </categories>
      <tags>
        <tag>RL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强化学习(1)]]></title>
    <url>%2F2019%2F05%2F27%2F%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%2F2019-05-27-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(1)%2F</url>
    <content type="text"><![CDATA[强化学习考虑的是序贯决策过程(智能体处在特定的环境中产生一系列的动作，而环境能够根据这些动作改变智能体的当前状态。) 根据环境反馈的奖励，调整智能体的行为策略，提升智能体 实现目标的能力。 强化学习是基于奖励假设：所有的目标都可以通过最大化期望累加奖励实现 强化学习 监督/非监督学习 产生的结果能够改变数据的分布 产生的结果 (输出) 不会改变数据的分布 最终的目标可能要很长时间才能观察到 结果是瞬时的 没有明确的标签数据 要么有明确的标签数据 (SL) 根据当前的奖励，实现长远的目标 要么完全没有任何标签数据 (USL) 马尔科夫性(RL主要研究的问题) 智能体未来的状态只与当前时刻的状态\(S_t\)有关, 而与过去的状态\({S_1,...,S_{t−1}}\) 无关，那么称智能体的模型具有马尔可夫性。 对于一个马尔可夫状态 \(s\) 和后继状态 \(s′\)，状态转移概率定义为\(P_{ss&#39;} = \mathbb{P}[S_{t+1}=s&#39;|S_t=s]\),状态转移矩阵定义为 \[ P = from\begin{bmatrix} P_{11}&amp;...&amp;P_{1n} \\ ... &amp; \\ P_{n1} &amp;... &amp; P_{nn} \end{bmatrix} \] 其中矩阵的每一行和均为1。 markov 马尔科夫奖励过程=马尔科夫链+奖励（\(&lt;S,P,R,\gamma&gt;\),\(S\)有限状态集\(P\)状态转移概率矩阵\(R\)奖励函数\(\gamma\)折扣因子） 回报\(G_t = R_{t+1}+\gamma R_{t+2}+... = \sum_{k=0}^\infty \gamma^kR_{t+k+1}\)，这种定义形式更重视近期的奖励，忽视远期的奖励，且\(\lambda\)越大回报越长远。 状态价值函数 等于从状态s出发的期望回报 \(v(s)=\mathbb{E}[G_t|S_t=s]\)，分为瞬间奖励\(R_{t+1}\)以及后续状态的折扣价值\(\lambda v(S_{t+1})\) \[ v(s) = \mathbb{E}[G_t|S_t=s] =\mathbb{E}[R_{t+1}+\lambda v(S_{t+1})|S_t=s]\\ v(s) = R_s + \gamma \sum_{s&#39;\in S}P_{ss&#39;}v(s&#39;) \] 矩阵形式的贝尔曼方程 \[ v = R + \lambda Pv; v=(I-\lambda P)^{-1}R \] 马尔可夫决策过程\(&lt;S,A,P,R,\lambda&gt;\)(A有限动作集) 一个强化学习的智能体可能包括如下一个或多个元素 * 确定性/随机性策略：智能体的行为(状态到动作的映射)，与历史无关，静态性\(A_t\sim\pi(\cdot|S_t),\forall t&gt;0\) * 价值函数（值函数、性能指标函数）：智能体在某一状态和/或某一动作时是好还是坏 * 模型：智能体对真实环境的估计，预测下一时刻的状态\(P_{ss&#39;}^a\)和奖励\(R_s^a\) 策略 ： 状态到动作的一种分布\(\pi (a|s)=\mathbb{P}[A_t=a|S_t=s]\),马尔科夫奖励过程\(&lt;S,P^{\pi},R^{\pi},\lambda&gt;,P_{ss&#39;}^{\pi} = \sum_{a\in A}\pi (a|s)P_{ss&#39;}^a,R_s^{\pi}=\sum_{a\in A}\pi(a|s)R_s^a\) 状态-价值函数 从状态s出发, 在策略 \(\pi\) 作用下的期望回报\(v_{\pi}(s)=\mathbb{E}_\pi[G_t|S_t=s]\) 动作-价值函数 从状态s出发, 首先执行动作 a, 然后在策略\(\pi\)作用下的期望回报\(q_\pi(s,a)=\mathbb E_{\pi}[G_t|S_t=s,A_t=a]\) 最优价值函数(智能体在MDP问题下最好的性能，表示该问题可解) 最优状态-价值函数在所有策略中价值最大的\(v_*(s)=max_{\pi}v_{\pi}(s)\) 最优动作-价值函数在所有策略中动作价值函数最大的\(q_*(s,a)=max_{\pi}q_{\pi}(s,a)\) 总是存在一个最优策略，通过最大化\(q_*(s,a)\)来确定 \[ \pi_*(a|s)\left\{\begin{matrix} 1 &amp; if\ a=argmax_{a\in A}q_*(s,a)\\ 0 &amp; otherwise \end{matrix}\right. \] 强化学习目标是找到一组时间序列的动作\(\{A_0,A_1,...\}\)，使得智能体从\(S_0\)出发得到的期望累加奖励最大化\(v*(s_0)=\mathbb E[max_{A_0,A_1,...}(R_1+\lambda R_2+\lambda^2R_3...)]\) 最优策略性质：以第一步决策所形成的阶段和状态作为初始条件来 考虑时，余下的决策对余下的问题而言也必构成最优策略]]></content>
      <categories>
        <category>RL</category>
      </categories>
      <tags>
        <tag>RL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[互联网搜索与排序]]></title>
    <url>%2F2018%2F12%2F05%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%2F2018-12-05-%E4%BA%92%E8%81%94%E7%BD%91%E6%90%9C%E7%B4%A2%E4%B8%8E%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[向量空间模型（VSM） 将查询字符串表达为带权重的tf-idf向量(查询向量) 类似,将文档字符串表达为带权重tf-idf向量(文档向量) 计算查询查询向量和文档向量的余弦相似度 将文档按照其与查询的相似度分值从大到小进行排序 返回前K个(e.g.,K=10)文档并展示给用户 tf-idf 衡量某一个词在文档中的重要性 tf(w,d):term frequency 词w在d中出现的次数，tf值越大，w在文档d中越重要。 df(w): document frequency 整个数据集中，包含w文档的个数，df越大，w越不重要。 idf(w): inverse document frequency \(idf = log \frac{N}{df}\) 其中N为文档集的个数 tf-idf(w,d) = tf(w,d)*idf(w) BM25(Best match 25) \[ BM25 = \sum_{i \in q} \log\frac{N}{df_i} \cdot \frac{(k_1+1)tf_i}{k_1((1-b)+b\frac{dl}{avdl})+tf_i} \] avgdl:集合中平均文档长度 \(k_1\):控制因\(tf\)的增大最终排序值的速度 k1=0:二值模型,只反映词是否出现,不考虑出现次数 k1无穷大:反映真正的tf值 b:控制文档长度归一化程度 b=0:不考虑文档长度对最终分值的影响 b=1:考虑文档长度平均文档长度的相对值 经验值:k1=1.2~2,b=0.75 在上述公式中，文档长度定义为\(dl = \sum_{i\in V}tf_i\)，文档长度归一化部分为\((1-b)+b\frac{dl}{avdl}, 0\leq b \leq 1\) 当\(b=0\)时，不进行归一化，当\(b=1\)时，全文档进行归一化。 排序评价指标 P@K(Precision at K) 设置一个排序位置K 前K个位置相关文档所占的比例 忽略K位置之后的所有值 MAP(Mean average precision) 只考虑出现过相关文档的位置 DCG(Discounted Cumulative Gain) Gain: 文档对用户Gain与其查询相关度有关，\(2^{label}-1\)，其中\(label\)取值如bad(0),fair(1),good(3),excellent(7),perfect(15)等，也就是说Gain是一个指数函数，效果越好影响越大。 Discounted Cumulative Gain：由于返回结果有一个排序，因此根据所在排序还需要一定的打折\(\frac{1}{log_2(rank+1)}\) 比较二者那么 CG@N \(CG=r_1+r_2+...+r_n\) NCG@N \(NCG= \frac{r_1}{\log(1+1)} + \frac{r_2}{\log(1+2)}+...+\frac{r_n}{\log(1+n)}\) NDCG(Normalized DCG) 利用最优排序对DCG@N进行归一化处理，其中最优排序为按照用户标注对文档进行排序。其中\(IDCG_p\)为理想情况下最大的\(DCG\)值。 \[ nDCG_p = \frac{DCG_p}{IDCG_p} \] Pair-wise排序学习：区分文档间的差异 核心思想：模型只需要区分同一个查询内部标注为不同相关度文档间的差异 排序支持向量机（ranking SVM） Ranking SVM 训练 构造训练数据集合\(\{\phi(q_k,d_{ki})-\phi(q_k,d_{kj}),+1\}\) 训练二值分类SVM，得到打分函数\(f(q,d)=&lt;w,\phi(q,d)&gt;\) Ranking SVM 在线应用 给定一个查询q和检索出的文档集合\(C=\{d_i\}\) 用\(f(q,d)\)对每一个C中的文档进行打分 将C中的文档按照\(f(q,d)\)从大到小排序 优点 * 只关注文档间的差异性，解决了查询的差异化问题 * 实际应用效果良好 缺点 * N个文档有\(O(N^2)\)文档有序对，复杂度高 * 没有考虑浏览特性 * 违背分类训练数据独立同分布假设 语言排序模型 词袋假设\(P(w_1,w_2,...w_m)=P(w_1)P(w_2)...P(w_m)\) 估计每一个词的出现概率\(P(w)=\frac{#w}{all\,words}\)，其中\(\sum_{w\in V}P(w)=1\) 语言模型中的马尔科夫假设，\(P(w_n|w_{n-1},w_{n-2},...,w_1)=P(w_n|w_{n-1})\) \(P(w_1,w_2,...,w_m)=P(w_1)P(w_2|w_1)P(w_3|w_2)...P(w_m|w_{m-1})\) 给定一个训练文档集合，统计给个一个词之后，其他词出现的概率\(P(w_i|w_j)=\frac{#(w_jw_i)}{#w_j}\) 举例来说\(\sum_{w_i\in V}P(w_i|&#39;is&#39;)=1\) 数据稀疏问题 对于0概率问题采用平滑化方法 LM for IR 定义生成模型的细节 估计模型参数\(P(w|d)\) 平滑化，防止零概率 将文档对应的生成模型应用于查询，计算生成概率 按照生成概率将文档排序，取topN展现给用户 给定查询\(q\)和文档\(d\)，对文档的打分为\(P(d|q)\)根据贝叶斯公式 \[ P(d|q) = \frac{P(q|d)P(d)}{P(q)} \] 对于独立假设来说\(P(q|d)=P(q_1q_2,....q_m|d)=\Pi_{i=1}^MP(q_i|d)\) 举例： \(q\) 中国_科学院_大学 \(d\) 科学院_大学_计算机_学院 \(P(q|d)=P(中国|d)P(科学院|d)P(大学|d)=0*0.25*0.25=0\) Dirichlet 平滑 与混合平滑 D={d1,d2}, Query q: Michael Jackson d1: Jackson was one of the most talented entertainers of all time（11） d2: Michael Jackson anointed himself King of Pop（7） \(P(q|d_1)=\frac{0}{11}*\frac{1}{11}=0,P(q|d_2)=\frac{1}{7}*\frac{1}{7}=\frac{1}{49},P(Michael|C)=\frac{1}{18},P(Jackson|C)=\frac{2}{18}\) 混合模型\(\lambda=0.5\) \(P_{mix}(q|d_1)=(\frac{0}{11}*\frac{1}{2}+\frac{1}{18}*\frac{1}{2})*(\frac{1}{11}*\frac{1}{2}+\frac{2}{18}*\frac{1}{2})\) \(P_{mix}(q|d_2)=(\frac{1}{7}*\frac{1}{2}+\frac{1}{18}*\frac{1}{2})*(\frac{1}{7}*\frac{1}{2}+\frac{2}{18}*\frac{1}{2})\) 狄里克莱平滑\(\mu = 5\) \(P_{dir}(q|d_1)=(\frac{0+\frac{5}{18}}{11+5})(\frac{1+5*\frac{2}{18}}{11+5})\) \(P_{dir}(q|d_2)=(\frac{1+\frac{5}{18}}{7+5})(\frac{1+5*\frac{2}{18}}{7+5})\)]]></content>
      <categories>
        <category>Data mining</category>
      </categories>
      <tags>
        <tag>Data mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大规模机器学习]]></title>
    <url>%2F2018%2F12%2F05%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%2F2018-12-05-%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[百万级别的数据样本：指数级别的算法基本告别了 十亿级别的数据样本：开始考虑分布式存储 万亿级别的数据样本：无法得知数据全貌，采用Peer-to-peer（机器处理本地的数据无总控） 理解机器学习 从优化的角度看机器学习 \[ \arg max_{\vec{\theta}} \equiv \mathcal{L}(\{x_i,y_i\}_{i=1}^N;\vec{\theta})+ \Omega(\vec{\theta}) \] 其中\(\mathcal{L}\)是一个模型（经验风险），\(x_i,y_i\)代表的是数据，\(N\)是数据规模，\(\vec{\theta}\)代表参数（结构风险），有参数就是有偏估计，方差小，有更好的泛化能力。然后通过迭代求解： \[ \vec{\theta}^{t+1}=g(\vec{\theta}^t,\Delta_f \vec{theta}(\mathcal{D})) \] 其中后一项为模型参数的梯度计算，用于迭代与修正，梯度如果各项独立通常可以并行，即每台电脑可以算本地的，然后多台机器合并，显而易见的是模型并行数据一定并行。 这里的数据与参数都是稀疏的，只拉入必要的参数即可，即使参数有误，也可以在最后收敛。 参数更新方案 同步更新 同步更新特点 设置同步点，通常每一轮迭代至少一个同步点 同步点等候所有节点完成任务，统一更新参数 更新后进入下一轮迭代 最大程度模拟序列计算 与序列计算结果基本一致 与序列计算具有同样的理论保障 同步更新缺点 低效 网络速度慢，延迟大 配置相同的机器计算速度不一致导致等待 与机器的即时状态有关 与需要处理的数据有关 异步更新 异步更新缺点 本地数据不全面：单个节点只有部分数据，独立更新参数从总体看结果不正确 不同的机器执行的更新次数有很大的差异 参数互相依赖：下一轮的梯度计算可能依赖上一轮所有的正确参数值 参数过期：本轮更新的参数的梯度不是最新的参数的梯度 半同步更新 半同步更新特点 设置执行最快和最慢的节点间轮数的最大差异 比同步块，比异步准确]]></content>
      <categories>
        <category>Data mining</category>
      </categories>
      <tags>
        <tag>Data mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无监督学习 Unsupervised Learning(聚类、矩阵分解、话题模型)]]></title>
    <url>%2F2018%2F12%2F03%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%2F2018-12-03-%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[聚类 K-means 输入：数据D=&#123;x1,x2,...,xn&#125;,簇数目K1. 随机选取K个种子数据点（seeds）作为K个簇中心2. repeat3. foreach x in D do4. 计算x与每一个簇中心的距离5. 将x指配到距离最近的簇中心6. endfor7. 用当前的簇内点重新计算K个簇中心位置8. until（达到终止条件） 优点： * 简单：易于理解和实现 * 高效：时间复杂度为O(TKN)，其中T为运行轮数，K为簇数目，N为样本数 缺点： * 局部最优解：每一个数据点贪心选择距离最近的中心，不同初始中心可能得到不同的族 * 平均值点一般来说要求为数值型，对于类别型特种不适应 * 用户指定K，提前难以预知 * 离群点敏感（可能为数据准备，预处理过程中出现的错误） 矩阵分解 SVD分解 \[ D = \sum_{k=1}^p\sigma_k\mu_kv_k^T=U {\tiny \sum} V^T \] \({\tiny \sum}=\begin{bmatrix} \sigma_1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; \sigma_2 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; ... &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; \sigma_n \end{bmatrix}\) 对角矩阵，表示的是特征值,此维度上的方差与能量。 \(u_k,v_k\)表示的是对于\(\sigma_k\)对应的特征向量。 \(U^TU=I,V^TV=I:U,V\)均为正交矩阵。 左特征向量\(U\)，每一列对应一个方向，不同的列对应的向量互相垂直，那么将\({\tiny \sum}\)中的\(\sigma_k\)按照从小到大排序，\(u_k，v_k\)也相应排序，可以得到\(u_1\)是对应方差能量最大的方向，\(u_2\)是与\(u_1\)垂直的方差最大的方向... 右特征向量\(V\)，由于\(D^T=V{\tiny \sum}U^T\)，可以按照与上述相同的理解，因此只是维度存在的不同。 SVD分解与主成分分析(PCA) 给定矩阵 \[ \begin{aligned} S_{M*M}&amp;=D*D^T\\ &amp;=(U {\tiny \sum} V^T)(U {\tiny \sum} V^T)^T\\ &amp;={\tiny \sum}^2 \end{aligned} \] 也就是说\(U\)中对应最大的向量位主成分 LSI分解 NMF分解 单词的分布式表达 每一个词用一般的向量表示 科学院：[1.0,0.5,0],中科院：[0.5,1.0,0],数据挖掘：[0,0.1,1.0] 分布式假设： * Syntagmatic:两个单词频繁在文档中共现，则它们具有一定的语义相似度 * Paradigmatic:两个单词频繁在文档的上下文中共现，则它们具有一定的语义相似度 核心思想：一个单词的表达可以通过在它周围出现的单词计算出来（Word2Vec） 举例如下： d1: Albert Einstein was a physicist d2: Richard Feynman was a physicist WordsVec 分解Word-Word矩阵，建模单词间的上下文共现 Einstein Feynman physicist Einstein 0 0 1 Feynman 0 0 1 physicist 1 1 0]]></content>
      <categories>
        <category>Data mining</category>
      </categories>
      <tags>
        <tag>Data mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[监督学习 Supervised Learning(决策树+SVM/Perceptron+AdaBoost)]]></title>
    <url>%2F2018%2F12%2F02%2F%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%2F2018-12-02-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[监督学习的形式化描述 问题描述 样本空间\(X\)(如X为所有的网页集合)和目标空间\(Y\)(Y={个人主页，公司主页，科研机构主页，其他网页}) 预测函数\(f：X-&gt;Y\) 假设空间\(H=\{h|h:X-&gt;Y\}\) 算法输入 训练集合\(D={(x_i,y_i)}_{i=1}^N\),其中\((x_i,y_i)\in X*Y\) 算法输出 根据D中的样本估计"最优"的函数\(h\in H\),使之能够对未出现在D中的样本的标签进行预测 二值分类（Y为类别集合） 回归（Y为实数集合） 结构预测/排序（Y为结构类型/排序） 线性函数\(f(x)=&lt;w,x&gt;\) Perceptron,SVM Ridge regression SVR Structured SVM,Ranking SVM 树 Decision tree Regression tree LambdaMART 神经网络 神经网络 神经网络 RankNet 叠加函数\(f(x)=\sum_th_t(x)\) AdaBoost Boosted Regression Tree RankBoost 分类模型的评价方法 n折交叉验证 评价准则 预测为正样本 预测为负样本 标注为正样本 TP(true positive) FN(false negative) 标注为负样本 FP(false positive) TN(true negative) \(Accuracy = \frac{TP+TN}{TP+FN+FP+TN}\) \(Precision = \frac{TP}{TP+FP}\) \(Recall = \frac{TP}{TP+FN}\) \(F = \frac{2PR}{P+R}\) 调和平均数 由于数据大多不平衡，Accuracy在所有的预测样本均预测到负样本的时候，会严重偏差。 决策树 分类函数\(f\)为一棵树，称为决策树 中间节点：决策步骤 叶子节点：决策结果、类别标签 给定的训练数据，可能存在多颗能够拟合数据的决策树，那么如何选择呢？ 1. 选择最简单的树 2. 拟合精度高的树 选择决策特征 核心步骤：选择合适的特征进行决策，划分数据，生成子节点 合适：尽量大的减少划分后自数据集的混杂度 信息增益(Information gain) 从上图可以看出有以下性质 \[ \begin{aligned} &amp;H(A,X) = H(X,A)\\ &amp;IG(X|A) = IG(A|X)\\ &amp;IG(X|X) = H(X)\\ &amp;IG(X|A) = H(X) + H(A) - H(X,A) \end{aligned} \] 对于上述决策树算法有以下特征： * 贪心策略 * 从根节点开始，已建立的树不再改变 * 数据划分后不再改变 * 每次选择局部信息增益最大的特征划分数据 * 局部最优解 * 递归算法 - 每一个决策节点用相同的策略扩张 * 信息增益IG不是唯一的选择 改进 上述算法只能够处理类别型的特征，对于数值型特征需要划分区间，按照IG最大化的原则选择阈值。 对于过拟合的情况要降低模型复杂度，采用剪枝方法减少节点数目(post-pruning)。 SVM/Perceptron 分类边距Margin：对线性分类器而言，边距就是从分类面到最近的训练样本的距离。 SVM(support vector machine)：最大化分类边距，VC理论证明最大边距分类器有较好的泛化能力。 \[ Margin = |x^+-x^-| = |\lambda w|=\frac{2}{&lt;w,w&gt;}\sqrt{&lt;w,w&gt;}=\frac{2}{\sqrt{w,w}} \] 优化目标: \(min_{w,b}|w|^2\)，约束条件\(y_i(&lt;w,x_i&gt;+b)\geq 1, for \,i=1,...,N\) 当出现线性不可分的时候，解决方案是容忍错误的发生，采用软边距 优化目标：\(min_{w,b}|w|^2+C\cdot \sum_{i=1}^N\xi_i\)，约束条件\(y_i(&lt;w,x_i&gt;+b)\geq 1-\xi_i,\xi_i \geq 0\) \(C\)：权衡边距大小与错误容忍度，C变大牺牲边距减少训练集合上的错误 AdaBoost 组会有差异性的弱分类器可以得到强分类器 不同的弱分类器可以通过不同的算法、特征、数据训练得到 弱分类器的预测精度强于随机预测 基本训练过程如下： AdaBoost 算法如下：]]></content>
      <categories>
        <category>Data mining</category>
      </categories>
      <tags>
        <tag>Data mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[证明拉普拉斯矩阵是半正定矩阵]]></title>
    <url>%2F2018%2F11%2F19%2F%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB%2F2018-11-19-%E8%AF%81%E6%98%8E%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5%E6%98%AF%E5%8D%8A%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%2F</url>
    <content type="text"><![CDATA[因为\(L=D-W\),那么\(x^TLx\)有： \[ x^TLx = x^T(D-W)x = x^TDx - x^TWx \] \(W\)为一个对称矩阵,将\(W\)的各行元素累加得到了\(D\),由于\(D\)是对角矩阵\(x^TDx=\sum_{i=1}^nd_ix_i^2\)， \[ \begin{aligned} x^TLx &amp;= \sum_{i=1}^nd_ix_i^2 - \sum_{i=1}^n\sum_{j=1}^nw_{ij}x_ix_j\\\ &amp;=\frac{1}{2}(\sum_{i=1}^nd_ix_i^2 - 2\sum_{i=1}^n\sum_{j=1}^nw_{ij}x_ix_j + \sum_{j=1}^nd_jx_j^2)\\\ &amp;=\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^n(w_{ij}x_i^2-2w_{ij}x_ix_j+w_{ji}x_i^2)\\\ &amp;=\frac{1}{2}\sum_{i=1}^n\sum_{j=1}^nw_{ij}(x_i-x_j)^2\geq0 \end{aligned} \] 综上拉普拉斯矩阵\(L=D-W\)是一个半正定的矩阵。]]></content>
      <categories>
        <category>Pattern recognition</category>
      </categories>
      <tags>
        <tag>Pattern recognition</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ETH Zurich at TREC Precision Medicine 2017]]></title>
    <url>%2F2018%2F11%2F07%2F%E6%A3%80%E7%B4%A2%2F2018-11-7-ETH%20Zurich%20at%20TREC%20Precision%20Medicine%202017%2F</url>
    <content type="text"><![CDATA[摘要 这篇文章讲的是ETH在TREC 2017竞赛上的成果。 首先，将文本逐字的进行匹配，其中要考虑到的关键项是癌症的类型、基因的变体，以及人员的统计资料。其次，我们根据一系列的深度基因嵌入重新给最相关的结果进行rank排名，使用PubMed和NCBI信息上训练的前馈网络将文字投射到保留语义的向量空间中，但也依赖于关于生成对抗方法，以确定同一患者中各种突变共同发生的可能性。实证结果表明，即使没有现有的专家标签，所提出的方法也可以在竞争性tf-idf基线上引入边际改进。 介绍 我们的rank排名方法结合了以下四个来源的信息： 1. 对于患者、癌症类型以及基因变体的文字描述。 2. 对于关键医学术语的密集语义向量表示。 3. 对于基因表示以及患者北京的功能型的神经嵌入。 4. 基因突变共生的生成对抗模型 在对于以上可利用信息的初始化检索之后，可以将不用的数据源都聚合起来，从而使结果逐步导向一个具有鲁棒性的rank排名。 由于缺少历史训练数据，我们刚开始人工对1800个样本（包括1200个摘要以及600个临床实验）做了注释，使用这些样本来进行训练以及优化有监督的训练模型以及模糊规则。由于这些数据并非专家标注，因此在无训练的匹配规则中会有较大的性能提升。 方法 基于精确匹配的词项 我们使用患者描述来生成队列，以使得我们通过对比文档来获得一个相似的评分。假设的框架中采用了简要的数据以及临床实验数据作为向量空间模型，其中词项的权重由\(tf-idf\)的得分。对于算法实现来说，我们使用了开源框架\(Lucene\)，为了在固定结构的topic中确定不同field（理解成不同元素/项）我们使用如下的静态权重因子： 为了更科学的简化，我们将年龄具体划分成三个类别（小儿，成年，老年医疗），对于每一个类别我们都加入年龄。通过临床实验来加强对于每一个类别的特定年龄范围。 神经网络的内容嵌入 在第二个方法中，我们使用文字项来匹配计算出的语义向量，包括对于患者基因特征的描述以及抽象。我们构建了一个基因特征的词汇表，有生物信息概念以及文档中出现的常用词。然后我们使用神经概率语言模型，找出这些词项的连续嵌入。然后现在对于患者以及科学抽象的临床试验文档可以表示为距离函数，然后应用到各自的向量表达中。 为了区分文档集中相关基因的区分度，我们使用HGNC数据库中的基因特征，并应用基于符号同义词关系的简单启发式方法来消除模糊基因符号，如CO2或SARS，这些符号也具有非基因组解释。我们词汇表的生物医学概念由Uniﬁed Medical Language System（UMLS）提供。我们在PubMed中的所有摘要中训练我们的嵌入，其中包含任何已识别的相关基因符号。 相关度对于每个topic文章的分数都可以通过向量表示来进行计算，以及基于内容的相似度的分数可以写作\(s_c\)。我们考虑对于基因符号\(g_t\)最相似的三个词项\(d_{i,1},d_{i,2},d_{i,3}\)，以及一个给定的重要性的递减权重，采用最常用的\(1+log(k_{ij})\)来表示词项频率\(tf(d_{ij})\)来计算词项\(d_{ij}\)在文档中出现的多个次数，最后的评分可以被写作余弦距离： \[ s_c(T,D)= \\sum_{g_t\in T} \\sum_{j=1}^3 \omega_j*(1+log(tf(d_{ij})))(1-cos(g_t,d_{ij})) \] 神经网络的基因嵌入 在一个可选的神经嵌入规则中，我们目标是对一个医学的基因特性以及基因突变建模。函数的相似性可以被定义为基于相同的癌症类型以及基因，使得对于相同癌症的相关基因相似度更高。 我们使用NCBI数据库，对于每一个基因都包含染色体，基因以及它们的属性（例如蛋白质作用），相关标记，显性以及相互作用。除此之外，对于每一个记录的基因，有一个『总结』，在这一部分中，多有与该基因有关的癌症类型都被列出来了，总计有1357种不同的基因与109种癌症类型。 采用单层的欧式函数空间来前反馈基因型。该网络中的输入就是一个向量可以独一无二地表示这个基因，输出就是一个特殊的向量，对应一个特殊的癌症类型。如果一个输入基因对应着一个癌症类型，那么对应元素的输出向量(癌症类型)就置为1，如下图所示 输入层的大小等于基因的数量（1347），输出层对应癌症的类型（109），隐藏层大于为50，最大的用于预测癌症的交叉对比准确度约为60%。在训练完这些数据的特征之后，我们使用基因表示来对学术文章进行排名，用余弦函数来表示任意两个基因之间的相似度。\(a = {mean,max,mean max}\) \[ s_f(T,D) = a(cos(g_t,g_d))\forall g_t \in T, g_d \in D \] 其他的对于基因对排名的训练 为了提高兼容性，我们生成了一个额外的网络GAN，一个GAN网络包含两个不同目标的训练， GAN由针对不同目标训练的两个网络组成：发生器网络旨在复制原始数据分布，而鉴别器网络交替地馈送实际和生成的数据，并且负责识别真实数据点。基本假设就是经常一起发生的基因也有相似之处。最后，我们使用训练有素的GAN来构建度量，以根据文档的基因兼容性对文档进行排名。对于给定文件\(g_d\)中的每个患者基因\(g_t\)和基因提及，我们计算Disc的鉴别值\((g_t,g_d)\)。对于可能的实对，鉴别器分别输出1和0用于可能不相关的数据。我们通过应用聚合函数\(a = {min，max，mean}\)将\(Disc(.)\)的值组合在文档中的所有基因中。 \[ s_g(T,D) = a(cos(g_t,g_d)) \forall g_t \in T, g_d \in D \] 分数模糊 根据以上我们计算出了分数\((tfidf(.),s_c(.),s_f(.)以及s_g(.))\) 首先我们将所有的组成分高造成向量： 我们介绍5中方法来模糊分数使得他们可以融合起来。 1. Weighted Sum (nDCG)：将不同分数分配不同权重相加。 2. Pure Term-based Exact Matching：静态的精确匹配模糊 3. Neural Fusion：包含一个16个神经元的隐藏层，结合分数向量用来学习文档的rank值。该网络被训练来匹配输入向量，输出为0或者1。对于过拟合的数据我们可以丢弃数据。 4. Weighted Sum：与nDCG方法相反，该方法旨在通过线性回归将得分向量映射到带注释的文档标签上。 5. Neural Embeddings and GAN Values Exclusively：最后一种方法与第四种融合方法相同，但不考虑任何tfidf分数。 如前所述，文档已经通过精确匹配方法预先选择，因此这种融合测试了这种精确术语的预选是否足以仅使用神经嵌入分数和GAN估值对文档进行排名。]]></content>
      <categories>
        <category>Information Retrieval</category>
      </categories>
      <tags>
        <tag>Information Retrieval</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非负矩阵分解]]></title>
    <url>%2F2018%2F10%2F18%2F%E7%AE%97%E6%B3%95%2F2018-10-15-%E9%9D%9E%E8%B4%9F%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原论文 Algorithms for Non-negative Matrix Factorization 摘要 非负矩阵(NMF)对于多元数据的分解来说很有用，这里分析两个不同的NMF算法，其中一个最小化二乘误差，另一个最小化广义Kullback-Leibler分歧。两种算法的单调收敛可以使用类似于用于证明期望最大化算法的收敛的辅助功能来证明。算法也可以解释为对角重新缩放的梯度下降，其中最佳地选择重定标因子以确保收敛。 非负矩阵的分解 我们考虑以下形式化问题的求解： NMF 给定一个非负矩阵\(V\)，找到非负矩阵\(W\)和\(H\)使得有以下式子： \[V \approx WH \tag{1}\] NMF可以被应用到多元数据的统计分析当中，给定一个n维的数据向量集，由一个 \(n*m\) 的矩阵\(V\)来表示，其中\(m\)表示数据集的例子个数。这个矩阵可以被分解成\(n*r\)的矩阵\(W\)以及\(r*m\)的矩阵\(H\)，通常\(r\)都是要比\(n\)和\(m\)要小的，所以\(W\)与\(H\)也比原始矩阵要小一些。也就是说结果可以看做是原始数据矩阵的一种压缩。 那么公式（1）有什么意义呢？他可以携程列的形式\(v \approx Wh\)，\(v\)和\(h\)都是对应矩阵\(V\)和\(H\)的某一列。也就是说，每一列的数据向量\(v\)都是对于矩阵\(W\)的一个线性变换，权重取值为\(h\)。因此\(W\)可以被视为包含针对V中的数据的线性近似而优化的基础。因为很多基本列都可以变换得到其他的数据向量，因此一个好的变换就是可以通过这些基本列来实现。 现在所关注的不是NMF的如何应用，而是关注与找到非负矩阵如何分解。当然，其他类型的矩阵分解已经在数值线性代数中被广泛研究了，但是由于非负的限制，使得之前的工作与现在的例子不完全兼容。 现在我们考虑两种基于不断迭代更新\(W\)和\(H\)的NMF算法，因为这些算法容易实现且可以收敛，在实际情况中也可以应用。其他算法可能也有效但是比较难实现。 在我们算法的每一次迭代中，\(W\)与\(H\)的新值可以通过公式（1）将当前值乘以质量因子而得。我们证明得出这种近似估计的质量随着应用的多次迭代，单调递增。也就是说这种重复迭代通过更新规则保证了矩阵分解的局部优化的收敛。 成本函数 为了找到近似分解\(V \approx WH\)，我们首先需要确定成本函数来量化估计质量。成本函数可以通过构造两个非负矩阵\(A\)和\(B\)的距离来确定。一个有效的测量就是简单计算两个矩阵的欧氏距离 \[ \left \| A-B \right \|^2=\sum_{ij}(A_{ij}-B_{ij})^2 \tag{2} \] 根据上式可以明显看出当\(A=B\)时，取下界0。另外一个有效的测量方法是 \[ D(A||B)=\sum_{ij}(A_{ij}log\frac{A_{ij}}{B_{ij}})-A_{ij}+B_{ij} \tag{3} \] 虽然上式的下界也是0，但是却不能称之为距离，因为并没有根据A和B对称，所以我们将其称之为A与B的区分度，它简化了Kullback-Leibler分歧，或者说是相对熵。当\(\sum_{ij}A_{ij}=\sum_{ij}B_{ij}=1\)，A和B可以被看作是归一化的概率分布。 现在我们考虑两个可能的形式化NMF优化问题： Problem 1 最小化关于W和H的式子\(\left \|V-WH \right \|^2\)，其中\(W，H\geq0\) Problem 2最小化关于W和H的式子\(D(V \|WH)\)，其中\(W，H\geq0\) 尽管上式对于\(WH\)都分别是凸函数，但是二者一起来看就不是凸函数了，所以在全局对于\(WH\)找到一个最小值是不现实的，然而有很多技术可以进行数值优化找到局部最小值。 梯度下降法可能是最简单的一种方法，但是收敛速度可能比较慢，另外的如共轭梯度可以快速收敛找到一个局部最小值，但是实现复杂。除此之外，梯度下降法对于步长还比较敏感，对于大规模的应用来说适应性比较低。 乘法更新规则 我们发现"乘法更新规则"对于解决Problem 1&amp;2来说有较高的效率提升且易于实现。 Theorem 1 欧氏距离\(\left \| V -WH \right \|\)在以下的更新规则中是非增长的当W和H达到平稳点的时候，欧氏距离不再发生变化。 \[ H_{a \mu} \leftarrow H_{a \mu} \\frac{(W^TV)\_{a\mu}}{(W^TWH)_{a\mu}} \] \[ W_{ia} \leftarrow W_{ia} \frac{(VH^T)\_{ia}}{(WHH^T)_{ia}} \tag{4} \] Theorem 2 \(D(V \|WH)\)的分歧子啊以下更新规则中不再增加。 \[ H_{a \mu} \leftarrow H_{a \mu} \frac{\sum_iW_{ia}V_{i\mu}/(WH)_{i\mu}}{\sum_kW_{ka}} \\\\ W_{ia} \leftarrow W_{ia} \frac{\sum_{\mu}H_{a\mu}V_{i\mu}/(WH)_{i\mu}}{\sum_vH_{av}} \tag{5} \] 当W和H达到平稳点时，区分度会保持不变 乘法与加法更新规则 拿乘法更新规则与梯度下降法相比较是很有用的。特别的有，一个对于H的简单加法更新可以减小平方距离，可以被写作： \[ H_{a\mu} \leftarrow H_{a\mu}+ \eta_{a\mu}[(W^TV)\_{a\mu}-(W^TWH)_{a\mu}] \tag{6} \] 如果\(\eta_{a\mu}\)都等于小的正整数，那么就是常规的梯度下降法，只要这个数足够小那么该式就可以规约成\(\left \| V-WH \right \|\) 如果我们规定变量 \[ \eta_{a\mu} = \frac{H_{a\mu}}{(W^TWH)_{a\mu}} \tag{7} \] 那么我们就得到了Theorem 1的更新规则。注意到重缩放的结果是由乘法因子与分母中的梯度的正分量以及分子中的负分量的绝对值来决定的。 至于区分度，斜向重缩放的梯度下降表示形式为 \[ H_{a\mu} \leftarrow H_{a\mu}+\eta_{a\mu}[\sum_iW_{ia}\frac{V_{i\mu}}{(WH)_{i\mu}}-\sum_iW_{ia}] \tag{8} \] 同样的，如果\(\eta_{a\mu}\)是小的正数，这个更新应该会减少\(D(V||WH)\)，如果我们设定 \[ \eta_{a\mu}=\frac{H_{a\mu}}{\sum_iW_{ia}} \tag{9} \] 我们将会得到对于H的Theorem 2更新规则。这个重缩放能够被解释成一个在分母中有正因子梯度下降的乘法规则和分子中有负因子的乘法因子。 由于我们选择的\(\eta_{a\mu}\)并不非常小，所以它并不保证这样的梯度下降会造成成本函数的收敛。但是下一节将会对此证明。 收敛证明 为了证明\(Theorems 1,2\)，我们会重复使用一个辅助函数来近似期望最大化的算法。 定理 1 \(G(h,h&#39;)\)是一个对于\(F(h)\)的辅助函数，当且仅当以下条件满足时 \[ G(h,h&#39;) \geq F(h),G(h,h)=F(h) \tag{10} \] 由于Lemma 1，辅助函数是一个非常有帮助的函数，在Fig.1中有所阐释。 如果G是一个辅助函数，那么F在更新过程中是一个非增长的。 \[ h^{t+1}=arg min_h\,G(h,h^t) \tag{11} \] 证明： \(F(h^{t+1})\leq G(h^{t+1},h^t)\leq G(h^t,h^t) = F(h^t)\) 注意到当\(h^t\)是函数\(G(h,h^t)\)的局部最小点的时候，有\(F(h^{t+1})=F(h^t)\)。如果\(F\)存在分歧且在\(h^t\)的很小一个邻域内连续，就是说\(\bigtriangledown F(h^t)=0\)，因此，由(11)的更新规则，我们能得到一个序列，在局部对目标函数的最小值连续的收敛估计\(h_{min}=arg\,min_hF(h)\) \[ F(h_{min}) \leq ...F(h^{t+1}) \leq F(h^t) ... \leq F(h_2) \leq F(h_1) \leq F(h_0) \tag{12} \] 定理 2 如果\(K(h^t)\)是一个对角矩阵 \[ K_{ab}(h^t) = \delta_{ab}(W^TWh^t)_a/h_a^t/h_a^t \tag{13} \] 然后 \[ G(h,h^t) = F(h^t)+(h-h^t)^T\bigtriangledown F(h^t) + \frac{1}{2}(h-h^t)^TK(h^t)(h-h^t) \tag{14} \] 作为以下函数的辅助函数 \[ F(h)=\frac{1}{2}\sum_i(v_i-\sum_aW_{ia}h_a)^2 \tag{15} \] 证明有： 因为G(h,h) = F(h),我们需要证明\(G(h,h^t)\geq F(h)\) 我们比较下式与(14) \[ F(h) = F(h^t)+(h-h^t)^T\bigtriangledown F(h^t) + \frac{1}{2}(h-h^t)^T(W^TW)(h-h^t) \tag{16} \] 发现要满足\(G(h,h^t)\geq F(h)\)等价于 \[ 0 \leq (h-h^t)^T\[K(h^t)-W^TW\]\(h-h^t) \tag{17} \] 为了证明半定，考虑以下矩阵： \[ M_{ab}(h^t) = h_a^t(K(h^t)-W^TW)_{ab}h_b^t \tag{18} \] 这样，当且仅当\(M\)是一个半正定矩阵时，\(K-W^TW\)也是一个半正定的矩阵。有： \[ \begin{aligned} \upsilon^TM\upsilon = \frac{1}{2}\sum_{ab}(W^TW)_{ab}h_a^th_b^t(\upsilon_a - \upsilon_b)^2 \end{aligned} \] 上式大于0，我们可以证明Theorem1的收敛 Theorem 1证明 将公式(14)的结果代入公式(11)中得到更新规则： \[ h^{t+1} = h^t - K(h^t)^{-1} \bigtriangledown F(h^t) \tag{21} \] 因为公式(14)是一个辅助函数，F在此更新规则下是非增长的，根据Lemma 1，可以明确得到下式： \[ h_a^{t+1} = h_a^t\frac{W^T\upsilon_a}{W^TWh^t}_a \tag{22} \] 翻转W与H的角色，F也可以在W的更新规则下保持不增长。 现在我们考虑对于分歧开销函数的估计函数。 Lemma 3 定义 \[ G(h,h^t) = \sum_i(\upsilon_i log\upsilon_i - \upsilon_i)+\sum_{ia}W_{ia}h_a \\ -\sum_{ia}\upsilon_i \frac{W_{ia}h_a^t}{\sum_bW_{ib}h_b^t}(logW_{ia}h_a-log\frac{W_{ia}h_a^t}{\sum_b}W_{ib}h_b^t) \tag{23} \] 这是对于下式的辅助函数 \[ F(h) = \sum_i \upsilon_ilog(\frac{\upsilon_i}{\sum_aW_{ia}h_a}) - \upsilon_i + \sum_aW_{ia}h_a \tag{24} \] 证明 可以很直接证明\(G(h,h)=F(h)\)，为了证明\(G(h,h) \geq F(h)\)，有 \[ -log \sum_aW_{ia}h_a \leq -\sum_a\alpha_a log\frac{W_{ia}h_a}{\alpha_a} \tag{25} \] 总的来说这里的\(\alpha_a\)是非负的。设定有 \[ \alpha_a = \frac{W_{ia}h_a^t}{\sum_bW_{ib}h_b^t} \tag{26} \] 我们可以由此得到 \[ -log\sum_aW_{ia}h_a \leq - \sum_a\frac{W_{ia}h_a^t}{\sum_bW_{ib}h_b^t}(log W_{ia}h_a - log\frac{W_{ia}}{\sum_bW_{ib}h_b^t}) \tag{27} \] 从上述不等式可以看出\(F(h)\leq G(h,h^t)\) Theorem 2证明 关于h的\(G(h,h^t)\)的最小值是由梯度下降为0时而决定的： \[ \frac{dF(h,h^t)}{dh_a}=-\sum_i \upsilon_i\frac{W_{ia}h_a^t}{\sum_bW_{ib}h_b^t}W_{ia} \tag{28} \] 因为G是一个辅助函数，在公式(24)里面，F在更新下是一个非增长的函数。重写该矩阵可以得到公式(5)。翻转H和W的角色，关于W的更新规则也可以看做是非增长的。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蜜罐技术]]></title>
    <url>%2F2018%2F09%2F02%2F%E5%AE%89%E5%85%A8%2F2018-09-02-%E8%9C%9C%E7%BD%90%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[蜜罐技术 蜜罐主要工作原理 蜜罐通常伪装成看似有利用价值的网络且提供一些必要的漏洞，当一个攻击者试图侵入蜜罐时，入侵检测系统会触发一个报警，隐藏的记录器会记录下入侵者一切活动，当入侵者试图从蜜罐中转向真实主机时，一个单独的防火墙会随时把主机从网络上断开。 蜜罐技术的分类 高交互蜜罐： 模拟一个全功能的生产环境，因此攻击者可能因为多种服务浪费攻击时间。通过虚拟机技术可以在单个物理机上托管多个蜜罐，也方便恢复。高交互蜜罐难以检测，安全性较高但是维护开销也较高，对于某些特殊情况甚至需要一台物理机部署一个蜜罐。 低交互蜜罐： 只模拟那些经常被攻击请求的服务，由于它消耗的资源有限，复杂度较低可以降低一定的部署费用，但是安全性也相对较低。 蜜罐技术存在的风险： 如果蜜罐被设计从互联网来访问，可能会有一个风险，创建非信任站点列表的外部监控组织可能会报告组织的系统是脆弱的，因为无法区分这个脆弱性是属于蜜罐还是系统自身。 蜜罐原本提供的漏洞稍有不慎就会导致系统被渗透，可能会涉及隐私、责任与设陷技术等。例如黑客可能利用被攻陷的电脑作为跳板或者传播病毒等等。 工具资料 现有的蜜罐参考列表 蜜罐平台 开源蜜罐项目T-Pot：基于docker技术集成了众多针对不同应用蜜罐程序的系统。 现代蜜网MHN：集成了多种蜜罐的安装脚本，可以快速部署、使用，也能够快速的从节点收集数据。 T-pot和MHN支持的蜜罐容器： Conpot：低交互工控蜜罐，提供一系列通用工业控制协议, 能够模拟复杂的工控基础设施。 Cowire：中等交互的SSH与Telnet蜜罐，可以记录暴力攻击，并提供伪造的文件系统环境记录黑客操作行为。 Dionaea: 它开放常见网络服务的默认端口，当有外来连接时模拟正常反馈，同时记录下数据流，网络数据流经由检测模块检测后按类别进行处理。 Glastopf: 低交互型Web应用蜜罐，能够模拟成千上万的web漏洞，针对攻击的不同攻击手段来回应攻击者，然后从对目标Web应用程序的攻击过程中收集数据。 Honeytrap: 观察针对TCP或UDP服务的攻击，并能够分析攻击字符串，执行相应的下载文件指令。 可视化界面： 蜜罐衍生概念 蜜场： 蜜场的思想是将网络中可疑数据流重定向到蜜场中。在网络中放置检测器，当发现可疑数据流时，利用重定向器将其导向蜜场。所有蜜罐集中于蜜场，与外网之间用防火墙隔离。蜜场的优势在于集中性。 蜜网： 当多个蜜罐被网络连接在一起，组成一个大型虚假业务系统，利用其中一部分主机吸引攻击者入侵，通过监测入侵过程，一方面收集攻击者的攻击行为，另一方面可以更新相应的安全防护策略。这种由多个蜜罐组成的模拟网络就称为蜜网。 分布式蜜网： 分布式蜜网系统能够将各个不同位置部署的蜜网捕获的数据进行汇总分析，有效的提升安全威胁监测的覆盖面，克服了传统蜜罐监测范围窄的缺陷，因而成为目前安全业界采用蜜罐技术构建互联网安全威胁监测体系的普遍部署模式。 动态蜜网： 动态蜜网，将低交互蜜罐和高交互蜜罐结合起来，需要虚拟蜜网技术的支持，利用被动指纹工具监控网络。依据获得的网络信息对蜜网进行部署和配置。最主要的是其自适应能力，能够自动学习周围的网络环境，配置适当数量的蜜罐，并随网络环境的变化做出调整。 SDN蜜网： 结合虚拟化技术，能够在威胁发现之后动态的生成相应的蜜网系统，同时利用SDN控制器将异常流量调度到虚拟化的蜜网系统中，完成异常行为的跟踪取证与安全防护。这种SDN蜜网有效的解决了传统蜜网的部署结构不灵活，基础设施成本高等问题。 蜜网研究项目参考网站 总结分析 T-pot与MHN提供了比较完善的开源平台，我们可以尝试利用虚拟机或者docker技术等将其部署在物理机或云服务器上，进行异常流量的监测工作（同李振华老师的做法）。 针对项目特定需求二次开发相应的蜜罐容器，采用分布式蜜网或SDN蜜网等方法，将蜜罐部署到各个节点之上，对实际项目中的异常流量或者攻击行为进行监测。]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>Security</tag>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SketchLearn: Relieving User Burdens in Approximate Measurement with Automated Statistical Inference]]></title>
    <url>%2F2018%2F08%2F23%2F%E7%BD%91%E7%BB%9C%2F2018-8-24-SketchLearn%2F</url>
    <content type="text"><![CDATA[概述 在巨大的网络流量下，网络测量对于资源的利用有着严格的限制。近似测量的方法可以节省一定的资源，需要人工对其进行合适的配置。详细来说，典型方法通过严控参数，在合理的测量误差下提供足够的资源。我们设计了SketchLearn，这是一个sketch-based的测量框架，可以通过学习统计特性解决资源冲突从而消除了网络流量上的冲突。 介绍 由于网络资源的限制，许多的网络测量方法都需要在资源利用与测量准确度之间进行权衡。基本思路就是将次线性的数据结构压缩，并在有限的资源下理论保证恢复。尽管这具有理论可行性但是现有方法都不方便使用，因为巨大的网络流总是在竞争有限的资源，并由资源冲突引发一定的错误，为了消除这些错误，还需要分出一些资源来实现准确度。综上，资源配置与准确度之间还有紧密的联系，这些联系导致了一部分限制： 管理员需要将错误容忍级别当做一个参数引入到资源配置算法中。 每一种资源配置都对应一个阈值参数。 理论分析只给出了基于实际负载的最坏结果。 每一种配置都被特定的流所限制。 管理员不能容忍较大的测量误差。 由于以上限制的存在，如何在理论方法与实际应用之间架起桥梁对我们来说是一个挑战。 为了解决这个问题，我们使用的sketch-based方法可以完全记录所有观测到的数据包的统计数据，他们都有固定的数据结构。SketchLearn的基本思想是将固有的资源矛盾的统计特征描绘出来，而非追求一个消除所有资源冲突的配置参数。详细的说，SketchLearn建立了一个多层的sketch来追踪网络流记录的频数。这个多级结构引出了一个计数器的多bit-level的高斯分布。SketchLearn利用高斯分布来确定其限制。它反复从多级sketch中推算并提取出大数据流，直到剩余的多级sketch满足高斯分布。通过分离大小数据流，SketchLearn消除了资源冲突并且提高其测量准确性。 研究动机 在一个时间间隙里每条网络数据流的频数被称为epochs。每条流都用一个flowkey作为标志，例如5元组或者源/目的地址对。通过每条流的频数，我们都可以得到较复杂的数据流统计量，如heavy hitters, heavy changers, superspreaders 以及 DDoS，cardinality(势),流大小分布和熵。 设计要求 较小的内存使用 较快的包处理速度 实时响应 通用性 现有方法的一些限制 很难说明预期误差 很难处理不同的阈值（针对那些阈值作为一项输入的方法来说） 很难根据理论依据来调整参数配置 很难重新定义flowkeys 很难去检查其准确性 SketchLearn 概览 功能设计 对于每位进行追踪的多级sketch SketchLearn维护一个由多个小sketches所组成的多级sketch，每个多级sketch都会对一个给定的flowkey进行特定的网络流数据跟踪。结合统计模型，SketchLearn不仅仅减少了sketch的大小，还加强了对于资源的利用，同时还使得flowkey可以按需随意定制。在多级sketch中，每一个flowkey都有多个域来组成，如5元组。 对大小数据流进行分离 多级sketch提供了一个关键的特性就是如果没有大数据流，他的计数器就跟从高斯分布。这样，SketchLearn从多级sketch中抽取大数据流，并且剩下小数据流的计数器形成高斯分布。这样的分离使得SketchLearn解决哈希冲突。例如SketchLearn只对那些抽取出来的大数据流进行hitter检测。 无参数的模型接口 SketchLearn在不借助任何参数的情况下实现对于大小数据流的区分。它反复学习多级sketch中的统计分布并且利用这种分布来指导大数据流的提取。注意这里的无参数不是说SketchLearn是零配置的，例如对于heavy hitter的检测仍然需要一个阈值，但是SketchLearn已经尽可能减少了配置量。 对于独立数据流的误差测量对于给定数据流统计量SketchLearn都有相应的误差测量。我们不需要识别任何误差，相反的是我们利用这个来识别正确的数据流 全网范围SketchLearn可以部署到全网的测量节点上。 架构设计]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elastic Sketch: Adaptive and Fast Network-wide Measurements]]></title>
    <url>%2F2018%2F08%2F23%2F%E7%BD%91%E7%BB%9C%2F2018-8-23-Elastic%20Sketch%2F</url>
    <content type="text"><![CDATA[概要 当网络面临拥塞、扫描攻击以及DDos攻击等等时，通信特征例如可用带宽、包速率以及流大小都散布非常剧烈，严重影响了测量性能。为了解决这些问题，提出了Elastic sketch。ES对于不同的任务以及平台都有一定的普适性(P4，FPGA，GPU，CPU，多核CPU，OVS)。 简介 背景 现有的网络测量方法都是在准确度、速度以及内存使用量上的一个trade off问题。且现有方法都没有解决的问题是，在网络通信各个特征大幅变化时如何实现网络的准确测量。 第一个网络特征就是可用带宽。数据中心中，管理员相比于一条单独的链路或者节点，更关心整个网络的状态，也就是全网的测量。管理员可以部署多个测量节点，这些节点周期性地向 collector汇报 sketches测量结果，这样的测量过程也需要占用一定的带宽。在数据中心里，网络拥塞也是非常常见的，这样一来，网络测量对于拥塞控制与解除问题来说就至关重要了。一方面，不能等待可用带宽去汇报测量结果，因为这些结果都具有相当的实时性，另一方面，网络测量不应该是网络中的一个负担。一个良好的解决方法是同时兼顾准确性与低带宽的占用。这里用的方法是压缩sketch算法。 第二个网络特征就是包到达速率。这项指标在短时间内可能会大幅变化。有一些路由协议是根据网络性能来调整包的发送速率。但是现有的sketches算法对于包的处理速率都是固定的，因此对于突然提高的包速率处理不好，对此，我们可以加快对于重要信息的处理过程，丢弃不重要的信息。 第三个网络特征是流大小的分配。大多数的网络流都是比较小的。我们应当将大数据流区分出来，并用不同的数据结构来存储他们。然而，流大小十分分散。有的人认为我们可以通过预测实现预先分配内存大小，但是对于小时为单位的预测大数据流是可以的，却没办法精确到秒级。因此我们需要设计一个弹性的数据结构从而动态地给大数据流分配合适的内存空间。 总的来说，为了解决现阶段的问题需要一个弹性的sketch方案：自适应带宽，包速率以及网络流量大小分布。除此之外的要求还有普适性，实时性以及准确性。 解决方案： Elastic sketch，由heavy part和light part构成。提出了一种Ostracism技术可以保证大数据流导入heavy part 并且小数据流导入light part。 为了实现弹性伸缩，我们可以实现以下内容： 为了适应带宽，我们提出了压缩与合并sketch的算法。首先是压缩我们原有的sketch到一个合适的大小以适应现在的可用带宽，然后在用服务器来合并sketches并减少带宽使用。 当包速率提高时，我们改变其处理方法，我们仅仅记录那些大数据流并丢弃小数据流的信息。这样在损失极小的准确度的情况下可以实现更快的数据处理。 当大数据流的数量发生剧烈变化时，我们设计了一个算法动态增加heavy part的内存大小。 为了实现普适性，我们可以实现以下内容： 对于测量任务的普适性。我们保留每个数据包最不可或缺的信息，但是要丢弃小数据流的ID信息，因为根据我们观察得知处理ID通常会消耗内存但是实用性较低。 对于平台的普适性。我们分别提出了一个软件和硬件版本来表示ES，甚至针对P4也做出了适配改进。 背景和相关工作 自适应测量的挑战： 根据合适的带宽将测量数据以合适的大小发送出去。当可用带宽比较小时，发送较大的sketch将会导致较大的延迟并且影响正常的用户数据。除此之外，所有现有的测量方法都是在开始测量之前选定一个固定大小的内存。问题就是如何将sketch的大小缩小到可用带宽大小以下。设计目标是用低于现有方法一半的内存空间来实现与原方法相近的准确度。 处理包的速率适应包速率。现有方法大多是固定速率，且需要的内存空间较大（大于数据包10倍的内存空间）。设计目标是如何在包速率较低时用2倍的内存空间，以及包速率较高时用1倍的内存空间，同时保证高准确度。 在真实的网络环境中，网络流大小的分布式偏斜且变化无常的(skewed and variable)。（Skewed）大多数的网络数据流都是小流，少部分是大数据流。为了实现内存利用效率，可以分离大流与小流，因为大流往往比小流要重要得多，所以给大数据流分配合适的内存大小也是至关重要的。由于在网络中大流和小流都是未知的，因此动态地分配内存是极具挑战的。 测量的通用性方法： 流大小的估计：对任意一条网络流大小都进行规模估计。ID可以由5元组构成。本文将网络流大小用数据包的数量或者流字节大小来代替。 Heavy hitter检测：将所有大小超过预先定义阈值的网络流报告出来。 Heavy change检测：将所有在相邻两个时隙内流大小变化超过一定阈值的网络流报告出来。 流大小分布估计 熵估计：网络流大小的熵 势估计：网络流数量 弹性Sketches 基本思路 逻辑依据(Rationale): 根据上述提到的，我们需要区分大小数据流。我们将分流问题规约为：已知一个高速的网络流，如果用一个桶(bucket)来选择最大的网络流？因为内存大小有限，不可能实现一个完全准确的答案，因此我们应该致力于提高该算法的准确度。我们的方法与陶片放逐法(Ostracism)的思路类似。详细来讲，每一个桶(bucket)都有三个域：ID，positive votes，negative votes。已知一个ID为\(f_1\)的流传来了一个数据包，如果与bucket 中的ID一致，就增加其positive votes的值，反之增加negative notes的值。如果(\(\frac{negative\ votes}{positive\ votes} \geq \lambda\))其中λ是预先定义好的阈值，我们将原有的数据流从bucket中删除并将\(f_1\)放入到bucket中。 如图所示，数据结构包含两部分，heavy part记录大数据流，light part记录小数据流。\(h(.)\)是一个哈希函数，\(vote^+\)可以记录本数据流的数据包，\(vote^-\)可以记录其他数据流的数据包，flag标志light part里面是否包含本条数据流的positive votes。 light part是一个CM sketch, 一个CM sketch包含\(d\)个数组，每个数组都有一个哈希函数，并组成了\(w\)个计数器。给定一个进来的数据包，CM sketch取出流ID，计算\(d\)个哈希函数去给每一个数组定位一个计数器，并且在该计数器上加1。 插入：给定一个进来的流ID为\(f\)的数据包，我们把它哈希到桶\(\mathcal{H}[h(f)\%B]\)中，\(B\)是heavy part里面bucket的个数。假设bucket保存\((f1,vote+,flag1,vote-)\)。与陶片放逐法Ostracism相同的是，如果\(f\)与\(f_1\)匹配，我们增加\(vote^+\)，否则增加\(vote^-\)并且决定是否驱逐\(f_1\)。具体来说有以下四种情况： bucket是空的，插入\((f,1,F,0)\) \(f=f1\),\(vote^+\)加1 \(f \neq f1\)且在\(vote^-\)加1后，\(\frac{vote^-}{vote^+} &lt; \lambda\)，我们将\((f,1)\)插入到CMsketch中，并且将哈希计数器加1。 \(f \neq f1\)且在\(vote^-\)加1后，\(\frac{vote^-}{vote^+}\geq \lambda\), 我们将\(f_1\)剔除bucket并将\(f\)填到桶中，并初始化为\((f,1,T,1)\)。\(f_1\)会被放到CM sketch中，增量大小为原\(vote^+\)，注意这里的flag置为T，因为在此之前，有可能存在\(f\)流已经被插入到light part的情况。 对于任意不在heavy part的流，light part可以直接反映出其大小。对于任意一个在heavy part的数据流有两种情况： \(flag=F\)，大小就是\(vote^+\)。 \(flag=T\),我们需要合并\(vote^+\)以及CM sketch的结果。 Elastic Sketch 的准确性在大多数情况下都是足够高的，得益于以下两点： heavy part没有任何错误：对于任何flag为F的数据流，\(vote^+\)代表的就是全部的数据流，当flag为T时，\(vote^+\)代表的是一部分的真实数据流。 light part中我们没有记录流ID，仅仅记录那些小数据流的大小，因此可以使用很多小计数器（如8位计数器），相比传统sketch算法中的较大计数器，我们的方法可以更加精确。 对于精确度影响最大的就是大数据流的冲突：当两个或两个以上的大数据流哈希到同一个bucket里，其中一条大数据流就会导入light part中，使得一些小数据流过高估计了。对于该问题的解决方法就是减小哈希冲突，两个经典思路其一是使用子表，另一个就是多个key值匹配。 自适应匹配可用带宽 为了适应可用带宽，我们在发送sketches之前要先对其进行压缩。大多数的网络流都是小数据流，因此，light part的内存使用要远远大于heavy part的。这里我们要研究的内容是如何压缩合并light part，也就是CM sketch的。 压缩的主要思路是先将计数器分组，并将同一组里的计数器合并到一个计数器上。 分组：由上图所示，给定一个大小为\(zw&#39;*d\)的sketch A(宽度\(w=zw&#39;\)，深度为\(d\)，\(z\)是一个整数代表压缩率),我们的压缩方法遵循以下规定： 将sketch A划分为相等的部分，每个部分都是\(w&#39;*d\)。 我们设立一个sketch B大小为\(w&#39; * d\)。3）有同样索引的计数器将会被分到同一个组里（\({A_i^k[j]}_{k=1,...,z}\)），因此我们可以设置\(B_i[j]=OP^z_{k=1}{A_i^k[j]}(1&lt;=i&lt;=d,1&lt;=j&lt;=z)\),\(OP\)是一个合并操作符如MAX或Sum，图例中就是取最大值，为了符合sketch B，我们也仅仅需要将哈希函数\(hi(.)\%w\)变为\(hi(.)\%w\%w&#39;\)。 合并操作：第一种是加和压缩(SC)，将每一组的计数器求和。另一种就是最大值压缩(MC)。关于二者有以下结论： 1. SC不会改变原始的误差范围，MC则会让误差范围更加严格。2. 我们证实使用MC方法，压缩后的CM sketch有over-estimation的错误，但却没有under-estimation的错误，就是说只可能过度估计，不会少估计。 3. 压缩过程是很快的，比原始方法块5~8倍。 4. 不需要解压缩。 5. 压缩也不需要任何额外的数据结构。 合并sketches 如上图所示，可以利用服务器来节省带宽。每一个服务器都从测量节点收到很多个sketches，然后合并sketches并将合并结果发送到collector。为了实现合并，我们需要每一个sketches都使用相同的哈希函数。如果他们都有共同的流ID，我们建议使用求和合并，否则我们建议使用最大值合并。 求和合并（Sum Merging）：给定两个相同大小(\(d*w\))的，将相对应的计数器值相加即可，这种方法简单快速但是准确率低。 对于相同大小的sketches进行最大值合并：如下图所示，给定两个sketches A和B（\(w*d\)），建立一个新的sketch \(\mathbb{C}\)，\(C_i[j]=max\{Ai_[j],B_i[j]\}(1 \leq i \leq d,1 \leq j \leq w)\)。 自适应数据包传输速率 在测量节点上，总是有一个输入队列来缓存数据包。包速率在大多数情况下都是比较低的，但是更糟的情况下，其速度是很高的，输入队列也很快填满了，也就很难记录所有的数据流。上一篇文章SketchVisor使用一个专用组件fast path来容纳高速率的数据包。然而，最差情况下他还要将整个数据结构都进行传输，可能会影响一定的性能。 我们提出了一个方法来应对突发流量。当包数量大于预先设定的阈值时，我们让输入包只到heavy part中，这样保留大数据流，丢弃小数据流。这样一来，只有在以下情况可能发生改变：如果一个bucket里的数据流f由另一个数据流\(f&#39;\)替换，\(f&#39;\)的流大小就被设置成了\(f\)。因此我们需要一个探针，当数据流量速度减小的时候，就回到之前的方法上。 上述方法在损失很小精确度的情况下实现了更高的速度。该策略被激活的时候，我们没有丢弃light part而是阻止其更新。也就是仅仅当数据包速度很快的时候才会发生信息的丢失。 自适应网络流大小分布 对于流大小分布的主要判别依据就是大数据流的数量。我们需要根据数据流的分布来调整heavy part的规模。步骤如下：首先我们向heavy part分配一个小内存空间，随着越来越多的大数据流的加入，heavy part将会满了。我们设定一个阈值T1。当 heavy part满了的时候，我们提出了一下的复制操作：将 heavy part拷贝并与原heavy part合并为一个。哈希函数也从\(h(.)\%w\)变为\(h(.)\%2w\)。这样一来，bucket就节省了一半的空间。 上图所示到达的\(f_2\)数据流哈希到了\(f_3\)的bucket位置上，这样将\(w\)翻倍，由4变到8，\(f_3\)数据流的余数可以变为6，\(f_2\)落到原\(f_3\)的位置上，这样动态实现了网络流大小的分布适应。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SketchVisor: Robust Network Measurement for Soware Packet Processing]]></title>
    <url>%2F2018%2F08%2F23%2F%E7%BD%91%E7%BB%9C%2F2018-8-23-SketchVisor%2F</url>
    <content type="text"><![CDATA[概要 Sketch是一种紧凑的数据结构，以固定的内存大小来统计网络数据包。传统的sketch-based方法都是消耗大量的CPU资源，例如虚拟机或者容器环境下，同样位置的多个应用都会抢占资源。传统的sketch-based算法过于简洁，因此在将其应用到实际环境当中，就需要加入额外的扩展功能从而导致运算量的增加。虽然在数据中心的链路速度并不总是高要求的，但是这依然是重要的指标。 本文提出的SketchVisor是一种针对软件数据包处理的鲁棒性网络测量框架。即使在很高的网络流量当中，SV都会有很好的性能以及很高的准确性。SV 引入了独立的数据通路（fast path）以提供快速但是低准确度的测量，以解决那些不能被及时处理的数据包。之后，通过sketch-based以及fast path准确恢复整个网络范围内的测量结果。 简介 特别的，SV部署在一个分布式的数据平面上，网络管理员将对不同的数据平面上分配任务，如果这些任务过载或者不能被及时处理，那么就会将任务重定向到fast-path上。本文针对fast-path提出了一个top-k算法以跟踪大数据流。Top-k可以实现较低的偿还过程以及缩紧评价指标。还维持了一个全局的计数器用来追踪进入fast-path的网络流，从而来捕获所有较小的网络数据流的特征。 除此之外，SV还部署了个中心化的控制平面来合并本地的测量结果（sketch-based以及fast path的结果），fast path不可避免的会出现准确性的损失，本文形式化了一个矩阵插入问题，使得在控制平面可以恢复这些丢失的数据。 背景 网络测量 本文着重考虑一下的几个网络数据统计量： Heavy hitter：在一个时期中流字节大小超过一定阈值的网络流。 Heavy changer：在两个连续的时期中发生改变的字节大小超过一定的阈值的网络流。 DDos：一个目标host在一定时期中接到的网络数据包超过了阈值。 Superspreader：在一个时期内，源host向多于阈值个目标host发送数据。 Cardinality：势。在一个时期内不同网络流的数量。 Flow size distribution：一个时期内不同字节数范围内的分数大小。 Entropy：一个时期内流大小的熵。 概览 设计目标： 性能 资源效率 精确性 通用性 简洁性 数据层： 在每一个host上都部署了一个测量模块，每一个模块都处理连续不断的数据流并且统计分析该数据。为了防止多次测量，我们可以只测量出或者入的数据，再或者利用哈希来选择监控不连续的数据包。测量模块被分为两个部分，normal path和fast path。Normal path部署一个或者多个sketch-based方法， fast path作为一种补充，通过部署快速但是低准确度的测量方法。正常情况下，在normal path里采用FIFO buffer。 当数据流负载过重时，buffer满了，SV将重定向这部分数据包到fast path，然后收集这部分流量的数据。由网络管理来决定采用哪一种sketch-based方法。 fast path 所面临的挑战是： 足够快一致于可以吸收所有重定向的网络数据流 虽然比normal path的准确度低但是也要保持一定的准确度 对于不同的网络统计来讲具有一定的通用性。 控制层： 从多个host收集本地测量结果并且合并，提供网络范围内的测量结果。目标是当所有流量都走normal path时，在网络范围内提供准确的测量结果。 控制层面临的挑战： 排除fast path 所导致的测量错误，也就是说所有的错误都是由sketch本身所产生的。这样一来，对于fast path 设计带来了巨大挑战，要保证所有的测量任务的兼容。 Fast path Fast path 主要保证了系统的鲁棒性，如果没有这个设计，normal path必定要丢弃那些过载的数据流，从而在准确度上作出妥协。 设计fast path要尽可能多地去追踪网络数据信息，在大多数情况下网络都是被几个较大规模的数据流所占有，这个假设就会引起很多sketch 设计（要求该设计识别大规模数据流），在我们的设计中就着重关注最大规模的数据流，或者前k个数据流（k取决于内存空间）。 如果只关注大规模的数据流，那么必定会忽视小数据流的信息，这些对于基于连通的网络统计量来说也很重要，但同时对于所有的小数据流都进行追踪是不现实的。幸运的是，sketch-based解决方法会估计不同流的统计信息。观察发现小流的影响微不足道，因此我们用一个全局变量计数（此处应该是指统计大数据流），并在控制层来推断具体的sketch统计数据。 方案概览 fast path 算法是基于Misra-Gries‘s算法的top-k算法，但是原算法有两点对于高性能和准确性的限制。首先，改进算法剔除一个小数据流然后加入一个潜在的大数据流，它表现出\(O(k)\)的复杂度去更新k个计数器，当有很多个小的数据流时，节省下来的开销就很可观了。其次，改进算法对于估计top-k条数据流的界限要求比较宽松。我们结合了PLC算法，可以提高偏差数据的准确率。最后，每条数据流都用三个计数器来追踪确保每条流都有严格的上界和下界。 主要思路就是保证top-k条流一直在哈希表H中，当H满了就适当移除一条不满足条件的数据流。当接收到一条大小为v的数据流\(f\)时，先更新统计计数器\(V=V+v\)，如果\(f\)在哈希\(H\)中，那么就更新\(r_f=r_f+v\)，如果\(H\)未满，那么就直接加入\(f\)并初始化为\((E,v,0)\),如果\(H\)已满，那么就要计算一个减小值\(e\)，并对\(H\)中的所有流的\(r\)参数减小\(e\)，\(d\)参数增加\(e\)。倘若有\(r\)小于0那么将被剔除，并加入合适的流。 网络范围内的恢复 基本思想 控制层通过周期性的收集本地数据提供全网范围内的测量数据，它可以通过矩阵加将所有的sketch合并到一个sketch上（合并后的结果用N来表示），将多个哈希表合并成一个，并且将计数器的结果合并成一个，注意到之前算法有不确定性，因此它只维护top-k个数据流并且没有跟踪到具体的某一个小的数据流上。这部分的研究目标就是精确恢复。 我们分解网络流数据成两个向量，\(x\)表示哈希表\(H\)中的流实际的字节数，\(y\)表示其他流实际的字节数。如果一个流不存在，那么所有的数据就都是0了。\(x+y\)就表示了fast-path中的每一个数据流。 为了恢复出所有的网络流T，我们可以将fast path中的所有流都注入到normal path中，本质就是用sketch方法来处理\(x+y\)，表示为\(sk(x+y)\)， \[ T=N+sk(x+y) \] 由于fast path 并不是追踪到每条数据流，因此\(x\)和\(y\)实际上是未知的，但是我们可以通过统计量来明确其值的限制条件。\(x\)和\(y\)的\(l_1\)范数之和可以如下表示： \[ \lVert x\rVert_1 + \lVert y\rVert_1 = V \] 除此之外，合并后的哈希表H也给出了每条流的上/下确界： \[ rf+df \leq xf \leq rf+df+ef \] 前两个等式表述的是网络流的聚集合并特性，第三个式子表示的是每条流的错误区间。但是上述信息还不够完整全面，有很多工作都针对其做矩阵插入的解决方案，本文则着力于找到最佳的估计矩阵T，以实现最好的恢复效果。 压缩感知 首先明确出\(T，x，y\)的特性 \(T\)接近是一个低秩矩阵。网络中大多数都是较大流量的数据流，又因为大数据流会引起更多的重视，因此，计数器的统计量大多近似。 \(x\)和\(sk(x)\)是稀疏的。因为\(x\)只包含top-k条流在哈希表中，且整张表的规模是非常大的，因此我们可以将\(x\)视作一个稀疏向量，又因为\(x\)在sketch算法中由计数器限定了一定的数量，所以\(sk(x)\)也是稀疏的。 \(y\)和\(sk(y)\)是低噪的。由y所记录的所有数据流都是规模小且区分度低。因此我们可以将y视作一个低噪的向量。 我们使用奇异值分解方法，对几个sketch矩阵产生了低秩近似。 目标函数 我们将上述的特性引入到目标函数当中，然后利用压缩感知框架LENS去恢复T，LENS就是这样一种算法，可以将网络流矩阵分解成低秩、稀疏并且低噪的部分。通过LENS我们将目标函数设定为： \[ minimize: \alpha\lVert T\rVert_* + \beta\lVert x\rVert_1 + \frac{1}{2\gamma}\lVert y\rVert^2_F \] \(\lVert T\rVert_*\) : T的核范数，可以约束低秩矩阵。 \(\lVert x\rVert_1\) : x的l1范数，约束x的稀疏性。 \(\lVert y\rVert^2_F\) :Frobenius 范数，约束y里面的大元素。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mininet拓扑学习]]></title>
    <url>%2F2018%2F04%2F24%2F%E7%BD%91%E7%BB%9C%2F2018-4-24-Mininet%E6%8B%93%E6%89%91%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Mininet /Mininet API给出了相当丰富的功能，本篇对各函数总结归纳。 拓扑结构 Top build() addSwitch() addHost() addLink() start() stop() net.hosts from mininet.topo import Topofrom mininet.net import Mininetfrom mininet.util import dumpNodeConnectionsfrom mininet.log import setLogLevelclass SingleSwitchTopo(Topo): "Single switch connected to n hosts." def build(self, n=2): switch = self.addSwitch('s1') # Python's range(N) generates 0..N-1 for h in range(n): host = self.addHost('h%s' % (h + 1)) self.addLink(host, switch)def simpleTest(): "Create and test a simple network" topo = SingleSwitchTopo(n=4) net = Mininet(topo) net.start() net.stop()if __name__ == '__main__': # Tell mininet to print useful information setLogLevel('info') simpleTest() 网络工具 pingAll(): 测试网络所有节点的连通性，注意保证节点都在net中，否则不测试。 dumpNodeConnections():截获节点之间的连通并进行分析。 iperf(): 测试两个节点之间的网络性能，返回网速。 性能设定（以参数方法实现） self.addHost(name, cpu=f): 可以指定一个小数，意义是让CPU分配一定比例(设定的百分数)的CPU资源给虚拟主机。 self.addLink(node1, node2, bw=10, delay='5ms', max_queue_size=1000, loss=10, use_htb=True): 以bw(bandwidth)，delay，以及loss的值建立一个双向连接，最大等待队列长度为1000且启用HTB算法(提高带宽利用率且限制P2P海量软件的下载)。 #!/usr/bin/pythonfrom mininet.topo import Topofrom mininet.net import Mininetfrom mininet.node import CPULimitedHostfrom mininet.link import TCLinkfrom mininet.util import dumpNodeConnectionsfrom mininet.log import setLogLevelclass SingleSwitchTopo( Topo ): "Single switch connected to n hosts." def build( self, n=2 ): switch = self.addSwitch( 's1' ) for h in range(n): # Each host gets 50%/n of system CPU host = self.addHost( 'h%s' % (h + 1), cpu=.5/n ) # 10 Mbps, 5ms delay, 2% loss, 1000 packet queue self.addLink( host, switch, bw=10, delay='5ms', loss=2, max_queue_size=1000, use_htb=True )def perfTest(): "Create network and run simple performance test" topo = SingleSwitchTopo( n=4 ) net = Mininet( topo=topo, host=CPULimitedHost, link=TCLink ) net.start() print "Dumping host connections" dumpNodeConnections( net.hosts ) print "Testing network connectivity" net.pingAll() print "Testing bandwidth between h1 and h4" h1, h4 = net.get( 'h1', 'h4' ) net.iperf( (h1, h4) ) net.stop()if __name__ == '__main__': setLogLevel( 'info' ) perfTest() 指令 cmd() 由于每一个host主机都是作为bash shell来进行模拟的，所以理论上可以支持所有终端指令 h1 = net.get('h1')result = h1.cmd('ifconfig')print result]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Networking</tag>
        <tag>Mininet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序(位图数据结构)]]></title>
    <url>%2F2018%2F04%2F02%2F%E7%AE%97%E6%B3%95%2F2018-4-2-%E6%8E%92%E5%BA%8F(%E4%BD%8D%E5%9B%BE%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84)%2F</url>
    <content type="text"><![CDATA[对于规模比较大的数据集，但又不是特别特别大的数据集来说，使用位图数据结构的排序是一个不错的选择。 注：要求数据没有重复。 位图/位向量 表示一个整数合集{1，2，3，5，8，13}可以使用如下字符串： 0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 这种表示方法，1MB大小的空间可以表示月800万个数字，与十进制的7位数字1000万接近。 // phase 1: initialize set to emptyfor i = [0,n] bit[i] = 0;// phase 2: insert present elements into the setfor each i in the input file bit[i] = 1;//phase 3: write sorted outputfor i = [0,n] if bit[i] == 1 write i on the output file 位图数据结构还可以用来检查数据集的重复性 （编程珠玑）]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[路由协议汇总整理]]></title>
    <url>%2F2017%2F11%2F28%2F%E7%BD%91%E7%BB%9C%2F2017-11-28-%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE%E6%B1%87%E6%80%BB%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[IGP主内，EGP主外 IGP 是网内路由协议，运行在单一的自治系统内部(autonomous system，AS)内决策路由。 EGP 是网间路由协议，是一种在AS的相邻两个网关主机间交换路由信息的协议。 IGP 距离矢量协议：听信谣言 类似的，假如你要从A到D地区，先问路人甲如何从A到B,再问路人乙如何从B到C，最后问路人丙如何从C到D。这样的话引申出了RIP协议的缺陷： * RIP限制了网络的规模，能使用的最大距离为15(16表示不可达) * 其次路由器交换的信息是路由器的完整路由表，因而随着网络规模的扩大，开销也就增加 * “坏消息传播得慢”，使更新过程的收敛时间过长。 链路状态路由协议：全局考量 类似的，假如你要从A到D地区，先下载全国的地图，然后根据拥堵情况等等，在本地计算最近的路径。其优点是： * 创建拓扑图(SPF树)，路由器可以独立确定通向每个网络的最短路径。 * 收敛快速，当收到一个LSP(链路状态数据包)后链路状态路由协议立即将该LSP从除接收该LSP的接口以外的所有接口flooding出去。 * 事件驱动更新:仅在拓扑发生改变的时候才发出LSP,而距离路由协议则会定期发送更新。 * 层次设计：区域的概念使得多个区域行程了层次化的结构。 OSPF&amp;IS-IS OSPF 支持NBMA以及点对多点链接，但是IS-IS不支持 IS-IS直接建立在L2上，而OSPF则是基于IP,因此IS-IS有更好的安全性。 OSPF可以支持虚拟链路但是IS-IS不可以(因为它建立在L2上) OSPF选举DR(Designated Router)和BDR(Backup Designated Router),(注意这里是先选举BDR然后才选举DR,因为如果反过来当选举BDR的时候DR失效，切换将无法进行，状态机也没法切换)，这样不容易被预抢占。反之IS-IS使用单一的DIS。 EGP 一般局域网中用不到，在大网中使用。底层还是要IGP来负责。现在EGP里面主要用的就是BGP。 BGP BGP用于在不同的自治系统（AS）之间交换路由信息。当两个AS需要交换路由信息时，每个AS都必须指定一个运行BGP的节点，来代表AS与其他的AS交换路由信息。这个节点可以是一个主机。但通常是路由器来执行BGP。两个AS中利用BGP交换信息的路由器也被称为边界网关（Border Gateway）或边界路由器（Border Router）。 由于可能与不同的AS相连，在一个AS内部可能存在多个运行BGP的边界路由器。同一个自治系统(AS)中的两个或多个对等实体之间运行的BGP 被称为 IBGP（Internal/Interior BGP）。归属不同的AS的对等实体之间运行的BGP称为EBGP （External/Exterior BGP）。在AS边界上与其他AS交换信息的路由器被称作边界路由器(border/edge router)。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[马哈拉诺比斯距离(马氏距离)]]></title>
    <url>%2F2017%2F11%2F22%2F%E6%A6%82%E5%BF%B5%2F2017-11-22-%E9%A9%AC%E5%93%88%E6%8B%89%E8%AF%BA%E6%AF%94%E6%96%AF%E8%B7%9D%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[计算马氏距离 马氏距离用来表示数据的协方差距离。他可以有效地计算两个未知样本集的相似度，他也考虑到各种特性之间的联系。对于一个均值为 \(μ = (μ_1,μ_2,μ_3,...,μ_p)^T\)，协方差矩阵为 \(\Sigma\) 的多变向量 \(x = (x_1,x_2,x_3,...,x_p)^T\) 其马氏距离为： \[ D_M(x) = \sqrt{(x-μ)^T\Sigma^{-1}(x-μ)} \] 马氏距离也可以定义为两个服从同一分布并且协方差矩阵为 \(\Sigma\) 的随机变量 \(\vec{x}\) 与 \(\vec{y}\) 的差异程度： \[d(\vec{x},\vec{y}) = \sqrt{(\vec{x}-\vec{y})^T\Sigma^{-1}(\vec{x}-\vec{y})}\] 如果协方差矩阵为单位矩阵，马氏距离就简化为欧氏距离，如果协方差矩阵为对角矩阵，也可以称为正规化的欧氏距离： \[ d(\vec{x},\vec{y}) = \sqrt{\sum_{i=1}^{p}\frac{(x_i-y_i)^2}{\sigma_i^2}}\] 理解马氏距离 如下是一个离散图 将上图的坐标轴去掉 重新建立坐标，原点就应该在这些离散点的中心位置。蓝色的坐标轴将沿着这些离散点的伸展方向建立，使得绝大多数的点都在坐标轴附近，红色的坐标轴垂直蓝色的坐标轴建立(在大于二维的场景中，尽可能保持坐标轴的建立保持最大的相斥角度，从而保证建立的坐标轴能靠近更多的点)。 在新建立的坐标轴上也应当有新的尺度来度量。常常用68-95-99.7原则：大约三分之二(68%)的点应当在一个单位之内；大约95%的点应当在两个单位之内。 按照上述方法建立的坐标轴围成的不是一个标准的圆圈，横纵坐标单位长度的不统一导致了其是一个较为扭曲的圆圈。如果将上述图形重新标准化绘制成我们较为熟悉的样子，那么坐标上的距离就成了马氏距离。 翻译自 Bottom to top explanation of the Mahalanobis distance?]]></content>
      <categories>
        <category>Concept</category>
      </categories>
      <tags>
        <tag>Concept</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[奇异值分解]]></title>
    <url>%2F2017%2F11%2F22%2F%E6%A6%82%E5%BF%B5%2F2017-11-22-%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[奇异值分解 奇异值分解(singular value decomposition, SVD) 假设\(M\)是一个\(m*n\)阶矩阵，其中的元素全部属于域\(K\),也就是实数域或复数域。如此存在一个分解使得： \[ M=U\Sigma V^\ast\] 其中\(U\)是\(m\ast n\)阶酉矩阵,\(\Sigma\)是\(m\ast n\)阶非负实数对角矩阵,\(V^\ast\) 是\(V\)的共轭转置，是\(n\ast n\)阶酉矩阵。这样的分解就是 \(M\)的奇异值分解。\(\Sigma\) 对角线上的元素 \(\Sigma_{i,j}\) 即为奇异值分解，常见情况下将奇异值由大到小排列。如此 \(\Sigma\) 便能由\(M\)唯一确定。 V的列组成一套对M的正交"输入"或"分析"的基向量，也是 \(M\ast M\) 的特征向量。 U的列组成一套对M的正交"输出"基向量，也是 \(MM\ast\) 的特征向量。 \(\Sigma\) 对角线上的元素是奇异值，可视为是在输入与输出间进行的纯量的"膨胀控制"，这些是 \(MM\ast\) 及 \(M\ast M\) 的特征值的非负平方根，并与 \(U,V\) 相对应。 直观解释 上述图片中： 左上：单位圆上有两个正交单位向量。 右上：单位圆在 \(M\) 和奇异值 \(\sigma_1,\sigma_2\) 下的转换。 左下：单位圆通过 \(V^\ast\) 的旋转。 右下：单位圆通过 \(\Sigma V^\ast\) 的变形，其中 \(\Sigma\) 缩放了水平与垂直的比例。 举例 \[ M= \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; 2\\\\ 0 &amp; 0 &amp; 3 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix} \] 奇异值分解后的结果如下： \[ U=\begin{bmatrix} 0 &amp; 0 &amp; 1 &amp; 0\\\\ 0 &amp; 1 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 1\\\\ 1 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}, \Sigma=\begin{bmatrix} 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 3 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; \sqrt{5} &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}, V^*=\begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\\\ \sqrt{0.2} &amp; 0 &amp; 0 &amp; 0 &amp; \sqrt{0.8}\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\ \sqrt{0.8} &amp; 0 &amp; 0 &amp; 0 &amp; -\sqrt{0.2} \end{bmatrix} \] 注意矩阵 \(\Sigma\) 的所有非对角元为0，矩阵 \(U,V\) 都是酉矩阵，它们乘上各自的共轭转置都得到单位矩阵。由于 \(U,V^*\) 都是实矩阵，故它们都是正交矩阵。 \[ UU^\ast =\begin{bmatrix} 0 &amp; 0 &amp; 1 &amp; 0\\\\ 0 &amp; 1 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 1\\\\ 1 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}\ast \begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 1\\\\ 0 &amp; 1 &amp; 0 &amp; 0\\\\ 1 &amp; 0 &amp; 0 &amp; 0\\\\ 1 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix} = \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} =I_4 \] \[ VV^\ast =\begin{bmatrix} 0 &amp; 0 &amp; \sqrt{0.2} &amp; 0 &amp; \sqrt{0.8}\\\\ 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\ 0 &amp; 0 &amp; \sqrt{0.8} &amp; 0 &amp; -\sqrt{0.2} \end{bmatrix}\ast \begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\\\ \sqrt{0.2} &amp; 0 &amp; 0 &amp; 0 &amp; \sqrt{0.8}\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\ \sqrt{0.8} &amp; 0 &amp; 0 &amp; 0 &amp; -\sqrt{0.2} \end{bmatrix}= \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} =I_5 \] 由于 \(\Sigma\) 有一个对角元是0，所以这个奇异值分解值不是唯一的，例如 V 可以为： \[ V^\ast = \begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\\\ \sqrt{0.2} &amp; 0 &amp; 0 &amp; 0 &amp; \sqrt{0.8}\\\\ \sqrt{0.4} &amp; 0 &amp; 0 &amp; \sqrt{0.5} &amp; -\sqrt{0.1}\\ -\sqrt{0.4} &amp; 0 &amp; 0 &amp; \sqrt{0.5} &amp; \sqrt{0.1} \end{bmatrix} \]]]></content>
      <categories>
        <category>Concept</category>
      </categories>
      <tags>
        <tag>Concept</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[张量(Tensor)]]></title>
    <url>%2F2017%2F10%2F31%2F%E6%A6%82%E5%BF%B5%2F2017-10-31-%E5%BC%A0%E9%87%8F(Tensor)%2F</url>
    <content type="text"><![CDATA[张量 张量的概念在数学物理领域有多种定义，从计算机的角度来说： 单个的数值：Scalar 一维的数组：Vector 二维的数组：Matrix 三维及以上的数组：Tensor 在某些计算机领域(如深度学习)，n维数组统称为Tensor。 张量的模展开矩阵(Tensor Unfolding) 张量的模展开矩阵，主要任务是对张量进行降维，转化为矩阵。在张量的矩阵展开过程中，是对组成张量的所有阶按交错次序采样，并非简单采取某一阶的特征值再采取另一阶的特征值，这样在采集过程中实现了张量不同阶特征值之间的传递和融合。 例：A是一个(4×3×2)三阶张量 对A第一阶模展开矩阵是一个4×6矩阵： 对A的第二阶模展开矩阵是一个3×8矩阵： 对A的第三阶模展开矩阵是一个2×12矩阵：]]></content>
      <categories>
        <category>Concept</category>
      </categories>
      <tags>
        <tag>Concept</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-中断和中断处理]]></title>
    <url>%2F2017%2F10%2F22%2FLinux%2F2017-10-22-Linux%E4%B8%AD%E6%96%AD%E5%92%8C%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[中断 不同的设备对应的中断不同，而每个中断都通过一个唯一的数字标志，从而使得操作系统能够对中断进行区分，并且知道哪个硬件设备产生了哪个中断。 每个中断值通常被称作中断请求(IRQ)线。每个IRQ县都会被关联一个数值量(例如 IRQ 0 是时钟中断，IRQ 1是键盘中断)。对于连接在PCI总线上的设备而言，中断是动态分配的。 异常 异常与中断不同，它在产生时必须考虑与处理器时钟同步，因此异常也被称作同步中断。内核对于中断与异常的处理比较类似。 中断处理程序 在响应一个特定中断的时候，内核会执行一个函数，该函数叫做中断处理程序或者中断服务例程(interrupt service routine, ISR)。产生中断的每个设备都有一个相应的中断处理程序。 在Linux中，中断处理程序就是C函数，只不过这些函数必须按照特定的类型声明。ISR与其他内核函数的区别就是ISR是被内核调用来响应中断的，而它们运行于我们称之为中断上下文的特殊上下文中。 上半部与下半部的对比 中断处理程序是上半部(top half)——接收到一个中断，就开始立即执行，但是只做有严格时限的工作，例如对接收的中断进行应答或者复位。此后，在合适的时机，下半部会被开中断执行。 注册中断处理程序 中断处理程序是管理硬件的驱动程序的组成部分。每一设备都有相关的驱动程序，如果设备使用中断，那么相应的驱动程序就注册一个中断处理程序。 驱动程序可以通过request_irq()函数注册一个中断处理程序。 // arch/sparc/kernel/irq.c//// irq: 要分配的中断号，对于系统时钟或者键盘等，这个值是确定的，但是对于其他设备这个值可以探测获取或者编程动态确定。// handler：指针指向处理这个中断的实际中断处理程序。int request_irq(unsigned int irq, irqreturn_t (*handler)(int, void *, struct pt_regs *), unsigned long irqflags, const char * devname, void *dev_id) 中断处理程序标志 request_irq第三个参数flags可以为0，也可能是下列一个或多个标志的位掩码。这些标志中最重要的是： IRQF_DISABLED——该标志被设置后，意味着内核在处理中断处理程序本身期间，要禁用所有其他中断。如果不设置，中断处理程序可以与其它任何中断同时运行。 IRQF_SAMPLE_RANDOM——表明这个设备产生的中断对内核熵池(提供从各种随机事件导出的真正的随机数)有贡献。 IRQF_TIMER——该标志是特别为系统定时器的中断处理而准备的。 IRQF_SHARED——表明可以在多个中断处理程序之间共享中断线。在同一个给定线上注册的每个处理程序必须指定这个标志，否则每条线上只能有一个处理程序。 第四个参数name是与中断相关的设备的ASCII文本，例如PC机上键盘中断对应的这个值为"keyboard"。 第五个参数dev_id用于共享中断线。当一个中断处理程序需要释放时，dev将提供唯一的标志信息，以便从共享中断线的诸多中断处理程序中删除指定的那一个。如果没有这个参数，那么内核不可能知道在给定的中断线上到底删除哪一个处理程序。 注意 request_irq 成功执行会返回0.如果返回非0就代表有错误发生，在这种情况下，指定的中断处理程序不会被注册。常见的错误如 -EBUSY 表示给定的中断线已经在使用。 request_irq 函数可能会睡眠，因此不能再中断上下文或其他不允许阻塞的代码中调用该函数。在注册的过程中，内核需要在/proc/irq 文件中创建一个与中断对应的项。函数proc_mkdir()就是用来创建这个新的procfs项的，其中调用函数proc_create()对这个新的profs进行设置，而proc_create()会调用函数kmalloc()来请求分配内存，这里的kmalloc()是可以睡眠的。 释放中断处理程序 卸载驱动程序时，调用： /** * free_irq - free an interrupt * @irq: Interrupt line to free * @dev_id: Device identity to free * * Remove an interrupt handler. The handler is removed and if the * interrupt line is no longer in use by any driver it is disabled. * On a shared IRQ the caller must ensure the interrupt is disabled * on the card it drives before calling this function. The function * does not return until any executing interrupts for this IRQ * have completed. * * This function must not be called from interrupt context. */void free_irq(unsigned int irq, void *dev_id)&#123; ...&#125; 如果指定的中断线不是共享的，那么该函数删除处理程序的同时将禁用这条中断线,如果是共享的则删除dev_id所对应的处理程序，而这条中断线本身只有在删除了最后一个处理程序时才会被禁用。 中断上下文 当执行一个中断处理程序时，内核处于中断上下文(interrput context)中。 注意进程上下文是一种操作模式，此时内核代表进程执行——执行系统调用或运行内核线程。进程上下文可以睡眠也可以调度程序。 然而中断上下文与之相反，二者没有什么瓜葛。与current宏也是不相干的。中断上下文不可以睡眠，因此不能从中断上下文中调用某些函数。如果一个函数睡眠，就不能在你的中断处理程序中使用它。 中断上下文具有较为严格的时间限制，因为他打断了其他代码。代码应当迅速简洁尽量不要使用循环去处理繁重的工作。 中断处理机制的实现 设备产生中断，通过总线把电信号发送给中断控制器。如果中断线是激活的(它们允许被屏蔽)，那么中断控制器就会把中断发往处理器。在大多数的体系结构中，这个工作就是通过电信号给处理器的特定管脚发送一个信号。除非在处理器上禁止该中断，否则处理器会立即停止他正在做的事情，关闭中断系统，跳到内存中预定义的位置开始执行那里的代码，这个预定义的位置由内核设置，是中端处理程序的入口点。 由于每条中断线处理器都会跳到对应的一个唯一的位置，这样内核就可以知道所接收中断的IRQ号。初始入口点只是在栈中保存这个号，并存放当前寄存器的值(被中断的任务)，然后内核调用do_IRQ() unsigned int do_IRQ(struct pt_regs regs) 接下来do_IRQ()需要确保在这条中断线上有一个有效的处理程序，而且这个程序已经启动，当时当前并没有执行。do_IRQ()调用handle_IRQ_event()来运行为这条中断线所安装的中断处理程序。 中断控制 Linux 内核提供了一组接口用于操作机器上的中断状态。这些接口提供了能够禁止当前处理器的中断系统，或者屏蔽掉整个机器的一条中断线的能力。 一般控制中断系统的原因就是需要提供同步。通过禁止中断，可以确保某个中断处理程序不会抢占当前的代码，此外还可以禁止内核抢占。由于Linux支持多处理器，因此内核代码会用锁保护机制，防止多个处理器的并发访问，而禁止中断提供保护机制。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-下半部和推后执行的工作"]]></title>
    <url>%2F2017%2F10%2F22%2FLinux%2F2017-11-2-Linux-%E4%B8%8B%E5%8D%8A%E9%83%A8%E5%92%8C%E6%8E%A8%E5%90%8E%E6%89%A7%E8%A1%8C%E7%9A%84%E5%B7%A5%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[中断机制有一些局限，包括： 1. 中断以异步方式执行，并且有可能会打断其他重要代码。为了避免被打断的代码停止过长时间，中断处理应该执行得越快越好。 2. 如果当前有一个中断处理程序正在执行，最好情况下该中断同级的其他中断会被屏蔽；最坏情况下当前处理器上所有的其他中断都会被屏蔽。因为禁止中断后硬件与操作系统无法通信，所以中断处理程序执行得越快越好。 3. 中断往往需要对硬件进行操作，所以它们通常有很高的时限要求。 4. 中断不能再进程上下文中进行，所以不能阻塞。 正因如此，中断处理流程被分为两部分，第一部分是中断处理程序(上半部)，内核对它的异步执行完成对硬件中断的及时响应。另一部分就是下半部。 下半部 理想情况下中断(上半部)完成的工作越少越好，将所需处理的工作都留给下半部，但是中断程序注定要做一些工作，虽然不是严格要求，但是可以参考如下： 1. 对时间非常敏感，将其放在中断处理程序中执行。 2. 和硬件相关，将其放在中断处理程序中执行。 3. 要保证不被其他中断打断，将其放在中断处理程序中执行。 4. 其他所有任务都放在下半部执行。 软中断 软中断的实现 软中断是在编译期间静态分配的。有softirq_action结构表示，总共有32个该结构体的数组。 // linux/interrupt.hstruct softirq_action&#123; void (*action)(struct softirq_action *);&#125;; 每个被注册的软中断都占据一项，最多有32个软中断。 软中断处理程序 action的函数原型如下： void softirq_handler(struct softirq_action *) 一个软中断不会抢占另外一个软中断，只有中断处理程序才会抢占软中断，不过多个软中断可以在其他处理器上同时执行。 执行软中断 通常中断处理程序会在返回前标记它的软中断，使其稍后执行(触发软中断)。在以下情况，待处理的软中断会被检查和执行： 1. 从一个硬件中断代码处返回 2. 在ksoftirqd内核线程中 3. 在那些显示检查和执行待处理的软中断的代码中，如网络子系统中 tasklet tasklet是利用软中断实现的一种下半部机制，他和进程没有任何关系。tasklet的接口更简单，锁保护也要求比较低。通常情况下应该选用tasklet而非软中断。 tasklet的实现 因为tasklet是通过软中断实现的，所以它本身也是软中断，由两类软中断代表：HI_SOFIRQ和TASKLET_SOFTIRQ。其中HI_SOFTIRQ类型软中断要优先于TASKLET_SOFTIRQ。 tasklet结构体 // linux/interrupt.hstruct tasklet_struct&#123; struct tasklet_struct *next; //链表中的下一个tasklet unsigned long state; //tasklet 的状态 atomic_t count; //引用计数器 void (*func)(unsigned long); //tasklet 处理函数 unsigned long data; //给tasklet处理函数的参数&#125; func是tasklet的处理程序，data是它唯一的参数。 state只能在0，TASKLET_STATE_SCHED和TASKLET_STATE_RUN之间取值。TASKLET_STATE-SCHED表示tasklet已被调度准备投入运行；TASKLET_STATE_RUN表明tasklet正在运行(多用在多处理器上)。 count如果不是0，则tasklet被禁止不允许执行；当他为0时tasklet才允许被激活，并且被设置为挂起状态。 调度tasklet 已调度的tasklet存放在两个单处理器数据结构：tasklet_vec(普通tasklet)和tasklet_hi_vec(高优先级的tasklet)，这两个tasklet_struct结构体构成的链表。 执行步骤如下： 1. 检查tasklet的状态是否为TASKLET_STATE_SCHED。如果是则说明已经被调度过了，函数立即返回。 2. 调用_tasklet_schedule()。 3. 保存中断状态，然后禁止本地中断。在我们执行tasklet代码时，这么做能够保证当tasklet_schedule()处理这些tasklet时，处理器上的数据不会乱。 4. 把需要调度的tasklet加到每个处理器一个的tasklet_vec链表或tasklet_hi_vec链表的表头上去。 5. 唤起TASKLET_SOFTIRQ或HI_SOFTIRQ软中断，这样在下一次调用do_softirq()时就会执行tasklet。 6. 恢复中断到原状态并返回。 工作队列 工作队列可以把工作推后，交由一个内核线程去执行，这样工作队列执行的代码能占尽进程上下文的所有优势。工作队列允许重新调度甚至是睡眠。 工作队列：推后执行的任务需要睡眠，且需要用一个内核线程来推后执行工作。 tasklet：推后执行的任务不需要睡眠 工作队列的实现 工作队列可以让你的驱动程序创建一个专门的工作者线程来处理需要推后的工作，不过工作队列子系统提供了一个缺省的工作者线程 events/n来处理上述过程。这里的n是处理器的编号，每个处理器对应一个线程。例如单处理器系统就是有 events/0 线程，双处理器就多了 events/1 线程。许多内核驱动程序都把下半部交给缺省的工作者线程去做。 使用工作队列 首先就是创建一些需要推后完成的工作： DECLARE_WORK(name, void(*func) (void *), void *data); 以上代码创建一个名为name，处理函数func，参数为data的work_struct结构体。 工作队列处理函数 void work_handler(void *data) 这个函数由一个工作者线程执行。默认情况下会响应中断，并且不持有任何锁。 对工作进行调度 想要把给定的工作的处理函数提交给缺省的events工作线程，只需调用： schedule_work(&amp;work); work就会马上调度，一旦其所在的处理器上的工作者线程唤醒，他就会执行。如果需要在一定的延时之后再进行调度： schedule_delayed_work(&amp;work, delay)； 刷新操作 排入队列的工作会在工作者线程的下一次被唤醒时执行，有时，为了防止竞争条件的出现，可能需要确保不再有待处理的工作。出于以上目的，内核准备了一个用于刷新指定工作队列的函数： void flush_scheduled_work(void) 该函数会一直等待直到队列中所有对象都被执行以后返回，在等待过程中所有待处理的工作时，该函数会进入休眠状态]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-系统调用]]></title>
    <url>%2F2017%2F10%2F20%2FLinux%2F2017-10-20-Linux%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[与内核通信 系统调用在用户空间进程和硬件设备之间添加了一个中间层，作用如下： 1. 为用户空间提供了一种硬件的抽象接口。当需要读写文件时，程序可以不去管磁盘类型和介质，甚至不用管文件所在文件系统到底是哪种类型。 2. 保证系统的稳定和安全。内核可以基于权限、用户类型和其他一些规则对需要进行的访问进行裁决。 3. 每个进程都运行在虚拟系统中。 API &amp; POSIX &amp; C库 API: 定义了一组应用程序使用的编程接口，可以用一个系统调用实现，也可以通过调用多个系统调用来实现，也可以完全不使用系统调用。下图即为一个例子。 POSIX定义的API函数和系统调用之间有着直接关系，且C库提供了POSIX的绝大部分的API。 系统调用 在Linux中访问系统调用(syscall)，通常要用C库中定义的函数调用来进行。他们通常要定义几个参数。 系统调用号 在Linux中，每个系统调用被赋予一个系统调用号。当用户空间的进程执行一个系统调用的时候，这个系统调用号就用来指明到底是要执行哪个系统调用：进程不会提及系统调用的名称。 系统调用号一旦被分配就不会再有任何改变，否则编译好的应用就会崩溃。此外如果一个系统调用被删除，他所占用的系统调用号也不允许被回收利用，否则以前编译过的代码会调用这个系统调用。在Linux中有一个"未实现"系统调用sys_ni_syscall()，它除了返回-ENOSYS外不做任何工作，这个错误号就是专门针对这个无效的系统调用而设。 内核记录了系统调用表中的所有已注册的系统调用的列表，存储在sys_call_table中。 系统调用的性能 快速高效 系统调用处理程序 用户空间的程序无法直接执行内核代码。 通知内核的机制是靠软中断实现的：通过引发一个异常来促使系统切换到内核态去执行异常处理程序。此时的异常处理程序实际上就是系统调用处理程序。在x86系统上预定义的软中断是中断号128，通过 int $0x80 指令触发该终端。 指定恰当的系统调用 因为所有的系统调用陷入内核的方式都一样，因此还需要将系统调用号一并传给内核。在x86，系统调用号通过eax寄存器传递给内核。 system_call()函数通过将给定的系统调用号与NR_syscalls做比较来检查其有效性。如果它大于或者等于NR_syscalls,将函数就返回-ENOSYS。否则，就执行相应的系统调用： call *sys_call_table(,%rax,8) 参数传递 除了系统调用号以外，大部分系统调用都还需要一些外部的参数输入。所以，在发生陷入的时候，应该把这些参数从用户空间传给内核。最简单的办法就是把这些参数也存放到寄存器中。在x86-32系统上，ebx，ecx，edx，esi，edi按照顺序存放前5个参数。需要六个或以上的情况时，需要一个单独的寄存器存放指向所有这些参数在用户空间地址的指针。 用户空间的返回值也通过寄存器传递。在x86系统上，他存放在eax寄存器中。 系统调用的实现 实现系统调用 Linux 不提倡采用多用途的系统调用(一个系统调用通过传递不同的参数值来选择完成不同的工作)。很多系统共了标志参数确保向前兼容。标志并不是用来让单个系统调用具有多个不同的行为，而是为了即使增加新的功能和选项，也不破坏向后兼容或不需要增加新的系统调用。 参数验证 系统调用必须检查所有的参数是否合法有效。 举例来说，与文件I/O相关的系统调用必须检查文件描述符是否有效。与进程相关的函数必须检查提供的PID是否有效。 最重要的一种检查就是检查用户提供的指针是否有效。内核必须保证： * 指针指向的内存区属于用户区域，进程决不能哄骗内核去读内核空间的数据。 * 指针指向的内存区在进程的地址空间里。进程决不能哄骗内核去读其他进程的数据。 * 如果是读，该内存应被标记为可读；如果是写，该内存被标记为可写；如果是可执行，该内存应该被标记为可执行。进程决不能绕过内存访问限制。 //Copy a block of data into user space, with less checking.//void __user * to//Destination address, in user space.//const void * from//Source address, in kernel space.//unsigned long n//Number of bytes to copy.unsigned long __copy_to_user ( void __user * to, const void * from, unsigned long n); //Name: Copy a block of data from user space, with less checking.//Arguments//void * to//Destination address, in kernel space.//const void __user * from//Source address, in user space.//unsigned long n//Number of bytes to copy.unsigned long __copy_from_user ( void * to, const void __user * from, unsigned long n); 上述两个函数都有可能引起阻塞。当包含用户数据的页被换出到硬盘上而不是在物理内存上的时候，这种情况就会发生。此时，进程就会休眠，直到缺页处理程序将该页从硬盘重新换回物理内存。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-进程调度]]></title>
    <url>%2F2017%2F10%2F17%2FLinux%2F2017-10-17-Linux%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[多任务 多任务OS可以使得多个进程处于堵塞或者睡眠状态，也就是说，实际上不被投入运行直到工作确实就绪。这些任务尽管位于内存，但并不处于可运行状态。相反，这些进程利用内核阻塞自己，直到某一事件触发。 抢占式任务 &amp; 非抢占式任务 抢占式任务有调度程序来决定什么时候停止一个进程的运行，以便其他进程可以得到执行机会。在这样的系统下，进程可以运行的时间都是被提前预设好的，这一段时间被称作时间片(timeslice)。现代操作系统中系统对程序运行都采用动态时间片计算的方式。 在非抢占式任务模式下，除非程序自己停止，否则它会持续运行。进程主动挂起被称作让步，但是可能会有很多问题超出用户的预料。Linux 使用的是抢占式的多任务模式。 Linux进程调度 I/O消耗型 &amp; 处理器消耗型进程 I/O消耗型：进程大部分时间用来提交I/O请求或者等待I/O请求。这样的进程经常处于可运行状态，但通常都是运行时间较短，因为他们在等待I/O时总是会阻塞。 处理器消耗型：进程时间大多用于执行代码。除非被抢占否则这部分进程总是在运行。从相应速度考虑，操作系统尽量降低这部分进程的调度频率，从而延长其运行时间。 当然，上述划分并不绝对，有些进程满足以上两个特点，在不同时刻对处理器的要求完全不同。 进程优先级 Linux采用了两种不同的优先级: 第一种是nice值(-20 到 +19)，默认为0；越大的nice值意味着更低的优先级，nice绝对值代表时间片的比例。 第二种是实时优先级(默认情况是0到99)。越高的实时优先级意味着进程优先级越高。任何实时进程的优先级都高于普通的进程，也就是说实时优先级和nice优先级处于互不相交的范畴。 时间片 时间片标明进程在被抢占前所能持续运行的时间。Linux没有直接分配时间片到进程，它是将处理器的使用比划分给进程，这样，进程所获得的处理器时间其实和系统负载密切相关。 在Linux中的CFS抢占时机完全由进程优先级和是否有时间片决定，取决于新的可运行程序消耗了多少处理器使用比。如果消耗的使用比比当前进程小，则新进程立刻投入运行，抢占当前进程。否则推迟运行。 Linux调度算法 CFS(完全公平调度算法) CFS:允许每个进程运行一段时间、循环轮转、选择运行最少的进程作为下一个运行进程，而不再采用分配给每个进程时间片的做法。CFS在所有可运行进程总数基础上计算出一个进程应该运行多久，而不是依靠nice值计算时间片。nice值在CFS中变为一个权重，越低的nice值获得更高的处理器使用权重。 为了防止运行任务数量趋于无限大时，所造成的不可接受的切换损耗，CFS为每个进程设置了时间片最小粒度(默认1ms)。 Linux调度实现 时间记账 所有的调度器都必须对进程运行时间做记账。当每次系统时钟节拍发生时，时间片都会被减少一个街拍周期，当时间片减少到0时，他就会被其它可运行进程抢占。 进程选择 由于没有完美的多任务处理器，CFS试图利用一个简单的规则去均衡进程的虚拟运行时间：当CFS需要选择下一个运行进程时，他会挑选一个具有最小vruntime的进程。 CFS利用红黑树来组织可运行进程队列，并利用其迅速找到最小vruntime值的进程。 挑选下一个任务 假设一个红黑树上存储了系统中所有的可运行进程，其中节点的键值是可运行进程的虚拟运行时间。这时，CFS需要调度的是vruntime最小的那个，它对应的便是树中最左侧的叶子节点,实际上在代码实现中，最左边叶子节点缓存起来了。 向树中加入进程 这一步骤发生在进程变为可运行状态，或者通过fork()调用第一次创建进程时。通过遍历红黑树，如果键值小于当前节点键值，则需要转向树的左分支；相反如果大于当前节点键值，则会转向右分支。一旦发现转入右分支，则leftmost就绝对不会是新加入的节点，leftmost=0，否则leftmost=1，到最后要更新缓存。 从树中删除进程 删除动作发生在进程堵塞或者终止时，通过红黑树操作可以删除进程，然后检查是否删除的是最左节点，从而判断是否要更新rb_leftmost的缓存。 调整入口 进程调度主要入口是schedule(),他会调用pick_next_task()，以优先级为序，从高到低，依次检查每一个类，从而选择最高优先级的进程。 // kernel/sched.c//挑选最高优先级的任务static inline struct task_struct *pick_next_task(struct rq *rq)&#123; const struct sched_class *class; struct task_struct *p; //如果我们知道所有任务都在公平类中，那么可以直接调用该函数(所有可运行进程数量等于CFS类对应的可运行进程数，也就是说所有的可运行进程都是CFS类) if (likely(rq-&gt;nr_running == rq-&gt;cfs.nr_running)) &#123; p = fair_sched_class.pick_next_task(rq); if (likely(p)) &#123; return p; &#125; &#125; class = sched_class_highest; for (; ;) &#123; p = class-&gt;pick_next_task(rq); if (p) &#123; return p; &#125; //p永远不会为NULL,因为idle类总会返回非NULL的p。 class = class-&gt;next; &#125;&#125; 睡眠和唤醒 休眠的进程处于一个特殊的不可执行的状态，进程把自己标记成休眠状态，从可执行红黑树中移除，放入等待队列，然后调用schedule()选择和执行一个其他进程。 唤醒的过程与睡眠相反，进程被设置为可执行状态，然后从等待队列移到可执行红黑树中。 等待队列 等待队列是由某些事件发生的进程组成的简单链表(wake_queue_head_t)， // q 是我们希望休眠的等待队列DEFINE_WAIT(wait)；add_wait_queue(q, &amp;wait)；while(!condition) &#123; prepare_to_wait(&amp;q, &amp;wait, TASK_INTERPUPTIBLE); if (signal_pending(current)) &#123; /* 处理信号 */ &#125; schedule();&#125;finish_wait(&amp;q, &amp;wait); 调用宏DEFINE_WAIT()创建一个等待队列的项。 调用add_wait_queue()把自己加入到队列中。该队列会在进程等待的条件满足时唤醒它。当然我们必须在其他地方撰写相关代码，在事件发生时，对等待队列执行wake_up()操作 调用prepare_to_wait()方法将进程的状态变更为TASK_INTERRUPTIBLE 或者 TASK_UNINTERRUPTIBLE。 如果状态设置为TASK_INTERPUPTIBLE,则信号唤醒进程(伪唤醒)，因此要检查处理信号。 当进程被唤醒，再一次检查条件是否为真，如果是则退出循环；如果不是则再次调用schedule()并重复该操作。 当条件满足，进程将自己设置成TASK_RUNNING,调用finish_wait()并将自己移除等待队列。 唤醒 wake_up(),它会唤醒指定的等待队列上的所有进程。他调用函数try_to_wake_up(),该函数负责将进程设置成TASK_RUNNING状态，调用enqueue_task()将此进程放入红黑树中，如果被唤醒的进程优先级比较高还要设置need_resched状态。 抢占和上下文切换 上下文切换就是从一个可执行进程切换到另一个可执行进程，完成的操作内容如下： 调用声明switch_mm(),该函数负责把虚拟内存从上一个进程映射切换到新进程中。 调用声明中的switch_to(),该函数负责从上一个进程的处理器状态切换到新进程的处理器状态。这包括保存、恢复栈信息和寄存器信息，还有其他任何与体系结构相关的状态信息，都必须以每个进程为对象进行管理保存。 内核提供了一个need_resched标志来标明是否需要重新执行一次调度。当某个进程应该被抢占时，scheduler_tick()就会设置这个标志，当一个优先级高的进程进入可执行状态时，try_to_wake_up()也会设置这个标志，内核检查该标志，确认位置，调用schedule()来切换到一个新的进程，该标志对于内核来讲是一个信息，它表示有其他进程应当被运行。 用户抢占 内核即将返回用户空间时，检查need_resched标志是否被设置，如果被设置则会调用schedule()，此时发生用户抢占。 总结用户抢占发生在以下情况： * 从系统返回用户空间时。 * 从中断处理程序返回用户空间时。 内核抢占 只要重新调度是安全的，内核就可以在任何时间抢占正在执行的任务。只要没有持有锁，内核就可以进行抢占，锁是非抢占区域的标志。 每个进程的thread_info都可以引入preempt_count计数器，该计数器初始值为0，每当使用锁就加1，释放锁数值减1。当数值为0时，内核就可以执行抢占。从中断返回内核空间时，内核检查need_resched和preempt_count的值，如果need_resched被设置，并且preempt_count为0，说明有一个更为重要的任务需要执行并且可以安全地抢占；如果preempt_count不为0，那么说明当前任务有锁，那么抢占不安全，内核直接从中断返回当前执行进程。如果所有的所都被释放了，preempt_count就会是0，此时，释放锁的代码会检查need_resched是否会被设置，如果是的话，就会调度程序。 总结内核抢占发生在以下情况： 中断处理程序正在执行且返回内核空间之前。 内核代码再一次具有可抢占性的时候。 如果内核中的任务显示地调用schedule()。 如果内核中的任务阻塞。 实时调度策略 SCHED_FIFO(先进先出) 不使用时间片。处于可运行状态的SCHED_FIFO级的进程会比任何SCHED_NORMAL级的进程都先得到调度。一旦一个SCHED_FIFO级进程处于可执行状态，就会一直执行，直到它自己受阻塞或显式地释放处理器为止。只有更高优先级的SCHED_FIFO或者SCHED_RR任务才能抢占。 SCHED_RR(时间片轮转) 在耗尽事先分配给它的时间后就不能再继续执行了，这是一种实时轮流调度算法。当SCHED_RR任务耗尽它的时间片时，在同一优先级的其他实时进程被轮流调度。时间片只用来重新调度同一优先级的进程。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-进程管理]]></title>
    <url>%2F2017%2F10%2F05%2FLinux%2F2017-10-05-Linux-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[进程 进程就是出于执行期的程序，包括可执行的代码段、打开的文件、挂起的信号、内核内部的数据、处理器状态，一个或多个具有内存映射的内存地址空间及一个或多个线程，还包括用来存放全局变量的数据段等。进程就是正在执行的程序代码的实时结果。 线程是在进程活动的对象。每个线程都拥有一个独立的程序计数器、进程栈和一组进程寄存器。线程是内核调度的基本对象。通常一个进程包含多个线程，但是Linux的实现比较特别,他对线程和进程不进行特别区分，对其而言，线程是一种特殊的进程。 调用fork()的是父进程，产生的进程为子进程。fork()从内核返回两次：一次回到父进程(恢复执行)，另一次到子进程(开始执行)。 进程创建后接着调用exec()创建新的地址空间，并载入新的程序。最终用exit()推出执行，并释放资源。 进程描述符 内核把进程的列表存放在任务队列中（task list）的双向循环链表中。task list 中的每一项都是一个 task_struct, 结构为： \\ linux-2.6.10/include/asm-x86_64/thread_info.hstruct thread_info &#123; struct task_struct *task; /* main task structure */ struct exec_domain *exec_domain; /* execution domain */ __u32 flags; /* low level flags */ __u32 status; /* thread synchronous flags */ __u32 cpu; /* current CPU */ int preempt_count; mm_segment_t addr_limit; struct restart_block restart_block;&#125;; 内核通过唯一的进程标识符或PID来标识每个进程（最大0x8000）。一般进程数值大的比进程数值小的迟运行，所以可以通过修改/include/linux/threads.h /* * This controls the default maximum pid allocated to a process */#define PID_MAX_DEFAULT 0x8000 由于内核访问任务需要task_truct的指针，所以要通过current宏查找，这一部分具体实现与实际系统有关。 进程状态 进程有如下5种状态，在进程描述符的state域中标识 TASK_RUNNING: 进程可执行或者正在执行，或者在运行队列中等待执行。 TASK_INTERRUPTIBLE: 进程正在睡眠、阻塞，正在等待某些条件达成。 TASK_UNINTERRUPTIBLE: 接收到信号也不会被唤醒，使用较少。 __TASK_TRACED: 被其他进程跟踪的进程 __TASK_STOPPED: 进程停止执行，一般发生在接收到SIGSTOP,SIGTSTP,SIGTTIN,SIGTTOU时。 内核经常需要调整进程的状态，因此，可以用一下函数设置： // include/linux/sched.h#define __set_task_state(tsk, state_value) \ do &#123; (tsk)-&gt;state = (state_value); &#125; while (0)#define set_task_state(tsk, state_value) \ set_mb((tsk)-&gt;state, (state_value))#define __set_current_state(state_value) \ do &#123; current-&gt;state = (state_value); &#125; while (0)#define set_current_state(state_value) \ set_mb(current-&gt;state, (state_value)) 进程创建 fork()通过拷贝当前进程创建一个子进程。子进程与父进程的区别仅仅为一个PID (每个进程都是唯一的)， PPID(父进程的进程号，子进程将其复制成被拷贝的进程的PID)和某些资源及统计量。 exec() 负责读取可执行文件并将其载入地址空间开始运行。 写时拷贝（copy-on-write） 这是一种可以推迟甚至免除拷贝数据的技术。内核此时并不需要复制整个进程地址空间，而是让父子进程共享同一份拷贝。只有当需要写入时数据才会被复制，在此之前，数据都是以只读的形式进行共享。 fork() Linux 用clone()系统调用实现fork()。do_fork()调用copy_process()函数，让进程开始运行。 调用 dup_task_struct()为新进程创建一个内核栈、thread_info结构和task_struct结构，这些值与当前进程的值相同。此时，子进程与父进程的描述符是完全相同的。 检查并确保新创建这个子进程后，当前用户所拥有的进程数目没有超过给他分配的资源的限制。 子进程着手使自己与父进程区别开来。进程描述符内许多成员都要被清0或设置初始值。那些不是继承而来的进程描述符成员，主要是统计信息。task_struct中的大多数数据都依然未被修改。 子进程的状态被设置成TASK_UNINTERRUPTIBLE,保证其不会运行。 copy_process()调用copy_flags()以更新task_struct的flags成员。表明进程是否拥有超级用户权限的PF_SUPERPRIV标志被清0.表明进程还没有调用exec()函数的PF_FORKNOEXEC标志被设置。 调用alloc_pid()为新进程分配一个有效的PID。 根据传递给clone()的参数标志，copy_process拷贝或共享打开的文件、文件系统信息、信息处理函数、进程地址空间和命名空间等。一般情况下这些资源会被给定进程的所有线程共享，否则这些资源对每个进程是不同的，因此需要拷贝。 最后copy_process()返回一个指向子进程的指针。 如果copy_process()成功返回，子进程被唤醒并投入运行。内核有意选择子进程首先执行，这样可以立即调用exec()函数。 进程终结 它发生在exit() 系统调用时，既可能显式调用也可能是隐式的返回(这里注意，C语言在main()函数返回点后面放置调用exit()的代码)。当进程接受到它既不能处理也不能忽略的信号或异常，可能被动地终结。 do_exit()会调用schedule()切换到新的进程。 删除进程描述符 在调用do_exit()之后，尽管线程僵死不能运行，但是系统还是保留了进程描述符，这样可以让系统有办法在子进程终结后仍然获得他的信息。因此可以看出进程终结所需的清理工作和进程描述符的删除是分开的。只有当确定不再关注该线程时，所有信息task_struct才会被释放。 孤儿进程 如果父进程在子进程之前退出，必须有机制保证子进程可以找到一个父进程，否则这些成为孤儿的进程就会僵死耗费内存。解决方法是给子进程在当前线程组内找一个线程作为父亲，否则就让init做它们的父进程。 init也会例行调用wait()来检查子进程，从而清除所有与其相关的僵死进程。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[约瑟夫问题(SJTU OJ 1038)]]></title>
    <url>%2F2017%2F09%2F25%2F%E7%AE%97%E6%B3%95%2F2017-9-25-%E7%BA%A6%E7%91%9F%E5%A4%AB%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Description 话说二哥当年学习数据结构的时候遇到了那道猴子报数的题目，其实这就是经典的约瑟夫问题。 可是当年的二哥还是个毛头小子，只会用模拟的方法，而其他同学却使用了一些令二哥完全摸不到头脑的方法。 ……二哥一怒之下改了题目…… 话说当年花果山的猴子要选大王，选举办法如下： 所有猴子按1-M编号围坐一圈，二哥站在圈中心，由二哥指定一个整数Kn， 之后猴子们从1号开始按顺序报数，报到Kn的猴子退出到圈外，二哥再报出一个整数Kn+1， 然后由刚刚退出的猴子的下一只猴子再开始报数，如此循环报数，直到圈内只剩下一只猴子时，这只猴子就是大王。 由于二哥希望通过此种方法控制花果山，所以现在二哥把他制定的整数序列告诉你，希望你帮他预先算出那只猴子会成为大王。 Input Format 第一行 一个整数M，表示一共有M只猴子 第二行到第M行，每行一个整数 表示二哥即将指定的M-1个整数。这些数都大于0。 Output Format 一个整数，表示最后剩下那只猴子的编号。 Hint 对于40%的数据，M&lt;=1000, K&lt;=1000 对于70%的数据，M&lt;=10000, K&lt;=10000 对于100%的数据，M&lt;=10000, K&lt;=100000000 Sample Input 51234 Sample Output 4 Solution 用链表解决这个问题。需要注意以下两点： 单向循环链表可以相对节省空间。 单向链表在请求删除第一个数据时，由于不知道前一个结构体，所以我采用绕一圈的方式，其实也可以使用双向循环链表，各有利弊。 减少时间复杂度，在每次都记录一下剩余的链表结构体的数量，用余数来确定指定的位置，由此保证每一次操作，都控制在一次完整的循环链表遍历之内。 //// main.c// 1038//// Created by Oscar on 21/09/2017.// Copyright © 2017 刘丰瑞. All rights reserved.//#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;typedef struct Lnode&#123; int num; struct Lnode *next;&#125;LinkList;void createList (LinkList *L, int n) &#123; LinkList *s,*r,*p; int i; L-&gt;num = 1; r = L; for (i = 2 ; i&lt;=n; i++) &#123; s = (LinkList*)malloc(sizeof(LinkList)); s-&gt;num = i; r-&gt;next = s; r = s; &#125; r-&gt;next = L;&#125;void findList (LinkList *L, long long int n, long long int *remain)&#123; int a; LinkList *f; if (n == 1) &#123; for (a=1; a&lt;*remain; a++) &#123; L=L-&gt;next; &#125; &#125;else &#123; for (a=0; a&lt;n-1; a++) &#123; L=L-&gt;next; &#125; &#125; f = L-&gt;next; L-&gt;next = L-&gt;next-&gt;next; L = L-&gt;next; *remain -= 1; free(f);&#125;int main(int argc, const char * argv[]) &#123; int n,m,i,p=0,q=0,a,sum; int k; LinkList *monkey; LinkList *f; scanf("%d",&amp;sum); monkey = (LinkList *)malloc(sizeof(LinkList)); createList(monkey, sum); k=sum; for (m = 1; m&lt;sum; m++) &#123; if (m==sum-1) &#123; scanf("%d",&amp;i); &#125;else&#123; scanf("%d\n",&amp;i); &#125; i = i%k; if (i == 0) &#123; i = k; &#125; if (i == 1) &#123; for (a=1; a&lt;k; a++) &#123; monkey=monkey-&gt;next; &#125; &#125;else &#123; for (a=0; a&lt;i-2; a++) &#123; monkey=monkey-&gt;next; &#125; &#125; f = monkey-&gt;next; monkey-&gt;next = monkey-&gt;next-&gt;next; monkey = monkey-&gt;next; k -= 1; free(f); &#125; printf("%d ", monkey-&gt;num); return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DP（最长公共子序列）]]></title>
    <url>%2F2017%2F09%2F15%2F%E7%AE%97%E6%B3%95%2F2017-9-15-DP%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97%2F</url>
    <content type="text"><![CDATA[Description 在字母表中，分别给出两个长度为n和m的字符串A和B，确定在A与B中最长公共子序列的长度。 \(A = a_1a_2a_3...a_n\) 其中每个\(i_j\)都在1和n之间，并且\(1&lt;=i_1&lt;i_2&lt;...&lt;i_k&lt;=n\)。 Solution 使用动态规划解决这个问题，\(A = a_1a_2a_3...a_n\)，\(B = b_1b_2b_3...b_n\)，令\(L[i,j]\)来表示两个公共子序列的长度。那么总结有以下的结论： \[ L[i,j] = \left\{\begin{matrix} &amp; 0 &amp; 若i=0或j=0\\ &amp; L[i-1,j-1]+1 &amp; 若i&gt;0,j&gt;0 和 a_i=b_j\\ &amp; max\left\{L[i,j-1],L[i-1,j] \right\} &amp; 若i&gt;0,j&gt;0 和a_i \neq b_j \end{matrix}\right. \] Algotrithm 算法： LCS输入： 字母表上的两个字符串A和B，长度分别为n和m输出： A和B最长公共子序列的长度1. for i = 0 to n2. L[i, 0] = 03. end for4. for j = 0 to m5. L[0, j] = 06. end for7. for i = 1 to n8. for j = 1 to m9. if a_i = b_j then L[i,j] = L[i-1,j-1]+110. else L[i,j] = max&#123;L[i,j-1],L[i-1,j]&#125;11. end if12. end for13. end for14. return L[n,m]]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DP（SJTU OJ 1012）]]></title>
    <url>%2F2017%2F09%2F15%2F%E7%AE%97%E6%B3%95%2F2017-9-15-DP%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Description 有一个数列，它是由自然数组成的，并且严格单调上升。最小的数不小于S，最大的不超过T。现在知道这个数列有一个性质：后一个数相对于前一个数的增长率总是百分比下的整数（如5相对于4的增长率是25%，25为整数；而9对7就不行了）。现在问：这个数列最长可以有多长？满足最长要求的数列有多少个？ Input Format 输入仅有一行，包含S和T两个数（ 0&lt;S&lt;T≤200000）。 30%的数据，0&lt;S&lt;T≤100； 100%的数据，0&lt;S&lt;T≤200000。 Output Format 输出有2行。第一行包含一个数表示长度，第二行包含一个数表示个数。 Sample Input 2 10 Sample Output 52 样例解释 2 4 5 6 9以及2 4 5 8 10 解题思路 DP动态规划求解 如何将从S到T的问题转变成从S到T-1的问题呢？ 首先求出从S到T-1的最长序列有几个，他的末端分别是谁，然后把T和末端数字进行比较，看是否可以延续这个最长序列，从而决定是否要增加序列的长度。 DP设定以下几个状态 * d[i] 表示以i为结尾的最长序列的长度 * times[i] 以i为结尾的最长序列的个数 * cnt[x] 长度为x的序列的个数 算法： 从S到T遍历起点i。 逆向思考：假设增长的百分率为j%，也就是题目中的25。则确定序列中的下个数字tmp 与i的关系为 \((tmp - i)/i = j/100\) 整理得 \(tmp = i + i*j/100\) 注意这里的 \(tmp&lt;=T\)。 得到上述关系后，DP的状态转移为： 首先，我们的tmp是在以i为结尾的序列后加入的，长度为d[i]+1, 因此以tmp的结尾的序列长度和次数要更新； 如果d[tmp] 和 d[i]+1相等，那么在此之前以tmp结尾的序列最长长度和之前的序列长度一致。也就是说 \(times[tmp] += times[i]\)。 如果d[tmp] &lt; d[i]+1, 说明新的序列比原来的还要长，所以\(d[tmp] = d[i]+1, times[tmp] = times[i]\)。 更新总的最大长度\(ans = max（ans,d[tmp]）\); 最后输出ans和cnt[ans] #include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;#include &lt;iostream&gt;using namespace std;typedef long long ll;const int maxn=200007;int d[maxn];ll cnt[maxn],times[maxn];//cnt[i]存储的是 长度为i的序列的个数//d[i]存储的是以i结尾的序列最长的长度int main()&#123; int s,t; cin&gt;&gt;s&gt;&gt;t; memset(cnt,0,sizeof(cnt)); int i,j,tmp,ans=1; cnt[1]=t-s+1; for(i=s;i&lt;=t;i++) d[i]=times[i]=1; //初始化为1 for(i=s;i&lt;=t;i++) //遍历每个数作为起点 for(j=1;j&lt;=100;j++) if( (i*j)%100 == 0) //假设增长率为j% &#123; //则在此增长率下 得到的数为 tmp 可以看出,要让tmp为整数 必须i*j是100的倍数 tmp = i + i*j/100; if( tmp &lt;= t ) //如果这个tmp是在规定范围内的 我们就找到了一个解 &#123; if(d[i]+1 &gt; d[tmp]) //这时要比较 看看要不要更新以tmp结尾的最长的长度 &#123; d[tmp] = d[i] + 1;//以tmp为结尾的序列的长度 为 以i为结尾的序列的长度 再加上1 表示算上tmp times[tmp] = times[i]; //发生了最长长度的更新 所以要重置 以tmp结尾的最长长度的重复次数为 i的 &#125; else if(d[i]+1==d[tmp]) //恰好是重复的最长长度 &#123; times[tmp] += times[i];//则最长长度的次数 增加 以i结尾的最长长度重复次数 &#125; ans = max(ans,d[tmp]); //更新ans //d[i]+1 表示以i结尾的序列长度+tmp所增加的1位 这个长度的子列数量要增加times[i] cnt[d[i]+1] += times[i]; &#125; &#125; cout&lt;&lt;ans&lt;&lt;cnt[ans]; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DP（完全背包）]]></title>
    <url>%2F2017%2F09%2F15%2F%E7%AE%97%E6%B3%95%2F2017-9-15-%E5%AE%8C%E5%85%A8%E8%83%8C%E5%8C%85%2F</url>
    <content type="text"><![CDATA[Description 你现在有一个体积为V的大袋子，有N种物品，假设每种物品的数量有无限多个，而且第i种物品的体积是c[i],价值是w[i],请选择一些物品放入袋中，使袋中物品的价值总和最大。 注意每种物品的数量是无限多的；对于放入袋中的同种物品数量没有限制。 Input Format 第一行包含两个正整数V和N，分别代表袋子的体积和物品的种类数。 以下N行分别由2个正整数组成，代表每种物品的体积和价值。 \(V≤10000,N≤1000\)。 保证操作可在C++ int范围内完成。 Output Format 输出一个整数，表示最大的价值总和 Sample Input 5 32 33 24 1 Sample Output 6 Solution 第一层循环是从第一个物品到第n个物品的循环 第二层循环是先装第一种物品直到装满，然后分别对加入该物品后的体积和价值保留，然后再考虑从包中拿出某个第一种物品，加入第二种物品，直到装满，且价值最大。依次循环直到第n种物品，整个包装满且价值最大。 #include&lt;cstdio&gt;#include&lt;algorithm&gt;using namespace std;int w[1000],c[1000],f[300010];int V,n;int main()&#123; scanf("%d%d",&amp;V,&amp;n); for(int i=1;i&lt;=n;i++)&#123;scanf("%d%d",&amp;w[i],&amp;c[i]);&#125; for(int i=1;i&lt;=n;i++) for(int j=w[i];j&lt;=V;j++)f[j]=max(f[j],f[j-w[i]]+c[i]); printf("%d",f[V]); return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DP（0/1背包）]]></title>
    <url>%2F2017%2F09%2F15%2F%E7%AE%97%E6%B3%95%2F2017-9-15-DP(0%221%E8%83%8C%E5%8C%85)%2F</url>
    <content type="text"><![CDATA[Description 对于 \(U={u_1,u_2,u_3...}\) 是一个准备放入容器为\(C\)的背包中的\(n\)项物品的集合。我们要解决的是用\(U\)中的一些物品来装满背包，使得物体的总体积不超过\(C\),然后使得背包里的物品总价值最大，形式化表述为： 给出有\(n\)项物品的\(U\),我们要找出一个子集\(S\in U\) 使得 \[ \sum_{u_i\in S} v_i \] 在约束条件下 \[ \sum_{u_i\in S} s_i \leq C \] 下最大。 Solution 用V[i,j]表示从前i项 \([u_1,u_2,u_3...u_n]\) 中取出来的装入体积为j的背包的物品的最大价值。这里，i的范围是从0到n，j的范围是从0到C。这样，要寻求的是值V[n,C]。也就是说V[0,j]对于所有的j的值都是0，这是由于包里什么都没有。另一方面，V[i,0]对于所有i的值为0，因为没有东西可以放到包里。一般情况下，当i和j都大于0时，有下面的结论： V[i,j]是下面两个量的最大值： * \(V[i-1,j]\): 仅用最优的方法取自 \([u_1,u_2,...,u_{i-1}]\)的物品去装入体积为j的背包所得的价值最大值。 * \(V[i-1,j-s_i] + v_i\): 用最优的方法取自 \([u_1,u_2,...,u_{i-1}]\) 的物品去装入体积为 \(j-s_i\) 的背包所得到的价值最大值加上 \(u_i\) 的价值。 形式化有以下递推： \[ V[i,j] =\left\{\begin{matrix} 0 &amp;&amp; 若i=0或j=0 \\ V[i-1,j] &amp;&amp; 若j&lt;s_i \\ max\{V[i-1,j],V[i-1,j-s_i]+v_i\} &amp;&amp; i\geq 1 和j\geq s_i\\ \end{matrix}\right. \] Algotithm 算法：KNAPSACK输入：物品集合 $U$=&#123;u1,u2...,us&#125;,体积分别为s1,s2,...sn,价值分别为v1,v2,...vn,容量为C的背包。输出：最大总价值 for i=1 to n V[i,0] = 0; end for for j=0 to C V[0,j] = 0; end for for i=1 to n for j=1 to C V[i,j] = V[i-1,j] if si &lt;= j then V[i,j] = max&#123;V[i-1,j],V[i-1,j-si]+vi&#125; end for end for return V[n,C]]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[超大数求和（SJTU OJ 1007）]]></title>
    <url>%2F2017%2F09%2F14%2F%E7%AE%97%E6%B3%95%2F2017-9-14-%E8%B6%85%E5%A4%A7%E6%95%B0%E6%B1%82%E5%92%8C%2F</url>
    <content type="text"><![CDATA[题目描述 二哥当了多年的助教，今天终于要发工资了！二哥正在高兴之际，得知工资是分两部分发放的。第一部分是这学期的工资，另一部分是之前所有学期的工资总和。而领取工资时，出纳员会问二哥，两部分工资加在一起是多少，如果二哥回答错了，就只能领到这个学期的工资之前所有学期的劳动就白费了。 二哥从小道消息得知，出纳员是个对数字敏感的人，不能有一点差错，所以二哥需要一个程序来帮他算出精确的工资总和。 输入格式 输入共两行，每行是一个十进制表示的工资金额（没有正负号，小数点后有两位数字）。 输出格式 输出共一行，即精确的工资总和（没有正负号，小数点后有两位数字）。 说明 工资金额的有效数字位数不超过200位，并保证有小数点。 Sample Input 123.45543.21 Sample Output 666.66 思路 整体思路使用字符数组代替double类型实现大整数的相加，需要注意的地方是： 小数点符号不参与运算 最高位进位后要记得输出 //// main.c// calculation//// Created by Oscar on 11/09/2017.// Copyright © 2017 刘丰瑞. All rights reserved.//#include &lt;stdio.h&gt;#include "stdlib.h"#include "math.h"int main(int argc, const char * argv[]) &#123; int max = 0, m=0, n=0,k; int carry = 0; int sum=0; int temp = 0; int a[200] = &#123;&#125;; int b[200] = &#123;&#125;; int result[210] = &#123;&#125;; while ((temp=getchar())!='\n') &#123; a[m] = temp-'0'; m++; &#125; while ((temp=getchar())!='\n') &#123; b[n] = temp-'0'; n++; &#125; max = n&gt;m?n:m; for (k = 0; k &lt; max; k++) &#123; if (k!=2) &#123; if (k&gt;=n) &#123; result[k] = a[m-k-1] + carry; &#125;else if (k&gt;=m)&#123; result[k] = b[n-k-1] + carry; &#125;else&#123; result[k] = a[m-k-1] + b[n-k-1] + carry; &#125; if (result[k]&gt;=10) &#123; result[k] = result[k]%10; carry = 1; &#125;else&#123; carry = 0; &#125; &#125;else&#123; &#125; &#125; if (carry==1) &#123; printf("1"); &#125; for (k = 0; k &lt; max; k++) &#123; if (k==max-3) &#123; printf("."); &#125;else&#123; printf("%d",result[max-k-1]); &#125; &#125; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前缀和（SJTU OJ 1002）]]></title>
    <url>%2F2017%2F09%2F13%2F%E7%AE%97%E6%B3%95%2F2017-9-13-%E5%89%8D%E7%BC%80%E5%92%8C%2F</url>
    <content type="text"><![CDATA[SJTU OJ 1002 Description 二哥在自己的后花园里种了一些花生，也快到了收获的时候了。这片花生地是一个长度为L、宽度为W的矩形，每个单位面积上花生产量都是独立的。他想知道，对于某个指定的区域大小，在这么大的矩形区域内，花生的产量最大会是多少。 Input Format 第1行有2个整数，长度L和宽度W。 第2行至第L+1行，每行有W个整数，分别表示对应的单位面积上的花生产量A（ 0&lt; A&lt;10 ) 。 第L+2行有2个整数，分别是指定的区域大小的长度a和宽度b。 Output Format 输出一个整数m，表示在指定大小的区域内，花生最大产量为m。 Sample Input 4 51 2 3 4 56 7 8 0 00 9 2 2 33 0 0 0 13 3 Sample Output 38 样例解释 左上角：38 = (1+2+3) + (6+7+8) + (0+9+2) 数据范围 对于30%的数据： ( 1 &lt; L,W &lt; 100 )； 对于100%的数据： ( 1 &lt; L,W &lt; 1000 ); 全部区域大小满足：( 1 &lt; a &lt; L ，1 &lt; b &lt; W ) 。 解法 其实这道题有一点物化技术的思想，因为如果暴力计算的话我们会发现有很多部分是重复计算的，在数据处理当中对于这种重复计算的东西，可以把事先计算好的值保存下来，减少计算的复杂度。 在网上有的人是用'前缀和'这样的概念来描述并解决这个问题的： 我们先考虑一维的情形，如果我事先计算出 pre[i] 表示前1-i个格子内数字之和，那么完成这个处理之后，每次想要得到任意一个区间 [l, r]的数字和，只需要计算 pre[r] - pre[l -1]即可。随即我们可以推广到二维，事先计算pre[i][j]表示以1, 1为左上角，i, j为右下角的矩形内数字之和。那么不难推出如果要取得以x1, y1为左上角 x2, y2为右下角的矩形内数字之和，只需计算 pre[x2][y2] - pre[x1 - 1][y2] - pre[x2][y1 - 1] + pre[x1 - 1][y1 - 1] 即可。 #include&lt;iostream&gt;using namespace std;int main()&#123; int L(0), W(0), t(0); cin &gt;&gt; L &gt;&gt; W; //输入花生地的长和宽 //定义数组 int **store = new int*[L]; for (int i = 0; i &lt; L; ++i) store[i] = new int[W]; for (int i = 0; i &lt; L; ++i)&#123; for (int j = 0; j &lt; W; ++j)&#123; cin &gt;&gt; t; if (j&gt;0&amp;&amp;i&gt;0)store[i][j] = store[i-1][j] + t + store[i][j-1] - store[i-1][j-1]; else if (j&gt;0 &amp;&amp; i == 0)store[i][j] = t + store[i][j-1]; else if (i &gt; 0 &amp;&amp; j == 0)store[i][j] = t + store[i - 1][j]; else store[i][j] = t; &#125; &#125; int l, w, result(0), temp(0); cin &gt;&gt; l &gt;&gt; w;//获得目标区块的大小 //遍历计算 for (int i = l - 1; i &lt; L; ++i)&#123; for (int j = w - 1; j &lt; W; ++j)&#123; if(i == l- 1 &amp;&amp; j == w - 1)temp = store[i][j]; else if (i == l - 1 &amp;&amp; j != w - 1)temp = store[i][j] - store[i][j - w]; else if (i != l - 1 &amp;&amp; j == w - 1)temp = store[i][j] - store[i - l][j]; else temp = store[i][j] - store[i - l][j] - store[i][j-w] + store[i-l][j-w]; if (temp &gt;= result)result = temp; &#125; &#125; cout &lt;&lt; result;//输出结果 //释放内存！ for (int i = 0; i &lt; L; ++i) delete[] store[i]; delete[] store; return 0;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tf-idf]]></title>
    <url>%2F2017%2F07%2F14%2F%E7%AE%97%E6%B3%95%2F2017-7-14-tf-idf%2F</url>
    <content type="text"><![CDATA[tf-idf: term-frequency-inverse document frequency 这种技术常用来进行文本挖掘，可以评估出某一个语料库中的单词、文件集的重要程度。 term frequency 作为词频，是词数的归一化表示，可以避免它偏向长文件。 分子中 \(n_{i,j}\) 是该词在文件 \(d_j\) 中出现的次数，分母是文件 \(d_j\) 中所有字词的出现次数之和。 \[ tf_{i,j} = \frac {n_{i,j}}{\sum_kn_{k,j}} \] inverse document frequency 逆向文件频率，也可以是一个词语普遍重要性的度量，由总文件数目 除以包含该词语文件的数目，再将得到的商取对数。\(|D|\) 是语料库中文件总数，\(|\{j:t_i\in d_j\}|\) 表示包含该词语的文件，若值为0，用 \(|\{j:t_i\in d_j\}|+1\) 来代替。 \[ idf_i=log\frac{|D|}{|\{j:t_i\in d_j\}|} \] 综上所述， \[ rfidf_{i,j} = tf_{i,j}*idf_{i} \] 应用：tfidf常常与余弦相似性并用，具体步骤为：分词，计算词频，写出词频向量，计算余弦值 参考文献： * tf-idf * TF-IDF与余弦相似性的应用]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ego networks]]></title>
    <url>%2F2017%2F07%2F14%2F%E7%BD%91%E7%BB%9C%2F2017-07-14-Ego%20networks%2F</url>
    <content type="text"><![CDATA[可以简单理解为，Ego network 侧重研究网络中的局部，也就是某一个体的性质，这种网络常常出现在社交网络研究中， 2016年infocom workshop上面的一篇文章Distributed Probabilistic Caching Strategy in VANETs through Named Data Networking 提到了这种网络，可以考虑将这种网络结构运用到VANET当中，从而结合Degree and Betweenness measures等来确定中心节点。 ego network 其中ego就是中心节点，其它就是邻居节点（alert）,每一个ego网络中只有一个中心节点，以及若干与其相连的（tie）的邻居节点。 如何计算ego network的betweenness可以参考论文。 主要思想就是构建一个以ego为中心的矩阵，在矩阵中为第一行第一列，邻居节点补充为其它行列。 0表示不连通，1表示连通，因此对角线为全0. 如果是无向图，可以和容易发现这个矩阵是对称矩阵，计算betweeness可以用以下矩阵 betweeness 为上述矩阵中的值的倒数和，图例中计算的值为3.5。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Networking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VANET仿真-ns3(6)]]></title>
    <url>%2F2017%2F03%2F15%2FVANET%2F2017-3-15-Vanet%E4%BB%BF%E7%9C%9F-ns3(6)%2F</url>
    <content type="text"><![CDATA[VANET 仿真 ns3/examples/routing/manet-routing-compare.cc 该代码是在ns-3上运行DSDV，AODV，OLSR，仿真场景是典型的随机运动模型。 默认情况下，模拟共200s，前50s是启动时间；共50个节点，节点遵从RandomWaypointMobilityModel模型，运动速度20m/s，无暂停，运动范围300*1500 m的区域范围之内。WiFi的传播速度为2Mb/s，遵守Friis loss model(认为是ns-3中的一个模型)，广播发射功率为7.5dBm。 在这里，运动与密度模型、可以通过速度和节点数量被直接修改，也可以改变发射功率（很显然，当发射功率增加时，运动所造成的影响就减少了，密度造成的影响相应增大）。 默认是OLSR路由协议，参数2是AODV，3是DSDV。 默认状态下，有10对源数据对发送UDP，速度为2.048 kbps。均在50~51s内开始发送。 标准输出 1. 包接收： received one packet from 2. 每秒数据接收都会制表并输出成csv文件 3. 一些追踪和流监视器会在程序运行时输出一些状态信息 #include &lt;fstream&gt;#include &lt;iostream&gt;#include "ns3/core-module.h"#include "ns3/network-module.h"#include "ns3/internet-module.h"#include "ns3/mobility-module.h"#include "ns3/wifi-module.h"#include "ns3/aodv-module.h"#include "ns3/olsr-module.h"#include "ns3/dsdv-module.h"#include "ns3/dsr-module.h"#include "ns3/applications-module.h"using namespace ns3;using namespace dsr;NS_LOG_COMPONENT_DEFINE ("manet-routing-compare");class RoutingExperiment&#123;public: RoutingExperiment (); void Run (int nSinks, double txp, std::string CSVfileName); //static void SetMACParam (ns3::NetDeviceContainer &amp; devices, // int slotDistance); std::string CommandSetup (int argc, char \**argv);private: Ptr&lt;Socket&gt; SetupPacketReceive (Ipv4Address addr, Ptr&lt;Node&gt; node); void ReceivePacket (Ptr&lt;Socket&gt; socket); void CheckThroughput (); uint32_t port; uint32_t bytesTotal; uint32_t packetsReceived; std::string m_CSVfileName; int m_nSinks; std::string m_protocolName; double m_txp; bool m_traceMobility; uint32_t m_protocol;&#125;;//设置端口号、字节数、接收包的个数、CSV文件名、移动追踪、协议等RoutingExperiment::RoutingExperiment () : port (9), bytesTotal (0), packetsReceived (0), m_CSVfileName ("manet-routing.output.csv"), m_traceMobility (false), m_protocol (2) // AODV&#123;&#125;//在RoutingExperiment::ReceivePacket中使用static inline std::stringPrintReceivedPacket (Ptr&lt;Socket&gt; socket, Ptr&lt;Packet&gt; packet, Address senderAddress)&#123; //自动分配缓冲区，格式化字符串 std::ostringstream oss; oss &lt;&lt; Simulator::Now ().GetSeconds () &lt;&lt; " " &lt;&lt; socket-&gt;GetNode ()-&gt;GetId (); //如果找到匹配的地址，那么就把地址也表示出来 if (InetSocketAddress::IsMatchingType (senderAddress)) &#123; InetSocketAddress addr = InetSocketAddress::ConvertFrom (senderAddress); oss &lt;&lt; " received one packet from " &lt;&lt; addr.GetIpv4 (); &#125; else &#123; oss &lt;&lt; " received one packet!"; &#125; return oss.str ();&#125;voidRoutingExperiment::ReceivePacket (Ptr&lt;Socket&gt; socket)&#123; Ptr&lt;Packet&gt; packet; Address senderAddress; //从socket中读取一个数据包packet，并且检索发送地址，保存到变量senderAddress中 while ((packet = socket-&gt;RecvFrom (senderAddress))) &#123; bytesTotal += packet-&gt;GetSize (); packetsReceived += 1; NS_LOG_UNCOND (PrintReceivedPacket (socket, packet, senderAddress)); &#125;&#125;voidRoutingExperiment::CheckThroughput ()&#123; //先计算kbs，然后再把bytesTotal清零，用于计算下一次的kbs double kbs = (bytesTotal * 8.0) / 1000; bytesTotal = 0; //写操作到csv文件中 std::ofstream out (m_CSVfileName.c_str (), std::ios::app); out &lt;&lt; (Simulator::Now ()).GetSeconds () &lt;&lt; "," &lt;&lt; kbs &lt;&lt; "," &lt;&lt; packetsReceived &lt;&lt; "," &lt;&lt; m_nSinks &lt;&lt; "," &lt;&lt; m_protocolName &lt;&lt; "," &lt;&lt; m_txp &lt;&lt; "" &lt;&lt; std::endl; out.close (); //同理，这里packetsReceived也需要清零 packetsReceived = 0; //设置1s延时之后执行CheckThroughput，this标明是谁唤醒成员函数 Simulator::Schedule (Seconds (1.0), &amp;RoutingExperiment::CheckThroughput, this);&#125;Ptr&lt;Socket&gt;RoutingExperiment::SetupPacketReceive (Ipv4Address addr, Ptr&lt;Node&gt; node)&#123; //通过名字返回一个TypeId TypeId tid = TypeId::LookupByName ("ns3::UdpSocketFactory"); Ptr&lt;Socket&gt; sink = Socket::CreateSocket (node, tid); InetSocketAddress local = InetSocketAddress (addr, port); sink-&gt;Bind (local); //设置回调 sink-&gt;SetRecvCallback (MakeCallback (&amp;RoutingExperiment::ReceivePacket, this)); return sink;&#125;std::stringRoutingExperiment::CommandSetup (int argc, char \**argv)&#123; CommandLine cmd; cmd.AddValue ("CSVfileName", "The name of the CSV output file name", m_CSVfileName); cmd.AddValue ("traceMobility", "Enable mobility tracing", m_traceMobility); cmd.AddValue ("protocol", "1=OLSR;2=AODV;3=DSDV;4=DSR", m_protocol); cmd.Parse (argc, argv); return m_CSVfileName;&#125;intmain (int argc, char \*argv[])&#123; RoutingExperiment experiment; std::string CSVfileName = experiment.CommandSetup (argc,argv); //blank out the last output file and write the column headers std::ofstream out (CSVfileName.c_str ()); out &lt;&lt; "SimulationSecond," &lt;&lt; "ReceiveRate," &lt;&lt; "PacketsReceived," &lt;&lt; "NumberOfSinks," &lt;&lt; "RoutingProtocol," &lt;&lt; "TransmissionPower" &lt;&lt; std::endl; out.close (); int nSinks = 10; double txp = 7.5; //节点数10，传播功率7.5 experiment.Run (nSinks, txp, CSVfileName);&#125;voidRoutingExperiment::Run (int nSinks, double txp, std::string CSVfileName)&#123; Packet::EnablePrinting (); m_nSinks = nSinks; m_txp = txp; m_CSVfileName = CSVfileName; int nWifis = 50; double TotalTime = 200.0; std::string rate ("2048bps"); std::string phyMode ("DsssRate11Mbps"); std::string tr_name ("manet-routing-compare"); int nodeSpeed = 20; //in m/s int nodePause = 0; //in s m_protocolName = "protocol"; //这里OnOffApplication生成了一个单向的交通流，有以下两个属性可以设置 Config::SetDefault ("ns3::OnOffApplication::PacketSize",StringValue ("64")); Config::SetDefault ("ns3::OnOffApplication::DataRate", StringValue (rate)); //将非单播模式设置成单播 Config::SetDefault ("ns3::WifiRemoteStationManager::NonUnicastMode",StringValue (phyMode)); NodeContainer adhocNodes; adhocNodes.Create (nWifis); // setting up wifi phy and channel using helpers WifiHelper wifi; wifi.SetStandard (WIFI_PHY_STANDARD_80211b); YansWifiPhyHelper wifiPhy = YansWifiPhyHelper::Default (); YansWifiChannelHelper wifiChannel; wifiChannel.SetPropagationDelay ("ns3::ConstantSpeedPropagationDelayModel"); wifiChannel.AddPropagationLoss ("ns3::FriisPropagationLossModel"); wifiPhy.SetChannel (wifiChannel.Create ()); // Add a mac and disable rate control WifiMacHelper wifiMac; wifi.SetRemoteStationManager ("ns3::ConstantRateWifiManager", "DataMode",StringValue (phyMode), "ControlMode",StringValue (phyMode)); wifiPhy.Set ("TxPowerStart",DoubleValue (txp)); wifiPhy.Set ("TxPowerEnd", DoubleValue (txp)); wifiMac.SetType ("ns3::AdhocWifiMac"); NetDeviceContainer adhocDevices = wifi.Install (wifiPhy, wifiMac, adhocNodes); MobilityHelper mobilityAdhoc; //为了能持续性地得到移动交叉场景 int64_t streamIndex = 0; // used to get consistent mobility across scenarios //设置运动范围 ObjectFactory pos; pos.SetTypeId ("ns3::RandomRectanglePositionAllocator"); pos.Set ("X", StringValue ("ns3::UniformRandomVariable[Min=0.0|Max=300.0]")); pos.Set ("Y", StringValue ("ns3::UniformRandomVariable[Min=0.0|Max=1500.0]")); Ptr&lt;PositionAllocator&gt; taPositionAlloc = pos.Create ()-&gt;GetObject&lt;PositionAllocator&gt; (); streamIndex += taPositionAlloc-&gt;AssignStreams (streamIndex); std::stringstream ssSpeed; ssSpeed &lt;&lt; "ns3::UniformRandomVariable[Min=0.0|Max=" &lt;&lt; nodeSpeed &lt;&lt; "]"; std::stringstream ssPause; ssPause &lt;&lt; "ns3::ConstantRandomVariable[Constant=" &lt;&lt; nodePause &lt;&lt; "]"; mobilityAdhoc.SetMobilityModel ("ns3::RandomWaypointMobilityModel", "Speed", StringValue (ssSpeed.str ()), "Pause", StringValue (ssPause.str ()), "PositionAllocator", PointerValue (taPositionAlloc)); mobilityAdhoc.SetPositionAllocator (taPositionAlloc); mobilityAdhoc.Install (adhocNodes); streamIndex += mobilityAdhoc.AssignStreams (adhocNodes, streamIndex); AodvHelper aodv; OlsrHelper olsr; DsdvHelper dsdv; DsrHelper dsr; DsrMainHelper dsrMain; Ipv4ListRoutingHelper list; InternetStackHelper internet; switch (m_protocol) &#123; case 1: list.Add (olsr, 100); m_protocolName = "OLSR"; break; case 2: list.Add (aodv, 100); m_protocolName = "AODV"; break; case 3: list.Add (dsdv, 100); m_protocolName = "DSDV"; break; case 4: m_protocolName = "DSR"; break; default: NS_FATAL_ERROR ("No such protocol:" &lt;&lt; m_protocol); &#125; if (m_protocol &lt; 4) &#123; internet.SetRoutingHelper (list); internet.Install (adhocNodes); &#125; else if (m_protocol == 4) &#123; internet.Install (adhocNodes); dsrMain.Install (dsr, adhocNodes); &#125; NS_LOG_INFO ("assigning ip address"); Ipv4AddressHelper addressAdhoc; addressAdhoc.SetBase ("10.1.1.0", "255.255.255.0"); Ipv4InterfaceContainer adhocInterfaces; adhocInterfaces = addressAdhoc.Assign (adhocDevices); OnOffHelper onoff1 ("ns3::UdpSocketFactory",Address ()); onoff1.SetAttribute ("OnTime", StringValue ("ns3::ConstantRandomVariable[Constant=1.0]")); onoff1.SetAttribute ("OffTime", StringValue ("ns3::ConstantRandomVariable[Constant=0.0]")); for (int i = 0; i &lt; nSinks; i++) &#123; Ptr&lt;Socket&gt; sink = SetupPacketReceive (adhocInterfaces.GetAddress (i), adhocNodes.Get (i)); AddressValue remoteAddress (InetSocketAddress (adhocInterfaces.GetAddress (i), port)); onoff1.SetAttribute ("Remote", remoteAddress); Ptr&lt;UniformRandomVariable&gt; var = CreateObject&lt;UniformRandomVariable&gt; (); ApplicationContainer temp = onoff1.Install (adhocNodes.Get (i + nSinks)); temp.Start (Seconds (var-&gt;GetValue (100.0,101.0))); temp.Stop (Seconds (TotalTime)); &#125; std::stringstream ss; ss &lt;&lt; nWifis; std::string nodes = ss.str (); std::stringstream ss2; ss2 &lt;&lt; nodeSpeed; std::string sNodeSpeed = ss2.str (); std::stringstream ss3; ss3 &lt;&lt; nodePause; std::string sNodePause = ss3.str (); std::stringstream ss4; ss4 &lt;&lt; rate; std::string sRate = ss4.str (); //NS_LOG_INFO ("Configure Tracing."); //tr_name = tr_name + "_" + m_protocolName +"_" + nodes + "nodes_" + sNodeSpeed + "speed_" + sNodePause + "pause_" + sRate + "rate"; //AsciiTraceHelper ascii; //Ptr&lt;OutputStreamWrapper&gt; osw = ascii.CreateFileStream ( (tr_name + ".tr").c_str()); //wifiPhy.EnableAsciiAll (osw); AsciiTraceHelper ascii; MobilityHelper::EnableAsciiAll (ascii.CreateFileStream (tr_name + ".mob")); //Ptr&lt;FlowMonitor&gt; flowmon; //FlowMonitorHelper flowmonHelper; //flowmon = flowmonHelper.InstallAll (); NS_LOG_INFO ("Run Simulation."); CheckThroughput (); Simulator::Stop (Seconds (TotalTime)); Simulator::Run (); //flowmon-&gt;SerializeToXmlFile ((tr_name + ".flowmon").c_str(), false, false); Simulator::Destroy ();&#125; 仿真结果如下： 注意，如果需要使用netanim来导出xml文件的时候，一定要把asciihelper注释掉，否则有冲突，不能正常工作！！！！！！]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>VANET</tag>
        <tag>ns3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VANET仿真-ns3(4)]]></title>
    <url>%2F2017%2F03%2F13%2FVANET%2F2017-3-13-Vanet%E4%BB%BF%E7%9C%9F-ns3(4)%2F</url>
    <content type="text"><![CDATA[VANET 仿真 ns3示例代码fourth.cc注释整理，追踪（tracing）与回调。 #include "ns3/object.h"#include "ns3/uinteger.h"#include "ns3/traced-value.h" //提供了一系列的数据追踪的方法#include "ns3/trace-source-accessor.h"#include &lt;iostream&gt;using namespace ns3;class MyObject : public Object&#123;public: // Register this type. //return The TypeId. static TypeId GetTypeId (void) &#123; static TypeId tid = TypeId ("MyObject") .SetParent&lt;Object&gt; () .SetGroupName ("Tutorial") .AddConstructor&lt;MyObject&gt; () //.AddTraceSource提供了一个外部的钩子(hook)，参数分别为： //1.数据追踪的名字，可以被系统可见 //2.提示信息 //3.&amp;MyObject::m_myInt被追踪的值，是一个类的数据成员 //4.用来生成文档与正确的Callback信息 .AddTraceSource ("MyInteger", "An integer value to trace.", MakeTraceSourceAccessor (&amp;MyObject::m_myInt), "ns3::TracedValueCallback::Int32") ; return tid; &#125; MyObject () &#123;&#125; //Traceavalue可以用来回调，确定需要追踪的对象属性。 TracedValue&lt;int32_t&gt; m_myInt;&#125;;//与trace sink匹配的函数，是回调的直接信号，当值发生变化时就需要回调该函数voidIntTrace (int32_t oldValue, int32_t newValue)&#123; std::cout &lt;&lt; "Traced " &lt;&lt; oldValue &lt;&lt; " to " &lt;&lt; newValue &lt;&lt; std::endl;&#125;intmain (int argc, char \*argv[])&#123; Ptr&lt;MyObject&gt; myObject = CreateObject&lt;MyObject&gt; (); //在trace source与trace sink之间建立联系，第一个参数为trace source的名字，第二个为回调 myObject-&gt;TraceConnectWithoutContext ("MyInteger", MakeCallback (&amp;IntTrace)); myObject-&gt;m_myInt = 1234;&#125; 当执行代码 myObject-&gt;m_myInt = 1234; 时，由于值的改变触发了回调函数，有以下运行结果：]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>VANET</tag>
        <tag>ns3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VANET仿真-ns3(5)]]></title>
    <url>%2F2017%2F03%2F13%2FVANET%2F2017-3-13-Vanet%E4%BB%BF%E7%9C%9F-ns3(5)%2F</url>
    <content type="text"><![CDATA[VANET 仿真 ns3示例代码fifth.cc注释整理，我们希望在这部分代码观察TCP的拥塞窗口情况，因此需要调高数据流并且将拥塞窗口这个属性挂到发送方的套接字socket上。现在我们通过一个可以开关的应用来生成数据流，但是有一系列问题有待解决。首先，套接字socket是在应用开始之后才被创建的，因而我们不能在配置阶段处理套接字。其次，套接字socket是非公共属性，因而我们无法访问它。 所以，我们可以通过应用程式来实现我们想要的东西。首先创建一个套接字并连接一个追踪，然后将该套接字传递到我们应用程式的构造器中，并把它安装到源代码上即可。 #include &lt;fstream&gt;#include "ns3/core-module.h"#include "ns3/network-module.h"#include "ns3/internet-module.h"#include "ns3/point-to-point-module.h"#include "ns3/applications-module.h"using namespace ns3;NS_LOG_COMPONENT_DEFINE ("FifthScriptExample");// ===========================================================================//// node 0 node 1// +----------------+ +----------------+// | ns-3 TCP | | ns-3 TCP |// +----------------+ +----------------+// | 10.1.1.1 | | 10.1.1.2 |// +----------------+ +----------------+// | point-to-point | | point-to-point |// +----------------+ +----------------+// | |// +---------------------+// 5 Mbps, 2 ms////// We want to look at changes in the ns-3 TCP congestion window. We need// to crank up a flow and hook the CongestionWindow attribute on the socket// of the sender. Normally one would use an on-off application to generate a// flow, but this has a couple of problems. First, the socket of the on-off// application is not created until Application Start time, so we wouldn't be// able to hook the socket (now) at configuration time. Second, even if we// could arrange a call after start time, the socket is not public so we// couldn't get at it.//// So, we can cook up a simple version of the on-off application that does what// we want. On the plus side we don't need all of the complexity of the on-off// application. On the minus side, we don't have a helper, so we have to get// a little more involved in the details, but this is trivial.//// So first, we create a socket and do the trace connect on it; then we pass// this socket into the constructor of our simple application which we then// install in the source node.// ===========================================================================////继承自Application类，然后重写了StartApplication和StopApplication，这两个方法在调用MyApp时自动开始和停止发送数据。class MyApp : public Application&#123;public: MyApp (); virtual ~MyApp(); void Setup (Ptr&lt;Socket&gt; socket, Address address, uint32_t packetSize, uint32_t nPackets, DataRate dataRate);private: virtual void StartApplication (void); virtual void StopApplication (void); void ScheduleTx (void); void SendPacket (void); Ptr&lt;Socket&gt; m_socket; Address m_peer; uint32_t m_packetSize; uint32_t m_nPackets; DataRate m_dataRate; EventId m_sendEvent; bool m_running; uint32_t m_packetsSent;&#125;;MyApp::MyApp () : m_socket (0), m_peer (), m_packetSize (0), m_nPackets (0), m_dataRate (0), m_sendEvent (), m_running (false), m_packetsSent (0)&#123;&#125;MyApp::~MyApp()&#123; m_socket = 0;&#125;//将类里面的属性赋予初值voidMyApp::Setup (Ptr&lt;Socket&gt; socket, Address address, uint32_t packetSize, uint32_t nPackets, DataRate dataRate)&#123; m_socket = socket; m_peer = address; m_packetSize = packetSize; m_nPackets = nPackets; m_dataRate = dataRate;&#125;voidMyApp::StartApplication (void)&#123; m_running = true; m_packetsSent = 0; //bind函数，为socket()函数创建的套接字关联一个相应地址，发送到这个地址的数据可以通过该套接字读取与使用。 m_socket-&gt;Bind (); //connect函数，用TCP建立了地址联系 m_socket-&gt;Connect (m_peer); //开始建立一个模拟事件 SendPacket ();&#125;//当模拟启动的时候，事件也就被创建了voidMyApp::StopApplication (void)&#123; m_running = false; //如果事件正在被执行，则.IsRunning返回true if (m_sendEvent.IsRunning ()) &#123; //cancel则取消该事务队列 Simulator::Cancel (m_sendEvent); &#125; if (m_socket) &#123; m_socket-&gt;Close (); &#125;&#125;voidMyApp::SendPacket (void)&#123; Ptr&lt;Packet&gt; packet = Create&lt;Packet&gt; (m_packetSize); m_socket-&gt;Send (packet); if (++m_packetsSent &lt; m_nPackets) &#123; //schedule another transmit, 知道达到系统的上界 ScheduleTx (); &#125;&#125;voidMyApp::ScheduleTx (void)&#123; if (m_running) &#123; Time tNext (Seconds (m_packetSize * 8 / static_cast&lt;double&gt; (m_dataRate.GetBitRate ()))); //再一次发送数据包 m_sendEvent = Simulator::Schedule (tNext, &amp;MyApp::SendPacket, this); &#125;&#125;static voidCwndChange (uint32_t oldCwnd, uint32_t newCwnd)&#123; //每当发生变化时通过日志写出当前仿真的时间以及新的拥塞窗口大小 NS_LOG_UNCOND (Simulator::Now ().GetSeconds () &lt;&lt; "\t" &lt;&lt; newCwnd);&#125;static voidRxDrop (Ptr&lt;const Packet&gt; p)&#123; //检查数据包在物理层哪里drop了 NS_LOG_UNCOND ("RxDrop at " &lt;&lt; Simulator::Now ().GetSeconds ());&#125;intmain (int argc, char \*argv[])&#123; CommandLine cmd; cmd.Parse (argc, argv); NodeContainer nodes; nodes.Create (2); PointToPointHelper pointToPoint; pointToPoint.SetDeviceAttribute ("DataRate", StringValue ("5Mbps")); pointToPoint.SetChannelAttribute ("Delay", StringValue ("2ms")); NetDeviceContainer devices; devices = pointToPoint.Install (nodes); //跟踪channel信道上的错误信息，通过实例化一个RateErrorModel的对象，设置一个ErrorRate的属性，将实例作为错误模式 Ptr&lt;RateErrorModel&gt; em = CreateObject&lt;RateErrorModel&gt; (); em-&gt;SetAttribute ("ErrorRate", DoubleValue (0.00001)); devices.Get (1)-&gt;SetAttribute ("ReceiveErrorModel", PointerValue (em)); InternetStackHelper stack; stack.Install (nodes); Ipv4AddressHelper address; address.SetBase ("10.1.1.0", "255.255.255.252"); Ipv4InterfaceContainer interfaces = address.Assign (devices); //TCP协议当中需要设置目标节点 uint16_t sinkPort = 8080; Address sinkAddress (InetSocketAddress (interfaces.GetAddress (1), sinkPort)); //1. ns3::TcpSocketFactory：抽象地创建对象，这里不用创建对象本身，而是通过对象工厂（object factory）的方式进行创建 //2. 告知需要bind的地址与端口 PacketSinkHelper packetSinkHelper ("ns3::TcpSocketFactory", InetSocketAddress (Ipv4Address::GetAny (), sinkPort)); ApplicationContainer sinkApps = packetSinkHelper.Install (nodes.Get (1)); sinkApps.Start (Seconds (0.)); sinkApps.Stop (Seconds (20.)); //通过调用一个静态成员函数，提供一个节点和明确的TypeId，创建一个socket，这里有一个CwndChange的回调非常关键 Ptr&lt;Socket&gt; ns3TcpSocket = Socket::CreateSocket (nodes.Get (0), TcpSocketFactory::GetTypeId ()); ns3TcpSocket-&gt;TraceConnectWithoutContext ("CongestionWindow", MakeCallback (&amp;CwndChange)); Ptr&lt;MyApp&gt; app = CreateObject&lt;MyApp&gt; (); app-&gt;Setup (ns3TcpSocket, sinkAddress, 1040, 1000, DataRate ("1Mbps")); nodes.Get (0)-&gt;AddApplication (app); app-&gt;SetStartTime (Seconds (1.)); app-&gt;SetStopTime (Seconds (20.)); devices.Get (1)-&gt;TraceConnectWithoutContext ("PhyRxDrop", MakeCallback (&amp;RxDrop)); Simulator::Stop (Seconds (20)); Simulator::Run (); Simulator::Destroy (); return 0;&#125;]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>VANET</tag>
        <tag>ns3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VANET仿真-ns3(2)]]></title>
    <url>%2F2017%2F03%2F12%2FVANET%2F2017-3-12-Vanet%E4%BB%BF%E7%9C%9F-ns3(2)%2F</url>
    <content type="text"><![CDATA[VANET 仿真 ns3示例代码second.cc注释整理，总线网络拓扑仿真，拓扑结构如下： 10.1.1.0 n0 -------------- n1 n2 n3 n4 point-to-point | | | | ================ LAN 10.1.2.0 #include "ns3/core-module.h"#include "ns3/network-module.h"#include "ns3/csma-module.h"#include "ns3/internet-module.h"#include "ns3/point-to-point-module.h"#include "ns3/applications-module.h"#include "ns3/ipv4-global-routing-helper.h"using namespace ns3;NS_LOG_COMPONENT_DEFINE ("SecondScriptExample");intmain (int argc, char \*argv[])&#123; bool verbose = true; //启用日志的参数 uint32_t nCsma = 3; //附加节点 CommandLine cmd; cmd.AddValue ("nCsma", "Number of \"extra\" CSMA nodes/devices", nCsma); cmd.AddValue ("verbose", "Tell echo applications to log if true", verbose); cmd.Parse (argc,argv); if (verbose) &#123; LogComponentEnable ("UdpEchoClientApplication", LOG_LEVEL_INFO); LogComponentEnable ("UdpEchoServerApplication", LOG_LEVEL_INFO); &#125; nCsma = nCsma == 0 ? 1 : nCsma; //保证附加节点至少为1个 NodeContainer p2pNodes; p2pNodes.Create (2); NodeContainer csmaNodes; csmaNodes.Add (p2pNodes.Get (1)); csmaNodes.Create (nCsma); PointToPointHelper pointToPoint; pointToPoint.SetDeviceAttribute ("DataRate", StringValue ("5Mbps")); pointToPoint.SetChannelAttribute ("Delay", StringValue ("2ms")); NetDeviceContainer p2pDevices; p2pDevices = pointToPoint.Install (p2pNodes); CsmaHelper csma; csma.SetChannelAttribute ("DataRate", StringValue ("100Mbps")); csma.SetChannelAttribute ("Delay", TimeValue (NanoSeconds (6560))); NetDeviceContainer csmaDevices; csmaDevices = csma.Install (csmaNodes); InternetStackHelper stack; stack.Install (p2pNodes.Get (0)); stack.Install (csmaNodes); //这里给网络设备与CSMA设备部署ipv4地址的方法是相同的 Ipv4AddressHelper address; address.SetBase ("10.1.1.0", "255.255.255.0"); Ipv4InterfaceContainer p2pInterfaces; p2pInterfaces = address.Assign (p2pDevices); address.SetBase ("10.1.2.0", "255.255.255.0"); Ipv4InterfaceContainer csmaInterfaces; csmaInterfaces = address.Assign (csmaDevices); UdpEchoServerHelper echoServer (9); ApplicationContainer serverApps = echoServer.Install (csmaNodes.Get (nCsma)); serverApps.Start (Seconds (1.0)); serverApps.Stop (Seconds (10.0)); UdpEchoClientHelper echoClient (csmaInterfaces.GetAddress (nCsma), 9); echoClient.SetAttribute ("MaxPackets", UintegerValue (1)); echoClient.SetAttribute ("Interval", TimeValue (Seconds (1.0))); echoClient.SetAttribute ("PacketSize", UintegerValue (1024)); ApplicationContainer clientApps = echoClient.Install (p2pNodes.Get (0)); clientApps.Start (Seconds (2.0)); clientApps.Stop (Seconds (10.0)); //路由配置，对用户是不可见的，节点可以直接访问路由表 Ipv4GlobalRoutingHelper::PopulateRoutingTables (); pointToPoint.EnablePcapAll ("second"); csma.EnablePcap ("second", csmaDevices.Get (1), true); Simulator::Run (); Simulator::Destroy (); return 0;&#125; 注：在netanim-module下，修改代码如下，确定节点位置，方便利用.xml文件查看动态效果。 #include "ns3/netanim-module.h" ........ ...... .. AnimationInterface anim("second.xml"); anim.SetConstantPosition(p2pNodes.Get(0), 10, 10); anim.SetConstantPosition(p2pNodes.Get(1), 50, 50); //anim.SetConstantPosition(csmaNodes.Get(0), 25, 0); anim.SetConstantPosition(csmaNodes.Get(1), 40, 0); anim.SetConstantPosition(csmaNodes.Get(2), 30, 10); anim.SetConstantPosition(csmaNodes.Get(3), 20, 20); Simulator::Run (); Simulator::Destroy (); return 0; 仿真效果如下]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>VANET</tag>
        <tag>ns3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VANET仿真-ns3(1)]]></title>
    <url>%2F2017%2F03%2F12%2FVANET%2F2017-3-12-Vanet%E4%BB%BF%E7%9C%9F-ns3(1)%2F</url>
    <content type="text"><![CDATA[VANET 仿真 ns3示例代码first.cc注释整理，点对点的udp传输仿真 #include "ns3/core-module.h"#include "ns3/network-module.h"#include "ns3/internet-module.h"#include "ns3/point-to-point-module.h"#include "ns3/applications-module.h"//namespace 定义之后，所有命令行的参数都需要用ns::的形式来表示using namespace ns3;//定义日志的组成部分NS_LOG_COMPONENT_DEFINE ("FirstScriptExample");intmain (int argc, char \*argv[])&#123; //开启命令行参数，可以设置全局变量、属性等，可以用./waf --run "scratch/myfirst --PrintHelp"查看帮助信息 CommandLine cmd; cmd.Parse (argc, argv); Time::SetResolution (Time::NS); //时间被设定成纳秒级别 LogComponentEnable ("UdpEchoClientApplication", LOG_LEVEL_INFO); LogComponentEnable ("UdpEchoServerApplication", LOG_LEVEL_INFO); NodeContainer nodes; nodes.Create (2); PointToPointHelper pointToPoint; //实例化一个点对点模型 //有两种方式可以设置节点参数，一种可以通过下面的方式修改， //另一种通过命令行./waf --run "scratch/myfirst --ns3::PointToPointNetDevice::DataRate=5Mbps --ns3::PointToPointChannel::Delay=2ms" pointToPoint.SetDeviceAttribute ("DataRate", StringValue ("5Mbps")); pointToPoint.SetChannelAttribute ("Delay", StringValue ("2ms")); NetDeviceContainer devices; devices = pointToPoint.Install (nodes); //协议栈，包括TCP，UDP，IP等 InternetStackHelper stack; stack.Install (nodes); //设定地址掩码等信息 Ipv4AddressHelper address; address.SetBase ("10.1.1.0", "255.255.255.0"); //通过下面的函数将ipv4地址与设备链接起来 Ipv4InterfaceContainer interfaces = address.Assign (devices); //设置udp端口号为9 UdpEchoServerHelper echoServer (9); //install函数就是把节点挂载到server上 ApplicationContainer serverApps = echoServer.Install (nodes.Get (1)); serverApps.Start (Seconds (1.0)); serverApps.Stop (Seconds (10.0)); //client上五个属性分别为节点地址、端口号、包数量、间隔、包大小 UdpEchoClientHelper echoClient (interfaces.GetAddress (1), 9); echoClient.SetAttribute ("MaxPackets", UintegerValue (1)); echoClient.SetAttribute ("Interval", TimeValue (Seconds (1.0))); echoClient.SetAttribute ("PacketSize", UintegerValue (1024)); ApplicationContainer clientApps = echoClient.Install (nodes.Get (0)); clientApps.Start (Seconds (2.0)); clientApps.Stop (Seconds (10.0)); //开始仿真、结束仿真 Simulator::Run (); Simulator::Destroy (); return 0;&#125;]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>VANET</tag>
        <tag>ns3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VANET仿真-ns3(3)]]></title>
    <url>%2F2017%2F03%2F12%2FVANET%2F2017-3-12-Vanet%E4%BB%BF%E7%9C%9F-ns3(3)%2F</url>
    <content type="text"><![CDATA[VANET 仿真 ns3示例代码third.cc注释整理，无线网络拓扑仿真，拓扑结构如下： Number of wifi or csma nodes can be increased up to 250 | Rank 0 | Rank 1-------------------------|---------------------------- Wifi 10.1.3.0 AP * * * * | | | | 10.1.1.0n5 n6 n7 n0 -------------- n1 n2 n3 n4 point-to-point | | | | ================ LAN 10.1.2.0 #include "ns3/core-module.h"#include "ns3/point-to-point-module.h"#include "ns3/network-module.h"#include "ns3/applications-module.h"#include "ns3/wifi-module.h"#include "ns3/mobility-module.h"#include "ns3/csma-module.h"#include "ns3/internet-module.h"using namespace ns3;NS_LOG_COMPONENT_DEFINE ("ThirdScriptExample");intmain (int argc, char \*argv[])&#123; bool verbose = true; uint32_t nCsma = 3; uint32_t nWifi = 3; bool tracing = false; CommandLine cmd; cmd.AddValue ("nCsma", "Number of \"extra\" CSMA nodes/devices", nCsma); cmd.AddValue ("nWifi", "Number of wifi STA devices", nWifi); cmd.AddValue ("verbose", "Tell echo applications to log if true", verbose); cmd.AddValue ("tracing", "Enable pcap tracing", tracing); cmd.Parse (argc,argv); // Check for valid number of csma or wifi nodes // 250 should be enough, otherwise IP addresses // soon become an issue if (nWifi &gt; 250 || nCsma &gt; 250) &#123; std::cout &lt;&lt; "Too many wifi or csma nodes, no more than 250 each." &lt;&lt; std::endl; return 1; &#125; if (verbose) &#123; LogComponentEnable ("UdpEchoClientApplication", LOG_LEVEL_INFO); LogComponentEnable ("UdpEchoServerApplication", LOG_LEVEL_INFO); &#125; //p2p 节点 NodeContainer p2pNodes; p2pNodes.Create (2); PointToPointHelper pointToPoint; pointToPoint.SetDeviceAttribute ("DataRate", StringValue ("5Mbps")); pointToPoint.SetChannelAttribute ("Delay", StringValue ("2ms")); NetDeviceContainer p2pDevices; p2pDevices = pointToPoint.Install (p2pNodes); //csma 节点 NodeContainer csmaNodes; csmaNodes.Add (p2pNodes.Get (1)); csmaNodes.Create (nCsma); CsmaHelper csma; csma.SetChannelAttribute ("DataRate", StringValue ("100Mbps")); csma.SetChannelAttribute ("Delay", TimeValue (NanoSeconds (6560))); NetDeviceContainer csmaDevices; csmaDevices = csma.Install (csmaNodes); //wifi 节点 NodeContainer wifiStaNodes; wifiStaNodes.Create (nWifi); //将p2p中的0节点设为wifi中的Ap节点 NodeContainer wifiApNode = p2pNodes.Get (0); //wifi 节点中的内部信道配置，需要分别处理channel与phy的信号 YansWifiChannelHelper channel = YansWifiChannelHelper::Default (); YansWifiPhyHelper phy = YansWifiPhyHelper::Default (); //将channel于phy物理层连接，保证所有创建的物理层共享同一个底层的通道，可以让彼此通信 phy.SetChannel (channel.Create ()); //wifi可以设置使用算法AarfWifiManager WifiHelper wifi; wifi.SetRemoteStationManager ("ns3::AarfWifiManager"); //ns3::StaWifiMac : mac的类型，区分sta与ap //ssid：网络名称，用来区分网络 //ActiveProbing: 探针不允许被发送 WifiMacHelper mac; Ssid ssid = Ssid ("ns-3-ssid"); mac.SetType ("ns3::StaWifiMac", "Ssid", SsidValue (ssid), "ActiveProbing", BooleanValue (false)); NetDeviceContainer staDevices; staDevices = wifi.Install (phy, mac, wifiStaNodes); //ap节点 mac.SetType ("ns3::ApWifiMac", "Ssid", SsidValue (ssid)); NetDeviceContainer apDevices; apDevices = wifi.Install (phy, mac, wifiApNode); //sta节点保持移动，ap节点静止 MobilityHelper mobility; //建立一个二维场景 mobility.SetPositionAllocator ("ns3::GridPositionAllocator", "MinX", DoubleValue (0.0), "MinY", DoubleValue (0.0), "DeltaX", DoubleValue (5.0), "DeltaY", DoubleValue (10.0), "GridWidth", UintegerValue (3), "LayoutType", StringValue ("RowFirst")); //一个随机速度与方向的模型，非常方便 mobility.SetMobilityModel ("ns3::RandomWalk2dMobilityModel", "Bounds", RectangleValue (Rectangle (-50, 50, -50, 50))); mobility.Install (wifiStaNodes); mobility.SetMobilityModel ("ns3::ConstantPositionMobilityModel"); mobility.Install (wifiApNode); InternetStackHelper stack; stack.Install (csmaNodes); stack.Install (wifiApNode); stack.Install (wifiStaNodes); Ipv4AddressHelper address; address.SetBase ("10.1.1.0", "255.255.255.0"); Ipv4InterfaceContainer p2pInterfaces; p2pInterfaces = address.Assign (p2pDevices); address.SetBase ("10.1.2.0", "255.255.255.0"); Ipv4InterfaceContainer csmaInterfaces; csmaInterfaces = address.Assign (csmaDevices); address.SetBase ("10.1.3.0", "255.255.255.0"); address.Assign (staDevices); address.Assign (apDevices); UdpEchoServerHelper echoServer (9); ApplicationContainer serverApps = echoServer.Install (csmaNodes.Get (nCsma)); serverApps.Start (Seconds (1.0)); serverApps.Stop (Seconds (10.0)); UdpEchoClientHelper echoClient (csmaInterfaces.GetAddress (nCsma), 9); echoClient.SetAttribute ("MaxPackets", UintegerValue (1)); echoClient.SetAttribute ("Interval", TimeValue (Seconds (1.0))); echoClient.SetAttribute ("PacketSize", UintegerValue (1024)); ApplicationContainer clientApps = echoClient.Install (wifiStaNodes.Get (nWifi - 1)); clientApps.Start (Seconds (2.0)); clientApps.Stop (Seconds (10.0)); Ipv4GlobalRoutingHelper::PopulateRoutingTables (); Simulator::Stop (Seconds (10.0)); if (tracing == true) &#123; pointToPoint.EnablePcapAll ("third"); phy.EnablePcap ("third", apDevices.Get (0)); csma.EnablePcap ("third", csmaDevices.Get (0), true); &#125; Simulator::Run (); Simulator::Destroy (); return 0;&#125; 修改节点位置并仿真结果：]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>VANET</tag>
        <tag>ns3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习构造用户空间的IP栈（资料总结）]]></title>
    <url>%2F2016%2F12%2F24%2F%E7%BD%91%E7%BB%9C%2F2016-12-24-ipv4%E5%9C%A8Linux%E4%B8%8A%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[学习构造用户空间的IP栈（资料总结） saminiir的博客及相关代码 Ethernet &amp; ARP BY saminiir's blog IPv4 &amp; ICMPv4 BY saminiir's blog TCP Basics &amp; Handshake BY saminiir's blog TCP Data Flow &amp; Socket API BY saminiir's blog level-ip(code) chobits的代码 tapip(code) Linux源码-IP部分 root/net/ipv4]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>Networking</tag>
        <tag>IPv4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bloom Filter]]></title>
    <url>%2F2016%2F12%2F08%2F%E7%AE%97%E6%B3%95%2F2016-12-08-Bloom%20Filter%2F</url>
    <content type="text"><![CDATA[最近学习中老师总是提到Bloom Filter，但一直都没系统学过，今天花点时间仔细研究一下。 基本概念 当一个元素被加入到集合中时，通过K个散列函数将这个元素映射成一个位数组中的K个点，并将这些点置位1，当检索时只要检查这些散列点是否全为1就可以判断集合中有没有这个元素了。 优点： 空间效率，时间效率都是（O(k)） 可以表示全集，其他数据结构均不能表示全集 缺点： 有一定误识别率 很难将元素从集合中删除 算法描述 元素加入 创建一个m位的二进制串并将每一位都初始化为0，选择k个不同的哈希函数 利用相互独立的哈希函数将集合中的每一个元素映射到{1...m}的范围当中，对于元素x，第i个哈希函数映射的位置hi(x) = 1,其中 1&lt;=i&lt;=k。如果一个位置被多次映射，那么只有第一次置位1，后面的不起作用。 下图中m = 18， k = 3。 元素查询 对查询元素y应用k次哈希函数 如果所有hi(y) = 1,那么y是集合中元素，否则不是 错误率估计 由算法可知，所有元素通过k个哈希函数哈希后，二进制串中某一位还为0的概率是 p' = (1-1/m)kn 错误率则可以表示成k次哈希都刚好选中1的区域（false positive rate），表示成下面的公式 (1-p')k 基本Bloom Filter的内容就这样了，详细的扩展内容包括最优哈希函数，位串的选取可以参看维基百科，总的来说还是相当简单易用的一种数据结构，在数据挖据等方面使用较为广泛。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bellman-Ford算法]]></title>
    <url>%2F2016%2F10%2F25%2F%E7%AE%97%E6%B3%95%2F2016-10-25-BellmanFord%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Bellman-Ford 算法 Bellman-Ford算法是计算单源（single source vertex）最短路径的算法。相比较于 Dijkstra's algorithm 算法，BellmanFord算法较慢，但是却能适合有负权值的边，对于负环图（negative cycle）也能检测到其存在，这对于图计算/计算机网络路由算法都有重要的意义。 Bellman-Ford算法是基于松弛计算的（relaxation operation） 松弛计算 对于两点（A和B）以及连接他们的边，如果源节点S（source node）到第一个节点A的距离加上AB间的边的距离小于源节点S到第二个节点B的距离，那么A将作为B的先驱节点，源节点到B的距离也更新到（distance（A）+ edge.length（A,B）），否则不进行任何更新。 Bellman-Ford算法可以大致分为三个部分 1. 初始化所有点。每一个点保存一个值，表示从原点到达这个点的距离，将原点的值设为0，其它的点的值设为无穷大（表示不可达）。 2. 进行循环，循环下标为从1到n－1（n等于图中点的个数）。在循环内部，遍历所有的边，进行松弛计算。 3. 遍历途中所有的边（edge（u，v）），判断是否存在这样情况： d（v） &gt; d (u) + w(u,v)，则返回false，表示途中存在从源点可达的权为负的回路 function &lt;predecessors&gt; Bellman-Ford(G, source) for i in 1 to |U| do distance[i] = +inf predecessors[i] = null distance[source] = 0 for i in 1 to (|U| - 1) do for each Edge e in Edges(G) do if distance[e.from] + length(e) &lt; distance[e.to] do distance[e.to] = distance[e.from] + length(e) predecessors[e.to] = e.from for each Edge e in Edges(G) do if distance[e.from] + length(e) &lt; distance[e.to] do error("Graph contains cycles of negative length") return predecessors 这里的第三步是为了检测是否存在negative cycle，假设存在以下图并进行relaxation operation： 由于存在negative edge 导致每进行一次松弛计算，节点的权值都会减小，这样在环图中就没有收敛，此时根据算法第三条进行判断，若满足条件则说明存在negative edge example]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dijkstra算法]]></title>
    <url>%2F2016%2F10%2F25%2F%E7%AE%97%E6%B3%95%2F2016-10-25-Dijkstra%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Dijkstra算法 Dijkstra算法求图中最短路径的一种算法，优点是其能找到所有最短路径，但是要求图中不能含有负权值的边。 算法描述 Dijkstra算法的思想是一种贪婪算法，初始化时根节点（root）被设置为distance = 0 并放在优先队列S中，其他节点被设置成distance = +inf 并放在等待队列V中。设descendent node是V的某一个节点，我们把从processed node到descendent node且中间只经过S中节点的路径叫做关键路径，采用数组dist记录路径长度，也就是说在算法中保证 distance.processed + edgeWeight.(processed,descendant) &lt; distance.descendent 如果上式成立，那么将processed node设置成descendant node 的祖先节点（ancestor），遍历V集合中的所有节点，然后选取最优（最短路径）加入S集合中，然后重复上述过程，直到V集合为空。 /** * Dijkstra's algorithm * @param d matrix of legths, position [0 1] = 2 means that from node 0 leads an edge to node 1 of length 2 * @param from root node * @return tree an ancestors (denotes path from the node to the root node) */procedure int[] doDijkstra(d, from) &#123; //insert all nodes to the priority queue, node from has a distance 0, all others infinity Q = InsertAllNodesToTheQueue(d, from) CLOSED = &#123;&#125; //closed nodes - empty set predecessors = new array[d.nodeCount] //array of ancestors while !Q.isEmpty() do node = Q.extractMin() CLOSED.add(node) //close the node //contract distances for a in Adj(node) do //for all descendants if !CLOSED.contains(a) //if the descendatn was not closed yet //and his distance has decreased if Q[node].distance + d[node][a] &lt; Q[a].distance //zmen prioritu (vzdalenost) uzlu Q[a].distance = Q[node].distance + d[node][a] //change its ancestor predecessors[a] = node return predecessors /** * Dijkstra's algorithm * @param d matrix of lengths (Integer.MAX_VALUE if there is no edge between the nodes) * @param from root node * @return tree an ancestors (denotes path from the node to the root node) */ public static int[] doDijkstra(int[][] d, int from) &#123; Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); set.add(from); boolean[] closed = new boolean[d.length]; int[] distances = new int[d.length]; for (int i = 0; i &lt; d.length; i++) &#123; if (i != from) &#123; distances[i] = Integer.MAX_VALUE; &#125; else &#123; distances[i] = 0; &#125; &#125; int[] predecessors = new int[d.length]; predecessors[from] = -1; while (!set.isEmpty()) &#123; //find the nearest node int minDistance = Integer.MAX_VALUE; int node = -1; for(Integer i : set)&#123; if(distances[i] &lt; minDistance)&#123; minDistance = distances[i]; node = i; &#125; &#125; set.remove(node); closed[node] = true; //contract the distances for (int i = 0; i &lt; d.length; i++) &#123; //edge exists if (d[node][i] != Integer.MAX_VALUE) &#123; if (!closed[i]) &#123; //the path length decreased using the ancestor node if (distances[node] + d[node][i] &lt; distances[i]) &#123; distances[i] = distances[node] + d[node][i]; predecessors[i] = node; set.add(i); &#125; &#125; &#125; &#125; &#125; return predecessors; &#125; 图示 迭代 S descentdent node dist[A] dist[B] dist[C] dist[D] 初始 {S} - 20 10 max int 70 1 {S，B} B 20 10 40 70 2 {S，B，A} A 20 10 40 70 3 {S，B，A，C} C 20 10 40 70 4 {S，B，A，C，D} D 20 10 40 70]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi Input02]]></title>
    <url>%2F2016%2F09%2F01%2FPi%2F2016-09-01-Raspberry%20Pi%20Input02%2F</url>
    <content type="text"><![CDATA[实验目标 在实验Input 01的基础上建立一个命令行接口，计算机可以中断并显示它们。 终端 具体操作行为步骤如下： 1. 启动计算机，显示欢迎信息 2. 计算机表明它准备好工作 3. 使用者在键盘上键入指令和参数 4. 当敲下回车键时表示提交一条指令 5. 计算机解析并执行指令如果该指令没有错误 6. 计算机显示指令正确以及接下来发生了什么 7. 返回到步骤2 在终端的命令行输入输出操作都具有一定的统一性，因此我们不再需要去绘制出每一个像素点（计算机在此处的额操作是以字符为单位的），我们将每一个字符的图案信息、颜色信息等都保存起来，再按照需要通过DrawCharacter函数调用每一个字符即可。 .section .data.align 4terminalStart:.int terminalBufferterminalStop:.int terminalBufferterminalView:.int terminalBufferterminalColour:.byte 0xf.align 8terminalBuffer:.rept 128*128.byte 0x7f.byte 0x0.endrterminalScreen:.rept 1024/8 * 768/16.byte 0x7f.byte 0x0.endr terminalBuffer 可以保存我们所有需要显示的文本信息，这里定义了最多可以保存128行并且每个保存了128个字符，每个字符又保存了ASCII字符以及颜色信息，使用buffer的优点如下： 1. 我们可以轻易看哪个字符不同，从而区分出来 2. 我们可以回滚到历史版本因为buffer里面可以保存到历史信息 terminalScreen 保存当前显示的文本信息 terminalStart terminalStop 由于在这里的buffer是环形结构的，类似于数据结构的循环链表，因此需要用Start和Stop来进行标识起始于中止位置，因此当中止超过起始的时候就能发觉是否要更替字母或者其它操作 . terminalColor 综合前景文字与背景各16种颜色，一共256组合,每个字符中低位保存的是前景颜色，高位保存的是背景颜色， 文本显示 terminalDisplay 该函数是从terminalBuffer中复制当前的数据到terminalScreen中，首先要比较二者是否不同，如果不同要数据更新。 加载 terminalView terminalStop terminalDisplay 函数 对于每一行来说（先行遍历） 对于每一列来说（再列遍历） 如果view视图中不为stop，则加载view当前字符与颜色 否在加载字符0x7f与颜色0 从terminalDisplay加载当前字符 如果二者相同则跳转到步骤10 二者不同则需要将加载到的字符与颜色保存到terminalDisplay中 调用 TerminalColor 函数，获取背景颜色 调用 DrawCharacter 函数，r0 = 0x7f（空白），r1=x， r2 = y 调用 TerminalColor 函数，获取前景颜色 调用 DrawCharacter 函数，r0 = 当前显示字符，r1=x， r2 = y 将 terminalDisplay 函数显示的位置加2 如果view 与 stop 不相同（没有将所有空间填满），view的位置也加2 否则要将end替换掉start的位置 x的坐标要加8 y的坐标要加16 打印行信息 该函数在r0寄存器中保存了串地址，在r1中保存了串长度，然后将内容写出到当前的地址中，并显示到显示器上。 检测串长度是否为0，如果为0则返回 加载 terminalStop 和 terminalView 函数 计算并确认x坐标的位置（目的是为了确定要显示串的位置） 对于每一个字符有以下操作 检查换行符 如果需要换行将bufferStop标识更新到行尾 如果不需要换行将字符复制到当前的terminalColour中 检查是否在行尾 如果在行尾就需要检查在terminalView与terminalStop中的字符数量是否超过了当前屏幕所能容纳的数量 如果超出当前屏幕就需要换行 检查 terminalView 如果在buffer尾，则需要将start更新 检查 terminalStop 如果在buffer尾，则需要将start更新 检查 terminalStop 与 terminalStart 是否相等，如果相等则需要增加 terminalStart的值来换行 检查 terminalStart 是否在buffer尾，如果是这样则用start来更新当前值 保存 terminalStop 与 terminalView 标准输入 ReadLine 如果最大长度是0（即没有输入），那么返回0 取回 terminalStop 和 terminalView 当前值 如果最大长度大于buffer大小的一半，将长度置为buffer大小的一半 从最大长度减去以保证能实现下划线闪烁与空终端的实现 在字符串中加上下划线 写回 terminalView 与 terminalStop 地址 对当前字符串调用 Print 函数 调用 terminalDisplay 调用 KeyboardUpdate 调用 KeyboardGetChar 如果是新的行字符，到步骤16 如果是空格并且长度大于1则在长度上减1 如果是常规字符并且长度小于最大长度那么将字符写入到串中 如果字符串以下划线结尾，加一个空格否则加一个下划线 回到步骤6 在已有的字符串后面增加一个新行 调用 Print 和 TerminalDisplay 函数 将新行用空终端来代替 返回字符串的长度]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi Input01]]></title>
    <url>%2F2016%2F08%2F31%2FPi%2F2016-08-31-Raspberry%20Pi%20Input01%2F</url>
    <content type="text"><![CDATA[实验目标 了解驱动与链接，以及键盘和如何在显示器上显示文本。 链接 静态链接库与动态链接库都是共享代码的方式，它允许我们通过链接的方式实现代码调用。静态链接库直接将代码地址写入到操作系统中，而动态链接库则是在加载的过程中实现链接，本实验采用的是静态链接的方式。 键盘实现键入更新 在计算机当中，重复查看某一更新被称为轮询，这种方法经常在I/O当中使用，在本实验当中也是通过这种轮询的方法来查看键盘是否有新的输入。 具体步骤如下： 取回存入的键盘地址（默认初始为0） 如果不为0则说明有当前键入值，那么跳到步骤9 使用UsbCheckForChange函数来检测是否有新的函数值更新 使用KeyboardCount检测现在有多少键 当返回0时说明没有找到设备 使用KeyboardGetAddress函数去得到第一个键盘地址 存入地址 有错误产生返回0 重复使用6次KeyboardGetKeyDown函数取得每一个键值并存储 使用KeyboardPoll函数 如果没有错误则跳转到步骤3 .section .text.globl KeyboardUpdateKeyboardUpdate:push &#123;r4,r5,lr&#125;kbd .req r4ldr r0,=KeyboardAddressldr kbd,[r0]teq kbd,#0bne haveKeyboard$getKeyboard$:bl UsbCheckForChange 首先将KeyboardAddress存入r4中，并判断其是否为0，当地址为0则说明发生错误没有找到键盘，那么就使用UsbCheckForChange来查找新设备，但是这一步消耗资源较大，尽量避免。 teq r0,#0ldreq r1,=KeyboardAddressstreq r0,[r1]beq return$mov r0,#0bl KeyboardGetAddress 当没有找到键盘是，理应获取不到键盘地址，那么就应该将r0初始化为0后继续进行返回来查看地址。 saveKeys$:mov r0,kbdmov r1,r5bl KeyboardGetKeyDownldr r1,=KeyboardOldDownadd r1,r5,lsl #1strh r0,[r1]add r5,#1cmp r5,#6blt saveKeys$ 这里就是采用轮询的方式来获取键入值 mov r0,kbdbl KeyboardPollteq r0,#0bne getKeyboard$return$:pop &#123;r4,r5,pc&#125;.unreq kbd 成功获取当前键入值之后使调用KeyboardPoll函数。 然后根据键盘匹配的字符表来进行比对从而得到每一个按键所代表的字符信息，完成信息键入。]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi Screen04]]></title>
    <url>%2F2016%2F08%2F16%2FPi%2F2016-08-16-Raspberry%20Pi%20Screen04%2F</url>
    <content type="text"><![CDATA[实验目标 在图形界面上操作文本 背景补充 字符串操作 计算机不能满足于只显示提前准备好的字符串，需要有特定的函数来处理含有变量的字符串，比如说接下来的表格就是C++常见语法。 即使传入的变量相同，但是显示的格式不一样得到的结果也是不同的，比如说如下： 除法 不同于人们运算除法时采用的乘法表的方式，计算机在进行除法运算时，首先将其转换成二进制数字，从被除数最高为开始，选择一个数，非零即一，检查该位上能否减去除数之后余数还大于0。接下来把余数部位，继续完成下一位的运算。重复直到所有被除数的位都被处理既完成。 相比较于其他运算，除法相对来说开销是很大的，一方面他的每一个商实际上都是试验的结果，并不是直接计算能确定的结果；另一方面他的每一次运算都取决于上一次的运算结果，没法通过硬件实现并行计算。所以如果能提升除法的性能是很有意义的。 我们对于一些特殊的除法运算可以进行如下的优化：比如说一些较小的数的计算，1/1 我们就没有必要从最高位开始loop，用clz指令（可以计算前导0的数目），这样我们就可以避开高位为0的情况，提高计算性能。 代码分析 数字串 SignedString 我们处理有符号和无符号数时主要的区别就是在于最高位所代表的含义是不同的，因此对于正有符号数可以直接按照无符号数处理，负有符号数可以用剩余位的数字进行处理然后最后判断符号填在结果前面就好。 UnsignedString 在处理无符号的数时，这里有两句伪代码 rem + '0'， rem - 10 + 'a' 就是根据ascii码进行处理的。 格式串 我们之前提到的 %d 就是一种格式化的输出，格式化字符串的精髓就是各种变参（可以参看这篇博客）,甚至可以限制长度、精度等。对于不同的函数，我们手首要确定的关键就是参数，这里我们采用栈来存储参数，对于传入的参数反向压栈，然后依次判断每个字符的含义，从而进行字符串的格式化处理。 进制转换 在这一部分我们将10进制数字转换成其它进制的数字。 mov r4,#0loop$:ldr r0,=formatmov r1,#formatEnd-formatldr r2,=formatEndlsr r3,r4,#4push &#123;r3&#125;push &#123;r3&#125;push &#123;r3&#125;push &#123;r3&#125;bl FormatStringadd sp,#16 注意这里push指令先减栈指针再数据入栈（也有说二者顺序颠倒，结果没有差别主要看CPU设计），然后接下来的工作就将数字进行进制转换。 结果展示]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi Screen03]]></title>
    <url>%2F2016%2F08%2F14%2FPi%2F2016-08-14-Raspberry%20Pi%20Screen03%2F</url>
    <content type="text"><![CDATA[实验目标 在图形界面上实现文本，以及一个命令行的功能。 背景补充 字符串及其编码 我们都知道计算机可以将字符显示到屏幕上，同时我们也知道计算机无法直接处理文本信息，因为它只认识bit和byte，并在数字的基础上做运算，所以实际上我们需要制定的是一种映射关系，使得计算机能将屏幕上显示的内容与内存中的信息联系起来。所以在我们录入信息的时候可以看做我们将文本加密成一种计算机可识别的信息，反过来显示的时候就是计算机的特定信息解密成可显示的文本，这其中的加密与解密的秘钥就是我们所说的编码，一种编码对应一种加解密方式，也就是说当你使用了错误的编码那么所得到的结果就注定是一种错误的乱码。 由于自然语言的多种多样，导致了编码时的难以统一，在现在网络的大环境下，必须要用同一的标准也就是说，在计算机里的同一个数字要对应同一个字符，尤其是面对多语音的混合文档。所以就像该书所说： Everything you thought you knew about strings is wrong. ASCII ASCII是专门为英语设计的，也是计算机非常流行的一种编码方式，使用一个字节的低7位（共8位），剩余的1位被用来制定其它语言的字符或者特殊符号，但是标准不是很统一。 Unicode - UTF32 UTF32的设想是用4个字节来表示所有自然语言的字符，不存在二义性，比如说U+0041总是代表'A'，即使这种语言没有'A'这个字符。但问题是，对于某些字符来说（比如说英语），4个字节是一种大大的浪费，这对空间的占用不可忽视，虽然说这种编码方式可以准确全面的定位到所有的字符，但是在绝大多数的使用场景中，都不会用到这么多种字符。 Unicode - UTF16 UTF16就是缩减到2个字节，对于盲区的字符用其他方法索引实现，这样一来就能大大减少空间使用。但是UTF32与UTF16都有一个很大的问题就是，对于计算机不同的大小端存储方式，可能会造成数据混乱。这里引入了Byte Order Mark（字节顺序标记），如果一个文档以FFEE开头则说明是单向，以FEFF开头则说明是反向文档。 Unicode - UTF8 人们对于UTF16的空间存储造成的浪费以及对于盲区字符的困扰没有满足，重新设计UTF8，这是一种变长的编码系统，对于不同的字符选择合适大小的存储空间，但是查询的索引可能复杂度高于前两者。 参考资料1 参考资料2 字体显示 早期的字体显示是用可以类比位图，这样的缺点就是我们需要给同一个字符设置许多种不同的大小来满足需求，很显然这样是非常愚蠢的一种做法，后来我们用向量来表示不同的字体，这样我们存储一个字符实际上就是存储这个字符的表述信息，比如说字母'o'我们就可以描述成一个圈。（尽管向量描述是一个优秀的方法，但是在本次实验中我们任然采用第一种位图的方法，因为实现起来相对容易一些），在原文中给了一个字母A的例子 可以看到，每一排都是8位，非0即1，每一排都可以对应一个特有的序列，我们用16进制表示 00 00 00 10 28 28 28 44 44 7C C6 82 00 00 00 00 代码分析 drawCharacter 这个实际上的逻辑就是根据传入的具体字符，得到上述表示的每一行像素的8位表示，然后再通过起始的x与y坐标进行绘制，原文中给出伪代码与汇编对照看，容易理解。 drawStrings 画出一个字符串实际上就是多次画出其包含的每一个字符，除此之外我们还需要考虑的是什么时候能换行与结束。实际上我们在检查边界条件代码与上面drawCharacter的代码结合起来就可以了。（汇编代码中有一处是替换掉了loop循环中的乘法运算，因为位图的固定大小优势使得我们可以这样做） 命令行绘制 我们首先要了解实验在ARM架构中的数据格式，整理翻译如下 数据是在「tag」标签中止的。 总共有9种标签，「core」内核，「mem」内存，「videotext」可视图文，「ramdisk」虚拟内存盘，「intrd2」初始RAM磁盘，「serial」串口，「revision」校验，「videolfb」「cmdline」命令行。 标签只能出现一次但「core」是缺省标签。 标签地址是从0x100依次排列的。 在标签的末尾总是包含两个全0的字节。 大小是4的整数倍 标签总是以其大小为开始的，这个大小也包含其本身。 实际上标签是以从1到9的序号来代表他们的。 数据格式总是跟着一个5441（hex）的半字。 字中的数据长度+2总是能符合要求的 「core」既可以是2也可以是5的长度，如果是2那么没有数据，如果是5则代表有3个字。 「mem」4个字的长度，数据和总长度是在首地址的。 「cmdline」包含一个空的中止字符串，这个内核的一个重要特点。 在我们的实验中只有「core」「mem」「cmdline」出现。 首先初始化将1-9标签都设为 .int 0 FindTag 在这个函数中，首先检查标签范围，然后检查地址并将其设置为0x100，接下来在loop循环中依次获取tag的数据即可。 Hello World mov r0,#9bl FindTagldr r1,[r0]lsl r1,#2sub r1,#8add r0,#8mov r2,#0mov r3,#0bl DrawStringloop$:b loop$ 利用FindTag找到9号「cmdline」标签计算出长度等信息，然后传入参数，以及初始化，画出字符，大功告成。]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi OK04]]></title>
    <url>%2F2016%2F08%2F09%2FPi%2F2016-08-09-Raspberry%20Pi%20OK04%2F</url>
    <content type="text"><![CDATA[实验目标 利用timer使ACT灯闪烁 背景补充 timer的相关地址与其功能 根据流程图我们可以知道，timer实际上是每隔1s钟自加1，直到与其比较的寄存器相同时结束。 代码分析 ldr r0,=100000bl Wait 在main.s文件中我们可以看到，这两句代码是通过r0设置等待时间，然后调用新函数实现timer的计时等待功能。 delay .req r2 mov delay,r0 push &#123;lr&#125; bl GetTimeStamp 在systemTimer.s中的Wait函数中，将r0传入的参数保存到r2中 .globl GetSystemTimerBaseGetSystemTimerBase: ldr r0,=0x20003000 mov pc,lr 通过这个函数在r0中获取到timer的基地址，并使用lr返回。 ldrd r0,r1,[r2,#4] 在这里我们使用的计数器counter有8字节，但是实际上每个寄存器只有4字节大小，所以每个counter都需要2个寄存器，所以使用ldrd指令，一次可以向一个地址中加载两个寄存器的值，r1是高字节，r0是低字节，非常方便。 此时我们就可以通过loop函数进行逐次比较了。 结果展示 与上个实验现象相同]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi OK05]]></title>
    <url>%2F2016%2F08%2F09%2FPi%2F2016-08-09-Raspberry%20Pi%20OK05%2F</url>
    <content type="text"><![CDATA[实验目的 利用前面的知识做出一个SOS信号的闪烁灯。学会汇编中的代码段与数据段。 背景补充 转自梦开始的地方 .section .data 汇编程序中以.开头的名称并不是指令的助记符，不会被翻译成机器指令，而是给汇编器一些特殊指示，称为汇编指示（Assembler Directive）或伪操作（Pseudo-operation），由于它不是真正的指令所以加个“伪”字。.section指示把代码划分成若干个段（Section），程序被操作系统加载执行时，每个段被加载到不同的地址，操作系统对不同的页面设置不同的读、写、执行权限。.data段保存程序的数据，是可读可写的，相当于C程序的全局变量。本程序中没有定义数据，所以.data段是空的。 .section .text .text段保存代码，是只读和可执行的，后面那些指令都属于.text段。 .globl _start _start是一个符号（Symbol），符号在汇编程序中代表一个地址，可以用在指令中，汇编程序经过汇编器的处理之后，所有的符号都被替换成它所代表的地址值。在C语言中我们通过变量名访问一个变量，其实就是读写某个地址的内存单元，我们通过函数名调用一个函数，其实就是跳转到该函数第一条指令所在的地址，所以变量名和函数名都是符号，本质上是代表内存地址的。 .globl指示告诉汇编器，_start这个符号要被链接器用到，所以要在目标文件的符号表中标记它是一个全局符号。_start就像C程序的main函数一样特殊，是整个程序的入口，链接器在链接时会查找目标文件中的_start符号代表的地址，把它设置为整个程序的入口地址，所以每个汇编程序都要提供一个_start符号并且用.globl声明。如果一个符号没有用.globl声明，就表示这个符号不会被链接器用到。 代码分析 .section .data.align 2pattern:.int 0b11111111101010100010001000101010 .align 2 对齐伪指令，要求使用的地址都必须是2的倍数，因为在ldr指令中，所使用的地址都是4的倍数。.int 就是我们的闪烁序列了，1代表亮，0代表灭，在这里改变序列就可以改变灯的变化，可以多尝试几组不同序列。 ptrn .req r4ldr ptrn,=patternldr ptrn,[ptrn]seq .req r5mov seq,#0 ldr ptrn,=pattern 指令中，将pattern的地址加载到r4中，再从该地址取值，所以最后r4寄存器保存的是pattern中的数值（此处通过ldr的转换不同于mov有位数的限制，支持更大的数据） 结果展示]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi Screen02]]></title>
    <url>%2F2016%2F08%2F09%2FPi%2F2016-08-11-Raspberry%20Pi%20Screen02%2F</url>
    <content type="text"><![CDATA[实验目标 用产生伪随机数的方式画出线条和其它的一些东西。 代码分析 点 我们希望通过在任意两点确定一条直线的方式画线，所以我们需要SetPixel函数来确定两个点。 drawing.s .section .data.align 1foreColour:.hword 0xFFFF.align 2graphicsAddress:.int 0.section .text.globl SetForeColourSetForeColour:cmp r0,#0x10000movhs pc,lrldr r1,=foreColourstrh r0,[r1]mov pc,lr.globl SetGraphicsAddressSetGraphicsAddress:ldr r1,=graphicsAddressstr r0,[r1]mov pc,lr 这些函数写在drawing.s文件中方便调用，可以用在不同的memory中。 SetPixel 加载地址 graphicsAddress 确定x和y数值的合法性 计算每个像素点的地址（frameBufferAddress + (x + y * width) * pixel size） 加载颜色信息foreColor 将颜色foreColor保存到相应地址中 .globl DrawPixelDrawPixel:px .req r0py .req r1addr .req r2ldr addr,=graphicsAddressldr addr,[addr] px（r0寄存器），py（r1寄存器），addr（r2寄存器） height .req r3ldr height,[addr,#4]sub height,#1cmp py,heightmovhi pc,lr.unreq heightwidth .req r3ldr width,[addr,#0]sub width,#1cmp px,widthmovhi pc,lr 根据上个实验中定义的数据格式，Physical height和Physical width分别在偏移地址4和0上，然后再确认我们定义的px和py是否符合height和width的范围。 ldr addr,[addr,#32]add width,#1mla px,py,width,px.unreq width.unreq pyadd addr, px,lsl #1.unreq px [addr,#32] 是数据格式中的指向特定图像的指针； mla 指令是带累加的相乘，完成的是px = py*width+px，地址还需要乘上每个像素的大小，add addr, px,lsl #1 得到的地址就是特定像素的地址了。 fore .req r3ldr fore,=foreColourldrh fore,[fore]strh fore,[addr].unreq fore.unreq addrmov pc,lr 所以从foreColor中取出特定的颜色信息再传入到上面计算好的addr地址中，就是这个特定地址的像素信息了。 线 在汇编语言中使用除法是一件比较麻烦的事情，所以计算倾角来画线是不明智的选择，在这里介绍一种布雷森汉算法（Bresenham's line algorithm），可以画直线，并且只用到了加减与移位运算。 实际上Bresenham's Algorithm是将我们现实中连续的直线离散化，因为我们实际上不可能有足够高的精度去描述一条准确的直线，毕竟计算机本身就是离散的，图形描述的离散也是情理之中。 算法的流程图如下,有关各式的推导可以在维基百科中得到。 随机数生成 一种迭代的随机数生成算法，xn就是种子。 a是偶数 b = a + 1 mod 4 c是奇数 实际上我们知道最简单的随机数数学公式可以用 这样一个最简单的公式表达，也的确能生成的一个数字序列，但是随机性也是非常低的，我们用二次函数来代替一次函数在某些程度上可以增加他的随机性，但是这些依然是伪随机生成。 将算法与随机数生成程序都用汇编实现。然后接下来就是按照实验步骤一步一步实现一个随机数画图程序了。 实验过程 使用SetGraphicsAddress, 并用r0传入帧缓冲区的地址。 初始化4个寄存器，一个保存随机数，一个保存颜色信息，还有一对是x，y坐标信息。 在现有的坐标上，利用随机数生成下一个x轴坐标 利用x坐标生成下一个y坐标 迭代更新，用随机数代表y 使用SetForeColour函数和颜色寄存器去设置颜色。 由于我们的像素都是小于1024的，然而寄存器却能保存32位，远大于1024，所以要将寄存器值逻辑右移22位，以满足要求。 检查y寄存器是否小于等于767，否则回到步骤3. 利用布雷森汉算法在两点之间画线。 用生成的x和y坐标更新现有的坐标。 回到步骤三，画下一条线。 结果展示]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi Screen01]]></title>
    <url>%2F2016%2F08%2F09%2FPi%2F2016-08-10-Raspberry%20Pi%20Screen01%2F</url>
    <content type="text"><![CDATA[实验目标 了解图形图像的基本知识 背景补充 有关黑白、灰度、8色、低彩、高彩、真彩和RGB32的详细说明与区别见原文 Pi在开机时，先运行的是图像处理器，后运行主处理器，当外接显示器时可以看到在启动Pi时，是先在屏幕上显示一张全彩的影像，然后才进入到系统启动。 Pi在进行与图像处理器通信的时候采用的是信箱通信方式，以发送信件以及接收回答信件为进程间通信的基本方式。当一个进程希望与另一进程通信时，就创建一个链接两个进程的信箱，发送进程把信件投入信箱，而接收进程可以在任何时刻取走信件。 采用信箱通信的最大好处是，发送方和接收方不必直接建联系，没有处理时间上的限制。发送方可以在任何时间发信，接收方也可以在任何时间收信。 信箱的地址表如下 发送方： 发送方等待直到状态字段的最高位为0。 最低的4位代表了所要发送的信箱序号，高28位代表了所要发送的内容。 接收方： 接收方等待直到状态字段的30标志位为0。 读取。 确认信箱的正确，否则重复上述步骤直到正确。 代码分析 GetMailboxBase .globl GetMailboxBaseGetMailboxBase:ldr r0,=0x2000B880mov pc,lr 根据上表我们知道0x2000B880是信箱的地址。 MailboxWrite 校验输入（r0）输出（r1）的低四位都是0，确保信箱正确性。 利用GetMailboxBase函数得到信箱地址。 读取状态字段。 校验状态字段的最高位是否为0，否则返回第3步。（等待） 连接发送内容（高28位）与信箱通道（低4位） 写 .globl MailboxWriteMailboxWrite:tst r0,#0b1111movne pc,lrcmp r1,#15movhi pc,lr tst 数据处理指令，用于把一个寄存器的内容和另一个寄存器的内容或立即数进行按位的与运算，并根据运算结果更新CPSR中条件标志位的值,这几行代码就是检查r0和r1寄存器的最低4为是否为0，若不为0则把lr寄存器装载到pc中，返回并退出。 channel .req r1value .req r2mov value,r0push &#123;lr&#125;bl GetMailboxBasemailbox .req r0 保护现场，避免覆盖r0的值。 wait1$:status .req r3ldr status,[mailbox,#0x18] 根据表格可以知道0x2000B898是Status的地址。 tst status,#0x80000000.unreq statusbne wait1$ 检查最高位是否为0。 add value,channel.unreq channel 高28位数值于低4位通道号连接。 str value,[mailbox,#0x20].unreq value.unreq mailboxpop &#123;pc&#125; 根据表格可以得知地址2000B8A0是WRITE，将value的值保存到该地址中即可，同时取消所有定义，pc出栈，完成操作。 MailboxRead 从信箱中读取信件的代码与之前实现基本相同。在读取的时候要从0x2000B880地址中读取。 FrameBufferInfo .section .data.align 4.globl FrameBufferInfoFrameBufferInfo:.int 1024 /* #0 Physical Width */.int 768 /* #4 Physical Height */.int 1024 /* #8 Virtual Width */.int 768 /* #12 Virtual Height */.int 0 /* #16 GPU - Pitch */.int 16 /* #20 Bit Depth */.int 0 /* #24 X */.int 0 /* #28 Y */.int 0 /* #32 GPU - Pointer */.int 0 /* #36 GPU - Size */ 以上代码是定义传到GPU的数据格式，各项意义均已说明，注意字对齐。 接下来的步骤如下： 向mailbox1 写入地址FrameBufferInfo + 0x40000000。 从mailbox1 中读出数据，如果不是0，则停止申请frame buffer。 将指针指向我们所要展示的图片，就能在显示器上看到图片了。 FrameBufferInfo + 0x40000000 加上0x40000000是一种特定的指令，为了能够告诉GPU禁止自身的cache，以便能让我们观察到数据变换，这是规定好的指令。 输入 将输入写到帧缓冲区中 将frame buffer + 0x40000000 的地址送到mailbox中 从mailbox中得到返回值 判断返回是否为0，如果是0则表示成功 返回一个帧缓冲区的指针 InitialiseFrameBuffer .section .text.globl InitialiseFrameBufferInitialiseFrameBuffer:width .req r0height .req r1bitDepth .req r2cmp width,#4096cmpls height,#4096cmpls bitDepth,#32result .req r0movhi result,#0movhi pc,lr 检查width和height是否都小于等于4096，bitDepth是否小于等于32，如果满足条件则将0保存到result中，表示符合条件。 fbInfoAddr .req r3push &#123;lr&#125;ldr fbInfoAddr,=FrameBufferInfostr width,[fbInfoAddr,#0]str height,[fbInfoAddr,#4]str width,[fbInfoAddr,#8]str height,[fbInfoAddr,#12]str bitDepth,[fbInfoAddr,#20].unreq width.unreq height.unreq bitDepth 按照之前给出的数据格式保存到相应的地址中 mov r0,fbInfoAddradd r0,#0x40000000mov r1,#1bl MailboxWrite 这里就是之前说的固定格式的地址指令，r1中则是选择了通道。 mov r0,#1bl MailboxRead r0中选择了通道，与上面写信箱的通道保持一致。 teq result,#0movne result,#0popne &#123;pc&#125; 测试返回值是否为0，如果结果不为0则返回0表示有错误发生。 mov result,fbInfoAddrpop &#123;pc&#125;.unreq result.unreq fbInfoAddr 将帧缓冲地址返回 现在我们要使用GPU处理图像。 mov r0,#1024mov r1,#768mov r2,#16bl InitialiseFrameBuffer 定义一个1024*768，16位色的帧 teq r0,#0bne noError$mov r0,#16mov r1,#1bl SetGpioFunctionmov r0,#16mov r1,#0bl SetGpioerror$:b error$noError$:fbInfoAddr .req r4mov fbInfoAddr,r0 检查r0寄存器中是否为0，若不为0，进行图像处理程序，否则通过GPIO口点亮ACT灯。 在大多数的位图的存储方式中，总是从左向右，从上到下，所以我们使用两个循环完成每个像素点。 render$: fbAddr .req r3 ldr fbAddr,[fbInfoAddr,#32] colour .req r0 y .req r1 mov y,#768 drawRow$: x .req r2 mov x,#1024 drawPixel$: strh colour,[fbAddr] add fbAddr,#2 sub x,#1 teq x,#0 bne drawPixel$ sub y,#1 add colour,#1 teq y,#0 bne drawRow$ b render$.unreq fbAddr.unreq fbInfoAddr strh 指令是半字存储，在通过x和y分别控制循环变量，实现嵌套的循环，完成整个屏幕像素点的加载 结果展示]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi OK03]]></title>
    <url>%2F2016%2F08%2F06%2FPi%2F2016-08-06-Raspberry%20Pi%20OK03%2F</url>
    <content type="text"><![CDATA[实验目标 学会使用汇编语言写函数 背景补充 ABI 应用程序二进制接口 标准规定寄存器r0，r1，r2和r3应该按顺序使用，如果函数中没有输入，那么就不必使用任何寄存器；如果只需要1个输入，那么就使用r0，需要2个输入，就使用r0和r1，以此类推；函数的输出总使用r0，同理如果没有输出就不需要使用r0输出。 对于r4~r12寄存器，在每次调用函数之后都需要还原现场，保证使用前后寄存器的值不变。 函数运行结束之后需要返回，那么此时我们必须知道返回的地址，该地址用lr寄存器保存。 sp寄存器保存的是堆栈中第一个参数的地址，并且配合push{r4，r5}，pop{r4，r5}这样的指令进行使用。 各个寄存器的使用功能如下表所示，可供查阅 代码分析 GetGpioAddress .globl GetGpioAddressGetGpioAddress:ldr r0,=0x20200000mov pc,lr 我们可以通过这种方式定义在文件外部的函数代码，既可以本文件调用也可以让其他文件的函数引用。然后设置GPIO的基地址，并把lr寄存器的值保存到pc寄存器中，实现功能与之前实验基本相同。 SetGpioFunction .globl SetGpioFunctionSetGpioFunction:cmp r0,#53cmpls r1,#7movhi pc,lr cmp指令中，如果r0&gt;53则跳过cmpls指令运行movhi，函数结束；cmpls指令中，如果r1&gt;7则运行movhi，函数结束。正确情况下是r0&lt;=53,r1&lt;=7,指令继续执行。 push &#123;lr&#125;mov r2,r0bl GetGpioAddress 调用GetGpioAddress函数，首先将返回地址压栈，然后保存现场避免丢失寄存器的值（假如我们不知道调用的函数是如何工作的，那么就需要保存所有的寄存器，此处我们只保存r0）。 调用结束之后我们可以知道r0中的值就是GPIO的地址，r1保存function code，r2保存GPIO端口（r1和r2在main函数中定义） functionLoop$:cmp r2,#9subhi r2,#10addhi r0,#4bhi functionLoop$ 循环以保证r2&lt;9,地址r0 = r0+（GPIO%10）* 4 add r2, r2,lsl #1lsl r1,r2str r1,[r0]pop &#123;pc&#125; 为了加快运行速度，(r2 * 3) 变换成 (r2 左移1位 + r2)，然后剩余代码与之前实验功能一致，将对应位置1，同时使用pop指令出栈lr寄存器的值送到pc中。 SetGpio .globl SetGpioSetGpio:pinNum .req r0pinVal .req r1 这里使用到了register aliases，类似于c语言中的宏，优点就是避免只用符号代替的寄存器混淆掉。 cmp pinNum,#53movhi pc,lrpush &#123;lr&#125;mov r2,pinNum.unreq pinNumpinNum .req r2bl GetGpioAddressgpioAddr .req r0 首先检测给出的pinNum是否在允许范围，更改aliases所用的寄存器并调用函数，最后r2保存pinNum，r0保存的是gpioAddr。 pinBank .req r3lsr pinBank,pinNum,#5lsl pinBank,#2add gpioAddr,pinBank.unreq pinBank 利用r3把54个GPIO划分成32和22两组，分别对应GPIO 0~31的地址0x20200000和GPIO 32~53的地址0x20200004 and pinNum,#31setBit .req r3mov setBit,#1lsl setBit,pinNum.unreq pinNum 生成对应GPIO口的置位数值，注意其中31在二进制中表示5个1， teq pinVal,#0.unreq pinValstreq setBit,[gpioAddr,#40]strne setBit,[gpioAddr,#28].unreq setBit.unreq gpioAddrpop &#123;pc&#125; 注意teq(test equal),并保存在相应地址处，pop出栈结束函数。 最后注意堆栈结构，并写入main函数中 结果展示 本实验结果与ok02结果相同]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi OS Development 前言]]></title>
    <url>%2F2016%2F08%2F06%2FPi%2F2016-08-06-Baking%20Pi%20%E2%80%93%20Operating%20Systems%20Development%E5%89%8D%E8%A8%80%2F</url>
    <content type="text"><![CDATA[树莓派操作系统 这一系列的实验教程是英国剑桥大学针对计算机专业学生开设的，可以帮助学生了解基础的树莓派操作系统，官网教程已经十分详尽，我记录一些实验过程中的问题以及详细实现，避免与教程重复。 要求 基本知识： 基础编程 汇编 硬件： 树莓派1代B型 SD卡 软件： 1.GNU 2.交叉编译器 其它说明 树莓派1代是2011年的产品，可以在二手市场找到。我本来想尝试使用树莓派3代完成实验，但是在进行实验过程中，发现layout布局已经相比1代有明显改动，实验中要求进行写入的地址发生了变化，在Github开源项目中issue提交可以查到相关问题描述，但是开发者还未正式公布layout的接口布局，故只能作罢，后续如果开发者有更新可以继续尝试。 树莓派官网以及操作系统安装教程。 根据实际使用操作系统下载相关软件，详情见Download 推荐使用一台hdmi接口的显示器]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi OK02]]></title>
    <url>%2F2016%2F08%2F06%2FPi%2F2016-08-06-Raspberry%20Pi%20OK02%2F</url>
    <content type="text"><![CDATA[实验目标 在OK01的实验基础上，通过GPIO口重复控制ACT/OK灯的亮灭。掌握OS的等待/延迟实现。 代码分析 mov r2,#0x3F0000wait1$:sub r2,#1cmp r2,#0bne wait1$ 通过减法实现可控的循环延迟。 在这幅图中又可以看出想要将GPIO16置0只需要设置0x2020001c就可以了，所以代码逻辑就是 开灯 延迟 关灯 延迟 开灯 ... 结果展示]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Raspberry Pi OK01]]></title>
    <url>%2F2016%2F08%2F06%2FPi%2F2016-08-06-Raspberry%20Pi%20OK01%2F</url>
    <content type="text"><![CDATA[实验目标 通过GPIO使能Pi上ACT/OK灯，从而了解GPIO口。 代码分析 ldr r0,=0x20200000 GPIO-Register-Bytes.png 通过上表我们可以知道GPIO口是以0x20200000作为开始的，那么此时r0寄存器中保存的就是基址。 mov r1,#1lsl r1,#18str r1,[r0,#4] Bits-Pin-Map.png 根据以上两张图我们可以知道将地址0x20200000的第18位置1，相当于将GPIO16设置为output，此处GPIO16就是我们要点亮的ACT灯的输出位置。 在正式点亮ACT灯之前，树莓派还要求将GPIO16口进行清除操作 mov r1,#1lsl r1,#16str r1,[r0,#40] 根据图标显示我们有了以上代码，将物理地址0x20200028里的第16位设置成1，代表着清除GPIO16。 可以将以上代码理解成初始化步骤，接下里就让Pi在一个无限循环的loop里工作。 loop$:b loop$ 此时使用make指令，将生成的kernel.img文件进行更换,可以观察到Pi的ACT灯亮起，实验结束。 结果展示]]></content>
      <categories>
        <category>Pi</category>
      </categories>
      <tags>
        <tag>OS</tag>
        <tag>Raspberry-Pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IRQ与FIQ中断]]></title>
    <url>%2F2016%2F05%2F02%2F%E6%A6%82%E5%BF%B5%2F2016-05-15-IRQ%E4%B8%8EFIQ%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[以S3C2410系统为例，七种异常中断如下： 复位 未定义指令 软中断 指令预取中止 数据中止 IRQ FIQ 以下主要分析IRQ（中断请求）和FIQ（快速中断请求）的区别。 FIQ必须尽快处理事情并离开这个模式，IRQ可以被FIQ中断，反之不可以。也就是说FIQ比IRQ优先级要高,在执行FIQ中断时不能处理其他一切中断。 为什么FIQ比较快呢呢？ FIQ模式下有自己的寄存器组r8-r14,r14寄存器链接到返回地址，但是如果你的FIQ处理程序可以被写入时，只需要r8-r13寄存器组。优势如下：它不产生像IRQ入栈和出栈时的寄存器开销，以节省中断处理运行运转周期；快速中断还可以重复利用寄存器组里的值，比如说r8寄存器指向一个外部硬件，很有可能下一次中断也是同一个中断请求这样寄存器组里的值就可以被重复利用而不需要重新装载。 FIQ中断服务程序被放在异常向量表的底部，也就是说不需要任何的分支指令，可以直接从0x1c执行，也节省了很多周期。 优先级问题，FIQ可以中断IRQ反之不可以。 为什么很多操作系统没有引入FIQ呢？ FIQ需要汇编写，c语言没法处理，FIQ中断需要自己r8-r14的特殊寄存器，c语言也无法解决这个限制问题。 大多数操作系统并没有高优先级的中断来源，也就不需要快速中断处理 资料参考: What is the difference between FIQ and IRQ interrupt system?]]></content>
      <categories>
        <category>Concept</category>
      </categories>
      <tags>
        <tag>Concept</tag>
      </tags>
  </entry>
</search>
